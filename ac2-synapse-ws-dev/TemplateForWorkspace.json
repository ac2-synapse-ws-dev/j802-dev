{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "ac2-synapse-ws-dev"
		},
		"CosmosDbNoSql1_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'CosmosDbNoSql1'"
		},
		"CosmosGraphTest_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'CosmosGraphTest'"
		},
		"EORACountryStats_accountKey": {
			"type": "secureString",
			"metadata": "Secure string for 'accountKey' of 'EORACountryStats'"
		},
		"GremlinTest_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'GremlinTest'"
		},
		"ac2-synapse-ws-dev-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'ac2-synapse-ws-dev-WorkspaceDefaultSqlServer'",
			"defaultValue": "Integrated Security=False;Encrypt=True;Connection Timeout=30;Data Source=tcp:ac2-synapse-ws-dev.sql.azuresynapse.net,1433;Initial Catalog=@{linkedService().DBName}"
		},
		"EORACountryStats_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://ac2synapsedatalabstorage.dfs.core.windows.net/"
		},
		"J802Container_World_Bank_Connector_properties_typeProperties_serviceEndpoint": {
			"type": "string",
			"defaultValue": "https://ac2synapsedatalabstorage.blob.core.windows.net/"
		},
		"ac2-synapse-ws-dev-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://ac2synapsedatalabstorage.dfs.core.windows.net"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/ACLEDtoParquet')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "TransformData",
						"description": "This Builds the ACLED Data as a SQL DB",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "ParquetSource",
								"storeSettings": {
									"type": "AzureBlobFSReadSettings",
									"recursive": true,
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "ParquetReadSettings"
								}
							},
							"sink": {
								"type": "ParquetSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								},
								"formatSettings": {
									"type": "ParquetWriteSettings"
								}
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "ACLED_Integration",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "ACLED_Integration",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-11-01T14:56:39Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/ACLED_Integration')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/EORACountryRawToParquet')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "TransformRawData",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "AzureBlobFSReadSettings",
									"recursive": true,
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings"
								}
							},
							"sink": {
								"type": "ParquetSink",
								"storeSettings": {
									"type": "AzureBlobFSWriteSettings"
								},
								"formatSettings": {
									"type": "ParquetWriteSettings"
								}
							},
							"enableStaging": false,
							"translator": {
								"type": "TabularTranslator",
								"mappings": [
									{
										"source": {
											"name": "year",
											"type": "Int32",
											"physicalType": "String"
										},
										"sink": {
											"name": "year",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "gross_output",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "gross_output",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "gross_exports_intermediate",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "gross_exports_intermediate",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "gross_exports_final",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "gross_exports_final",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "gross_exports",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "gross_exports",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "gross_imports_intermediate",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "gross_imports_intermediate",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "gross_imports_final",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "gross_imports_final",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "gross_imports",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "gross_imports",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "gross_trade_balance",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "gross_trade_balance",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "gross_domestic_demand_intermediate",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "gross_domestic_demand_intermediate",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "gross_domestic_demand_final",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "gross_domestic_demand_final",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "exports_domesitc_value_added",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "exports_domesitc_value_added",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "exports_foreign_value_added",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "exports_foreign_value_added",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "exports_used_for_export_production",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "exports_used_for_export_production",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "value_added_exports",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "value_added_exports",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "foreign_value_added_domestic_demand",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "foreign_value_added_domestic_demand",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "export_value_added_one",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "export_value_added_one",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "export_value_added_two",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "export_value_added_two",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "export_value_added_three",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "export_value_added_three",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "domestic_value_added_four",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "domestic_value_added_four",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "domestic_value_added_five",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "domestic_value_added_five",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "domestic_value_added_six",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "domestic_value_added_six",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "gross_value_added",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "gross_value_added",
											"type": "String",
											"physicalType": "UTF8"
										}
									},
									{
										"source": {
											"name": "gross_derived_value_added",
											"type": "Decimal",
											"physicalType": "String"
										},
										"sink": {
											"name": "gross_derived_value_added",
											"type": "String",
											"physicalType": "UTF8"
										}
									}
								],
								"typeConversion": true,
								"typeConversionSettings": {
									"allowDataTruncation": true,
									"treatBooleanAsNumber": false
								}
							}
						},
						"inputs": [
							{
								"referenceName": "EORACountryStats",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "EORACountryStats2022Parquet",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-11-01T14:56:21Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/EORACountryStats')]",
				"[concat(variables('workspaceId'), '/datasets/EORACountryStats2022Parquet')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Pipeline 1')]",
			"type": "Microsoft.Synapse/workspaces/pipelines",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"activities": [
					{
						"name": "Copy data1",
						"type": "Copy",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"source": {
								"type": "DelimitedTextSource",
								"storeSettings": {
									"type": "AzureBlobStorageReadSettings",
									"recursive": true,
									"enablePartitionDiscovery": false
								},
								"formatSettings": {
									"type": "DelimitedTextReadSettings"
								}
							},
							"sink": {
								"type": "SqlPoolSink",
								"allowCopyCommand": true,
								"copyCommandSettings": {},
								"tableOption": "autoCreate"
							},
							"enableStaging": true,
							"stagingSettings": {
								"linkedServiceName": {
									"referenceName": "ac2-synapse-ws-dev-WorkspaceDefaultStorage",
									"type": "LinkedServiceReference"
								},
								"path": "acj802/Basic_Stats_(WB_Sourced)"
							}
						},
						"inputs": [
							{
								"referenceName": "DelimitedText1",
								"type": "DatasetReference",
								"parameters": {}
							}
						],
						"outputs": [
							{
								"referenceName": "SqlPoolTable1",
								"type": "DatasetReference",
								"parameters": {}
							}
						]
					}
				],
				"policy": {
					"elapsedTimeMetric": {}
				},
				"annotations": [],
				"lastPublishTime": "2024-11-05T15:01:59Z"
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/datasets/DelimitedText1')]",
				"[concat(variables('workspaceId'), '/datasets/SqlPoolTable1')]",
				"[concat(variables('workspaceId'), '/linkedServices/ac2-synapse-ws-dev-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ACLED_Integration')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "EORACountryStats",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "ACLED_2023-07-01-2023-12-31.csv",
						"fileSystem": "acj802"
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/EORACountryStats')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AzureSynapseAnalyticsTable1')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ac2-synapse-ws-dev-WorkspaceDefaultSqlServer",
					"type": "LinkedServiceReference",
					"parameters": {
						"DBName": "ac2j802database"
					}
				},
				"annotations": [],
				"type": "AzureSqlDWTable",
				"schema": [],
				"typeProperties": {
					"schema": "dbo",
					"table": "World Bank"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ac2-synapse-ws-dev-WorkspaceDefaultSqlServer')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Dataset')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "EORACountryStats",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "ACLED_2023-07-01-2023-12-31.csv",
						"fileSystem": "acj802"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/EORACountryStats')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/DelimitedText1')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "J802Container_World_Bank_Connector",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobStorageLocation",
						"fileName": "World_Bank_Indicators_Unpivoted.csv",
						"folderPath": "Basic_Stats_(WB_Sourced)",
						"container": "acj802"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "Country Name",
						"type": "String"
					},
					{
						"name": "Country Code",
						"type": "String"
					},
					{
						"name": "Year",
						"type": "String"
					},
					{
						"name": "Age dependency ratio (% of working-age population)",
						"type": "String"
					},
					{
						"name": "Agricultural land (% of land area)",
						"type": "String"
					},
					{
						"name": "Agricultural land (sq. km)",
						"type": "String"
					},
					{
						"name": "Agriculture, forestry, and fishing, value added (% of GDP)",
						"type": "String"
					},
					{
						"name": "Agriculture, forestry, and fishing, value added (current US$)",
						"type": "String"
					},
					{
						"name": "Arable land (% of land area)",
						"type": "String"
					},
					{
						"name": "Arable land (hectares)",
						"type": "String"
					},
					{
						"name": "Arms exports (SIPRI trend indicator values)",
						"type": "String"
					},
					{
						"name": "Arms imports (SIPRI trend indicator values)",
						"type": "String"
					},
					{
						"name": "Battle-related deaths (number of people)",
						"type": "String"
					},
					{
						"name": "Birth rate, crude (per 1,000 people)",
						"type": "String"
					},
					{
						"name": "Chemicals (% of value added in manufacturing)",
						"type": "String"
					},
					{
						"name": "Container port traffic (TEU: 20 foot equivalent units)",
						"type": "String"
					},
					{
						"name": "Current health expenditure (% of GDP)",
						"type": "String"
					},
					{
						"name": "Current health expenditure per capita (current US$)",
						"type": "String"
					},
					{
						"name": "Death rate, crude (per 1,000 people)",
						"type": "String"
					},
					{
						"name": "Electric power consumption (kWh per capita)",
						"type": "String"
					},
					{
						"name": "Energy imports, net (% of energy use)",
						"type": "String"
					},
					{
						"name": "Energy use (kg of oil equivalent per capita)",
						"type": "String"
					},
					{
						"name": "Exports of goods and services (% of GDP)",
						"type": "String"
					},
					{
						"name": "External debt stocks (% of GNI)",
						"type": "String"
					},
					{
						"name": "External debt stocks, total (DOD, current US$)",
						"type": "String"
					},
					{
						"name": "Fertility rate, total (births per woman)",
						"type": "String"
					},
					{
						"name": "Food, beverages and tobacco (% of value added in manufacturing)",
						"type": "String"
					},
					{
						"name": "Foreign direct investment, net (BoP, current US$)",
						"type": "String"
					},
					{
						"name": "Foreign direct investment, net inflows (BoP, current US$)",
						"type": "String"
					},
					{
						"name": "Forest area (% of land area)",
						"type": "String"
					},
					{
						"name": "Forest area (sq. km)",
						"type": "String"
					},
					{
						"name": "GDP (current US$)",
						"type": "String"
					},
					{
						"name": "GDP growth (annual %)",
						"type": "String"
					},
					{
						"name": "GDP per capita (current US$)",
						"type": "String"
					},
					{
						"name": "GDP per capita, PPP (current international $)",
						"type": "String"
					},
					{
						"name": "GDP, PPP (current international $)",
						"type": "String"
					},
					{
						"name": "GNI per capita, Atlas method (current US$)",
						"type": "String"
					},
					{
						"name": "GNI per capita, PPP (current international $)",
						"type": "String"
					},
					{
						"name": "GNI, Atlas method (current US$)",
						"type": "String"
					},
					{
						"name": "GNI, PPP (current international $)",
						"type": "String"
					},
					{
						"name": "Gini index",
						"type": "String"
					},
					{
						"name": "Gross capital formation (% of GDP)",
						"type": "String"
					},
					{
						"name": "Gross value added at basic prices (GVA) (current US$)",
						"type": "String"
					},
					{
						"name": "High-technology exports (% of manufactured exports)",
						"type": "String"
					},
					{
						"name": "Imports of goods and services (% of GDP)",
						"type": "String"
					},
					{
						"name": "Income share held by lowest 20%",
						"type": "String"
					},
					{
						"name": "Individuals using the Internet (% of population)",
						"type": "String"
					},
					{
						"name": "Industry (including construction), value added (% of GDP)",
						"type": "String"
					},
					{
						"name": "Industry (including construction), value added (current US$)",
						"type": "String"
					},
					{
						"name": "Inflation, GDP deflator (annual %)",
						"type": "String"
					},
					{
						"name": "Inflation, consumer prices (annual %)",
						"type": "String"
					},
					{
						"name": "Interest payments (% of revenue)",
						"type": "String"
					},
					{
						"name": "Internally displaced persons, new displacement associated with disasters (number of cases)",
						"type": "String"
					},
					{
						"name": "International migrant stock (% of population)",
						"type": "String"
					},
					{
						"name": "Labor force, total",
						"type": "String"
					},
					{
						"name": "Land area (sq. km)",
						"type": "String"
					},
					{
						"name": "Life expectancy at birth, total (years)",
						"type": "String"
					},
					{
						"name": "Literacy rate, adult total (% of people ages 15 and above)",
						"type": "String"
					},
					{
						"name": "Manufacturing, value added (% of GDP)",
						"type": "String"
					},
					{
						"name": "Manufacturing, value added (current US$)",
						"type": "String"
					},
					{
						"name": "Market capitalization of listed domestic companies (% of GDP)",
						"type": "String"
					},
					{
						"name": "Merchandise trade (% of GDP)",
						"type": "String"
					},
					{
						"name": "Military expenditure (% of GDP)",
						"type": "String"
					},
					{
						"name": "Military expenditure (current USD)",
						"type": "String"
					},
					{
						"name": "Mobile cellular subscriptions (per 100 people)",
						"type": "String"
					},
					{
						"name": "Mortality rate, under-5 (per 1,000 live births)",
						"type": "String"
					},
					{
						"name": "Net ODA received per capita (current US$)",
						"type": "String"
					},
					{
						"name": "Net migration",
						"type": "String"
					},
					{
						"name": "PM2.5 air pollution, population exposed to levels exceeding WHO guideline value (% of total)",
						"type": "String"
					},
					{
						"name": "Personal remittances, paid (current US$)",
						"type": "String"
					},
					{
						"name": "Personal remittances, received (% of GDP)",
						"type": "String"
					},
					{
						"name": "Population growth (annual %)",
						"type": "String"
					},
					{
						"name": "Population, female",
						"type": "String"
					},
					{
						"name": "Population, female (% of total population)",
						"type": "String"
					},
					{
						"name": "Population, male",
						"type": "String"
					},
					{
						"name": "Population, male (% of total population)",
						"type": "String"
					},
					{
						"name": "Population, total",
						"type": "String"
					},
					{
						"name": "Poverty headcount ratio at national poverty lines (% of population)",
						"type": "String"
					},
					{
						"name": "Prevalence of HIV, total (% of population ages 15-49)",
						"type": "String"
					},
					{
						"name": "Primary completion rate, total (% of relevant age group)",
						"type": "String"
					},
					{
						"name": "Rail lines (total route-km)",
						"type": "String"
					},
					{
						"name": "Railways, goods transported (million ton-km)",
						"type": "String"
					},
					{
						"name": "Railways, passengers carried (million passenger-km)",
						"type": "String"
					},
					{
						"name": "Revenue, excluding grants (% of GDP)",
						"type": "String"
					},
					{
						"name": "School enrollment, primary and secondary (gross), gender parity index (GPI)",
						"type": "String"
					},
					{
						"name": "School enrollment, secondary (% gross)",
						"type": "String"
					},
					{
						"name": "School enrollment, tertiary (% gross)",
						"type": "String"
					},
					{
						"name": "Services, value added (% of GDP)",
						"type": "String"
					},
					{
						"name": "Services, value added (current US$)",
						"type": "String"
					},
					{
						"name": "Start-up procedures to register a business (number)",
						"type": "String"
					},
					{
						"name": "Stocks traded, total value (% of GDP)",
						"type": "String"
					},
					{
						"name": "Surface area (sq. km)",
						"type": "String"
					},
					{
						"name": "Survival to age 65, female (% of cohort)",
						"type": "String"
					},
					{
						"name": "Survival to age 65, male (% of cohort)",
						"type": "String"
					},
					{
						"name": "Tax revenue (% of GDP)",
						"type": "String"
					},
					{
						"name": "Taxes on exports (% of tax revenue)",
						"type": "String"
					},
					{
						"name": "Total debt service (% of GNI)",
						"type": "String"
					},
					{
						"name": "Unemployment, total (% of total labor force) (national estimate)",
						"type": "String"
					},
					{
						"name": "Urban population (% of total population)",
						"type": "String"
					},
					{
						"name": "Water productivity, total (constant 2015 US$ GDP per cubic meter of total freshwater withdrawal)",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/J802Container_World_Bank_Connector')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/EORACountryStats')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ac2-synapse-ws-dev-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "DelimitedText",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "eora26-country-stats-2022.csv",
						"folderPath": "Eora26_Country_Statistics",
						"fileSystem": "acj802"
					},
					"columnDelimiter": ",",
					"escapeChar": "\\",
					"firstRowAsHeader": true,
					"quoteChar": "\""
				},
				"schema": [
					{
						"name": "gross-output",
						"type": "String"
					},
					{
						"name": "gross-exports-intermediate",
						"type": "String"
					},
					{
						"name": "gross-exports-final",
						"type": "String"
					},
					{
						"name": "gross-exports",
						"type": "String"
					},
					{
						"name": "gross-imports-intermediate",
						"type": "String"
					},
					{
						"name": "gross-imports-final",
						"type": "String"
					},
					{
						"name": "gross-imports",
						"type": "String"
					},
					{
						"name": "gross-trade-balance",
						"type": "String"
					},
					{
						"name": "gross-domestic-demand-intermediate",
						"type": "String"
					},
					{
						"name": "gross-domestic-demand-final",
						"type": "String"
					},
					{
						"name": "exports-domesitc-value-added",
						"type": "String"
					},
					{
						"name": "exports-foreign-value-added",
						"type": "String"
					},
					{
						"name": "exports-used-for-export-production",
						"type": "String"
					},
					{
						"name": "value-added-exports",
						"type": "String"
					},
					{
						"name": "foreign-value-added-domestic-demand",
						"type": "String"
					},
					{
						"name": "export-value-added-one",
						"type": "String"
					},
					{
						"name": "export-value-added-two",
						"type": "String"
					},
					{
						"name": "export-value-added-three",
						"type": "String"
					},
					{
						"name": "domestic-value-added-four",
						"type": "String"
					},
					{
						"name": "domestic-value-added-five",
						"type": "String"
					},
					{
						"name": "domestic-value-added-six",
						"type": "String"
					},
					{
						"name": "gross-value-added",
						"type": "String"
					},
					{
						"name": "gross-derived-value-added",
						"type": "String"
					}
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ac2-synapse-ws-dev-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/EORACountryStats2022Parquet')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"linkedServiceName": {
					"referenceName": "ac2-synapse-ws-dev-WorkspaceDefaultStorage",
					"type": "LinkedServiceReference"
				},
				"annotations": [],
				"type": "Parquet",
				"typeProperties": {
					"location": {
						"type": "AzureBlobFSLocation",
						"fileName": "eora-country-stats-2022.parquet",
						"folderPath": "parquet",
						"fileSystem": "acj802"
					},
					"compressionCodec": "snappy"
				},
				"schema": []
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/linkedServices/ac2-synapse-ws-dev-WorkspaceDefaultStorage')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SqlPoolTable1')]",
			"type": "Microsoft.Synapse/workspaces/datasets",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "SqlPoolTable",
				"schema": [],
				"typeProperties": {
					"schema": "dbo",
					"table": "World_Bank"
				},
				"sqlPool": {
					"referenceName": "ac2sqldwdev",
					"type": "SqlPoolReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/sqlPools/ac2sqldwdev')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/CosmosDbNoSql1')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "CosmosDb",
				"typeProperties": {
					"connectionString": "[parameters('CosmosDbNoSql1_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/CosmosGraphTest')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "CosmosDb",
				"typeProperties": {
					"connectionString": "[parameters('CosmosGraphTest_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/EORACountryStats')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('EORACountryStats_properties_typeProperties_url')]",
					"accountKey": {
						"type": "SecureString",
						"value": "[parameters('EORACountryStats_accountKey')]"
					}
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/GremlinTest')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "CosmosDb",
				"typeProperties": {
					"connectionString": "[parameters('GremlinTest_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/J802Container_World_Bank_Connector')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobStorage",
				"typeProperties": {
					"serviceEndpoint": "[parameters('J802Container_World_Bank_Connector_properties_typeProperties_serviceEndpoint')]",
					"accountKind": "StorageV2"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ac2-synapse-ws-dev-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('ac2-synapse-ws-dev-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ac2-synapse-ws-dev-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('ac2-synapse-ws-dev-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				},
				"managedVirtualNetwork": {
					"type": "ManagedVirtualNetworkReference",
					"referenceName": "default"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/managedVirtualNetworks/default')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/default')]",
			"type": "Microsoft.Synapse/workspaces/managedVirtualNetworks",
			"apiVersion": "2019-06-01-preview",
			"properties": {},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ACLED_View')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE VIEW ACLED_Trial AS\nSELECT\n    event_id_cnty,\n    CONVERT(DATE, event_date, 113) AS event_date,\n    year,\n    time_precision,\n    disorder_type,\n    event_type,\n    sub_event_type,\n    actor1,\n    assoc_actor_1,\n    inter1,\n    actor2,\n    assoc_actor_2,\n    inter2,\n    interaction,\n    civilian_targeting,\n    iso,\n    region,\n    country,\n    admin1,\n    admin2,\n    admin3,\n    location,\n    latitude,\n    longitude,\n    geo_precision,\n    source,\n    source_scale,\n    fatalities,\n    notes,\n    tags,\n    timestamp\n\nFROM\n    OPENROWSET(\n        BULK 'https://ac2synapsedatalabstorage.dfs.core.windows.net/acj802/ACLED_2023-07-01-2023-12-31.csv',\n        FORMAT = 'CSV',\n        FIRSTROW = 2,\n        PARSER_VERSION = '2.0'\n    ) WITH (\n        event_id_cnty VARCHAR(255),\n        event_date VARCHAR(8000),\n        year INT,\n        time_precision INT,\n        disorder_type VARCHAR(255),\n        event_type VARCHAR(255),\n        sub_event_type VARCHAR(255),\n        actor1 VARCHAR(255),\n        assoc_actor_1 VARCHAR(8000),\n        inter1 INT,\n        actor2 VARCHAR(255),\n        assoc_actor_2 VARCHAR(8000),\n        inter2 INT,\n        interaction INT,\n        civilian_targeting VARCHAR(255),\n        iso INT,\n        region VARCHAR(255),\n        country VARCHAR(255),\n        admin1 VARCHAR(255),\n        admin2 VARCHAR(255),\n        admin3 VARCHAR(255),\n        location VARCHAR(255),\n        latitude FLOAT,\n        longitude FLOAT,\n        geo_precision INT,\n        source VARCHAR(8000),\n        source_scale VARCHAR(255),\n        notes VARCHAR(8000),\n        fatalities INT,\n        tags VARCHAR(255),\n        timestamp VARCHAR(8000)\n    ) AS [result];\nGO\n",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "master",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/EORA_Value_Add')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE VIEW EORA_ValueAdd AS\nSELECT\n\n    Importer,\n    Exporter,\n    Sector,\n    [Year],\t\n    [Value Added],\n    [Sender Input to Receiver]\n\nFROM\n    OPENROWSET(\n        BULK 'https://ac2synapsedatalabstorage.dfs.core.windows.net/acj802/EORA26/LBY_ValueAdd_1990_2022.csv',\n        FORMAT = 'CSV',\n        FIRSTROW = 2,\n        PARSER_VERSION = '2.0'\n    ) WITH (\n        Importer VARCHAR(255) COLLATE Latin1_General_100_CI_AI_SC_UTF8,\n        Exporter VARCHAR(255) COLLATE Latin1_General_100_CI_AI_SC_UTF8,\n        Sector VARCHAR(255) COLLATE Latin1_General_100_CI_AI_SC_UTF8,\n        [Year] INT,\n        [Value Added] FLOAT,\n        [Sender Input to Receiver] FLOAT\n    ) AS [result];\nGO",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "ac2j802database",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL script 1')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "select  a;;from World_Bank_Indicators",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "ac2j802database",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQL script 3')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "--CREATE USER [Steven.B.Masschelin.USA@missionpartners.us] FROM EXTERNAL PROVIDER;\nALTER ROLE db_owner ADD MEMBER [Steven.B.Masschelin.USA@missionpartners.us];\n\n ",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "ac2j802database",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Utility')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "SELECT *,\n       TRY_CAST(Value AS FLOAT) AS Value_Float\nFROM World_Bank_Indicators;",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "ac2j802database",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorldBankWide_View')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "DECLARE @cols AS NVARCHAR(MAX),\n        @query AS NVARCHAR(MAX);\n\n-- Get the distinct series codes\nSELECT @cols = STRING_AGG(QUOTENAME([Series Code]), ',') \n               FROM (SELECT DISTINCT [Series Code] FROM World_Bank_Indicators) AS SeriesCodes;\n\n-- Construct the dynamic SQL query\nSET @query = '\nSELECT \n    Country,\n    [Country Code],\n    Year,\n    ' + @cols + '\nFROM \n    (SELECT \n        Country, \n        [Country Code], \n        Year, \n        [Series Code], \n        Value\n     FROM \n        World_Bank_Indicators) AS SourceTable\nPIVOT\n(\n    MAX(Value)\n    FOR [Series Code] IN (' + @cols + ')\n) AS PivotTable';\n\n-- Execute the dynamic SQL query\nEXEC sp_executesql @query;",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "ac2j802database",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/World_Bank_Indicators')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE VIEW World_Bank_Indicators_2 AS\nSELECT\n\n    [Series Name],\n    [Series Code],\n    Country,\n    [Country Code],\t\n    [Year],\n    Value\n\nFROM\n    OPENROWSET(\n        BULK 'https://ac2synapsedatalabstorage.dfs.core.windows.net/acj802/Basic_Stats_(WB_Sourced)/World_Bank_Indicators.csv',\n        FORMAT = 'CSV',\n        FIRSTROW = 2,\n        PARSER_VERSION = '2.0'\n    ) WITH (\n        [Series Name] VARCHAR(255) COLLATE Latin1_General_100_CI_AI_SC_UTF8,\n        [Series Code] VARCHAR(255) COLLATE Latin1_General_100_CI_AI_SC_UTF8,\n        Country VARCHAR(255) COLLATE Latin1_General_100_CI_AI_SC_UTF8,\n        [Country Code] VARCHAR(255) COLLATE Latin1_General_100_CI_AI_SC_UTF8,\n        [Year] INT,\n        Value VARCHAR (255) COLLATE Latin1_General_100_CI_AI_SC_UTF8\n    ) AS [result];\nGO",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "ac2j802database",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/World_Bank_Indicators_Unpivoted')]",
			"type": "Microsoft.Synapse/workspaces/sqlscripts",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"content": {
					"query": "CREATE VIEW World_Bank_Indicators_Unpivoted AS\nSELECT\n    Country_Name,\n    Country_Code,\n    Year,\n    Age_dependency_ratio_Percent_of_working_age_population,\n    Agricultural_land_Percent_of_land_area,\n    Agricultural_land_sq_km,\n    Agriculture_forestry_and_fishing_value_added_Percent_of_GDP,\n    Agriculture_forestry_and_fishing_value_added_current_USD,\n    Arable_land_Percent_of_land_area,\n    Arable_land_hectares,\n    Arms_exports_SIPRI_trend_indicator_values,\n    Arms_imports_SIPRI_trend_indicator_values,\n    Battle_related_deaths_number_of_people,\n    Birth_rate_crude_per_1000_people,\n    Chemicals_Percent_of_value_added_in_manufacturing,\n    Container_port_traffic_TEU_20_foot_equivalent_units,\n    Current_health_expenditure_Percent_of_GDP,\n    Current_health_expenditure_per_capita_current_USD,\n    Death_rate_crude_per_1000_people,\n    Electric_power_consumption_kWh_per_capita,\n    Energy_imports_net_Percent_of_energy_use,\n    Energy_use_kg_of_oil_equivalent_per_capita,\n    Exports_of_goods_and_services_Percent_of_GDP,\n    External_debt_stocks_Percent_of_GNI,\n    External_debt_stocks_total_DOD_current_USD,\n    Fertility_rate_total_births_per_woman,\n    Food_beverages_and_tobacco_Percent_of_value_added_in_manufacturing,\n    Foreign_direct_investment_net_BoP_current_USD,\n    Foreign_direct_investment_net_inflows_BoP_current_USD,\n    Forest_area_Percent_of_land_area,\n    Forest_area_sq_km,\n    GDP_current_USD,\n    GDP_growth_annual_Percent,\n    GDP_per_capita_current_USD,\n    GDP_per_capita_PPP_current_international_dollar,\n    GDP_PPP_current_international_dollar,\n    GNI_per_capita_Atlas_method_current_USD,\n    GNI_per_capita_PPP_current_international_dollar,\n    GNI_Atlas_method_current_USD,\n    GNI_PPP_current_international_dollar,\n    Gini_index,\n    Gross_capital_formation_Percent_of_GDP,\n    Gross_value_added_at_basic_prices_GVA_current_USD,\n    High_technology_exports_Percent_of_manufactured_exports,\n    Imports_of_goods_and_services_Percent_of_GDP,\n    Income_share_held_by_lowest_20Percent,\n    Individuals_using_the_Internet_Percent_of_population,\n    Industry_including_construction_value_added_Percent_of_GDP,\n    Industry_including_construction_value_added_current_USD,\n    Inflation_GDP_deflator_annual_Percent,\n    Inflation_consumer_prices_annual_Percent,\n    Interest_payments_Percent_of_revenue,\n    Internally_displaced_persons_new_displacement_associated_with_disasters_number_of_cases,\n    International_migrant_stock_Percent_of_population,\n    Labor_force_total,\n    Land_area_sq_km,\n    Life_expectancy_at_birth_total_years,\n    Literacy_rate_adult_total_Percent_of_people_ages_15_and_above,\n    Manufacturing_value_added_Percent_of_GDP,\n    Manufacturing_value_added_current_USD,\n    Market_capitalization_of_listed_domestic_companies_Percent_of_GDP,\n    Merchandise_trade_Percent_of_GDP,\n    Military_expenditure_Percent_of_GDP,\n    Military_expenditure_current_USD,\n    Mobile_cellular_subscriptions_per_100_people,\n    Mortality_rate_under_5_per_1000_live_births,\n    Net_ODA_received_per_capita_current_USD,\n    Net_migration,\n    PM2decimal5_air_pollution_population_exposed_to_levels_exceeding_WHO_guideline_value_Percent_of_total,\n    Personal_remittances_paid_current_USD,\n    Personal_remittances_received_Percent_of_GDP,\n    Population_growth_annual_Percent,\n    Population_female,\n    Population_female_Percent_of_total_population,\n    Population_male,\n    Population_male_Percent_of_total_population,\n    Population_total,\n    Poverty_headcount_ratio_at_national_poverty_lines_Percent_of_population,\n    Prevalence_of_HIV_total_Percent_of_population_ages_15_49,\n    Primary_completion_rate_total_Percent_of_relevant_age_group,\n    Rail_lines_total_route_km,\n    Railways_goods_transported_million_ton_km,\n    Railways_passengers_carried_million_passenger_km,\n    Revenue_excluding_grants_Percent_of_GDP,\n    School_enrollment_primary_and_secondary_gross_gender_parity_index_GPI,\n    School_enrollment_secondary_Percent_gross,\n    School_enrollment_tertiary_Percent_gross,\n    Services_value_added_Percent_of_GDP,\n    Services_value_added_current_USD,\n    Start_up_procedures_to_register_a_business_number,\n    Stocks_traded_total_value_Percent_of_GDP,\n    Surface_area_sq_km,\n    Survival_to_age_65_female_Percent_of_cohort,\n    Survival_to_age_65_male_Percent_of_cohort,\n    Tax_revenue_Percent_of_GDP,\n    Taxes_on_exports_Percent_of_tax_revenue,\n    Total_debt_service_Percent_of_GNI,\n    Unemployment_total_Percent_of_total_labor_force_national_estimate,\n    Urban_population_Percent_of_total_population,\n    Water_productivity_total_constant_2015_USD_GDP_per_cubic_meter_of_total_freshwater_withdrawal\n\nFROM\n    OPENROWSET(\n        BULK 'https://ac2synapsedatalabstorage.dfs.core.windows.net/acj802/Basic_Stats_(WB_Sourced)/World_Bank_Indicators_Unpivoted.csv',\n        FORMAT = 'CSV',\n        FIRSTROW = 2,\n        FIELDTERMINATOR = ',',\n        CODEPAGE = '65001', -- UTF-8 encoding\n        PARSER_VERSION = '2.0'\n    ) WITH (\n            Country_Name VARCHAR(255) COLLATE Latin1_General_100_CI_AI_SC_UTF8,\n            Country_Code VARCHAR(255) COLLATE Latin1_General_100_CI_AI_SC_UTF8,\n            Year NUMERIC,\n            Age_dependency_ratio_Percent_of_working_age_population NUMERIC,\n            Agricultural_land_Percent_of_land_area NUMERIC,\n            Agricultural_land_sq_km NUMERIC,\n            Agriculture_forestry_and_fishing_value_added_Percent_of_GDP NUMERIC,\n            Agriculture_forestry_and_fishing_value_added_current_USD NUMERIC,\n            Arable_land_Percent_of_land_area NUMERIC,\n            Arable_land_hectares NUMERIC,\n            Arms_exports_SIPRI_trend_indicator_values NUMERIC,\n            Arms_imports_SIPRI_trend_indicator_values NUMERIC,\n            Battle_related_deaths_number_of_people NUMERIC,\n            Birth_rate_crude_per_1000_people NUMERIC,\n            Chemicals_Percent_of_value_added_in_manufacturing NUMERIC,\n            Container_port_traffic_TEU_20_foot_equivalent_units NUMERIC,\n            Current_health_expenditure_Percent_of_GDP NUMERIC,\n            Current_health_expenditure_per_capita_current_USD NUMERIC,\n            Death_rate_crude_per_1000_people NUMERIC,\n            Electric_power_consumption_kWh_per_capita NUMERIC,\n            Energy_imports_net_Percent_of_energy_use NUMERIC,\n            Energy_use_kg_of_oil_equivalent_per_capita NUMERIC,\n            Exports_of_goods_and_services_Percent_of_GDP NUMERIC,\n            External_debt_stocks_Percent_of_GNI NUMERIC,\n            External_debt_stocks_total_DOD_current_USD NUMERIC,\n            Fertility_rate_total_births_per_woman NUMERIC,\n            Food_beverages_and_tobacco_Percent_of_value_added_in_manufacturing NUMERIC,\n            Foreign_direct_investment_net_BoP_current_USD NUMERIC,\n            Foreign_direct_investment_net_inflows_BoP_current_USD NUMERIC,\n            Forest_area_Percent_of_land_area NUMERIC,\n            Forest_area_sq_km NUMERIC,\n            GDP_current_USD NUMERIC,\n            GDP_growth_annual_Percent NUMERIC,\n            GDP_per_capita_current_USD NUMERIC,\n            GDP_per_capita_PPP_current_international_dollar NUMERIC,\n            GDP_PPP_current_international_dollar NUMERIC,\n            GNI_per_capita_Atlas_method_current_USD NUMERIC,\n            GNI_per_capita_PPP_current_international_dollar NUMERIC,\n            GNI_Atlas_method_current_USD NUMERIC,\n            GNI_PPP_current_international_dollar NUMERIC,\n            Gini_index NUMERIC,\n            Gross_capital_formation_Percent_of_GDP NUMERIC,\n            Gross_value_added_at_basic_prices_GVA_current_USD NUMERIC,\n            High_technology_exports_Percent_of_manufactured_exports NUMERIC,\n            Imports_of_goods_and_services_Percent_of_GDP NUMERIC,\n            Income_share_held_by_lowest_20Percent NUMERIC,\n            Individuals_using_the_Internet_Percent_of_population NUMERIC,\n            Industry_including_construction_value_added_Percent_of_GDP NUMERIC,\n            Industry_including_construction_value_added_current_USD NUMERIC,\n            Inflation_GDP_deflator_annual_Percent NUMERIC,\n            Inflation_consumer_prices_annual_Percent NUMERIC,\n            Interest_payments_Percent_of_revenue NUMERIC,\n            Internally_displaced_persons_new_displacement_associated_with_disasters_number_of_cases NUMERIC,\n            International_migrant_stock_Percent_of_population NUMERIC,\n            Labor_force_total NUMERIC,\n            Land_area_sq_km NUMERIC,\n            Life_expectancy_at_birth_total_years NUMERIC,\n            Literacy_rate_adult_total_Percent_of_people_ages_15_and_above NUMERIC,\n            Manufacturing_value_added_Percent_of_GDP NUMERIC,\n            Manufacturing_value_added_current_USD NUMERIC,\n            Market_capitalization_of_listed_domestic_companies_Percent_of_GDP NUMERIC,\n            Merchandise_trade_Percent_of_GDP NUMERIC,\n            Military_expenditure_Percent_of_GDP NUMERIC,\n            Military_expenditure_current_USD NUMERIC,\n            Mobile_cellular_subscriptions_per_100_people NUMERIC,\n            Mortality_rate_under_5_per_1000_live_births NUMERIC,\n            Net_ODA_received_per_capita_current_USD NUMERIC,\n            Net_migration NUMERIC,\n            PM2decimal5_air_pollution_population_exposed_to_levels_exceeding_WHO_guideline_value_Percent_of_total NUMERIC,\n            Personal_remittances_paid_current_USD NUMERIC,\n            Personal_remittances_received_Percent_of_GDP NUMERIC,\n            Population_growth_annual_Percent NUMERIC,\n            Population_female NUMERIC,\n            Population_female_Percent_of_total_population NUMERIC,\n            Population_male NUMERIC,\n            Population_male_Percent_of_total_population NUMERIC,\n            Population_total NUMERIC,\n            Poverty_headcount_ratio_at_national_poverty_lines_Percent_of_population NUMERIC,\n            Prevalence_of_HIV_total_Percent_of_population_ages_15_49 NUMERIC,\n            Primary_completion_rate_total_Percent_of_relevant_age_group NUMERIC,\n            Rail_lines_total_route_km NUMERIC,\n            Railways_goods_transported_million_ton_km NUMERIC,\n            Railways_passengers_carried_million_passenger_km NUMERIC,\n            Revenue_excluding_grants_Percent_of_GDP NUMERIC,\n            School_enrollment_primary_and_secondary_gross_gender_parity_index_GPI NUMERIC,\n            School_enrollment_secondary_Percent_gross NUMERIC,\n            School_enrollment_tertiary_Percent_gross NUMERIC,\n            Services_value_added_Percent_of_GDP NUMERIC,\n            Services_value_added_current_USD NUMERIC,\n            Start_up_procedures_to_register_a_business_number NUMERIC,\n            Stocks_traded_total_value_Percent_of_GDP NUMERIC,\n            Surface_area_sq_km NUMERIC,\n            Survival_to_age_65_female_Percent_of_cohort NUMERIC,\n            Survival_to_age_65_male_Percent_of_cohort NUMERIC,\n            Tax_revenue_Percent_of_GDP NUMERIC,\n            Taxes_on_exports_Percent_of_tax_revenue NUMERIC,\n            Total_debt_service_Percent_of_GNI NUMERIC,\n            Unemployment_total_Percent_of_total_labor_force_national_estimate NUMERIC,\n            Urban_population_Percent_of_total_population NUMERIC,\n            Water_productivity_total_constant_2015_USD_GDP_per_cubic_meter_of_total_freshwater_withdrawal NUMERIC\n    ) AS [result];\nGO",
					"metadata": {
						"language": "sql"
					},
					"currentConnection": {
						"databaseName": "ac2j802database",
						"poolName": "Built-in"
					},
					"resultLimit": 5000
				},
				"type": "SqlQuery"
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AFRICOM_Instability_Index')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ac2sparkpooldev",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "c2fe799f-7830-465d-8b81-6c59357be223"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Synapse/workspaces/ac2-synapse-ws-dev/bigDataPools/ac2sparkpooldev",
						"name": "ac2sparkpooldev",
						"type": "Spark",
						"endpoint": "https://ac2-synapse-ws-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ac2sparkpooldev",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"automaticScaleJobs": false
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#### LTC Cardy Moten III, ACJ802, cardy.moten3.mil@mail.mil \n",
							"#### 19 May 2025"
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Purpose\n",
							"\n",
							"This notebook provides the methodology for extracting the requisite datasets to build and subsequently analyze the [AFRICOM Instability Risk Index (IRI) Assessment](https://dod365.sharepoint-mil.us/:w:/r/teams/AFRICOM-AFRICOMJ802Collaboration/Shared%20Documents/General/Campaign%20Assessment%20Literature/3-Analysis%20and%20Assessment/Risk%20Analysis/Africa%20Instability%20Risk%20Assessment_5MAY2025.docx?d=wc2e7e9be66ea4c1b9e77a30f729d54ce&csf=1&web=1&e=XXlM2m) [1]. The proponent for the use of the index and the methodology to create the index is the USAFRICOM J54."
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Index Overview\n",
							"\n",
							"The IRI is a composite index that is built from 30 indicators across two domains (Social Cohesion and Governance Capacity) developed by the IRI assessmeent team [1]. Each indicator is converted from its raw format to a rescaled score between 0 to 2 summarized by the table below.\n",
							"\n",
							"| Score | Interpretation            |\n",
							"|-------|---------------------------|\n",
							"| 0     | low instability risk      |\n",
							"| 1     | moderate instability risk |\n",
							"| 2     | high instability risk     |\n",
							"\n",
							"Based on this method a country can have a score ranging from 0 - 60 with lower scores representing more stability. To ensure consistency with using this index with across countries when analyzing with regards to domains across time, the scores are nomalized again to a 0 - 1 ratio value. This conversion is simply done by the following formula $$normalized\\_score = \\frac{current\\_score}{max\\_score}$$\n",
							"\n",
							"## Methodology Addition\n",
							"\n",
							"In addition to the coversion of the raw data, we will also produce estimates out to the current year of analysis since a few datasets stop their collection prior to the current year of analysis. In these cases we will employ Autoregressive Integrated Moving Average (ARIMA) estimates along with building a sample distribution using Metalogs [2] [3].\n",
							""
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Packages"
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Installs"
						]
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"%pip install pandas_datareader"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Imports"
						]
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"import pandas as pd\n",
							"import numpy as np\n",
							"import requests\n",
							"import pandas_datareader.wb as wb\n",
							"from notebookutils import mssparkutils\n",
							"from pyspark.sql import SparkSession\n",
							"from pyspark.sql.functions import col, year"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Helper Functions"
						]
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"def check_country_names(list_a, list_b):\n",
							"    set_a = set(list_a)\n",
							"    set_b = set(list_b)\n",
							"    print(set_a.difference(set_b))\n",
							"\n",
							"def capture_named_args(**kwargs):\n",
							"    return list(kwargs.keys())\n",
							"\n",
							"def create_domain_index(country_iso, df_1, df_2, df_3, df_4, df_5):\n",
							"    arg_names = capture_named_args(\n",
							"        country_iso=country_iso,\n",
							"        df_1=df_1,\n",
							"         df_2=df_2,\n",
							"         df_3=df_3,\n",
							"         df_4=df_4,\n",
							"         df_5=df_5\n",
							"    )\n",
							"\n",
							"    def extract_scores(df, df_name):\n",
							"        if country_iso not in df['iso3'].values:\n",
							"            raise ValueError(f\"{country_iso} not found. Check {df_name} data.\")\n",
							"        return df[df['iso3'] == country_iso][['iso3', 'name', 'year'] + [col for col in df.columns if col.endswith('_score')]]\n",
							"\n",
							"    df_1_score = extract_scores(df_1, arg_names[1])\n",
							"    df_2_score = extract_scores(df_2, arg_names[2])\n",
							"    df_3_score = extract_scores(df_3, arg_names[3])\n",
							"    df_4_score = extract_scores(df_4, arg_names[4])\n",
							"    df_5_score = extract_scores(df_5, arg_names[5])\n",
							"\n",
							"    # Merge all dataframes on 'year'\n",
							"    index_df = df_1_score.merge(df_2_score, on='year', suffixes=('', '_df2')) \\\n",
							"                         .merge(df_3_score, on='year', suffixes=('', '_df3')) \\\n",
							"                         .merge(df_4_score, on='year', suffixes=('', '_df4')) \\\n",
							"                         .merge(df_5_score, on='year', suffixes=('', '_df5'))\n",
							"\n",
							"    print(\"Current Index DF\")\n",
							"    print(index_df)\n",
							"    # Rename columns to match expected output\n",
							"    index_df.rename(columns={'iso3': 'iso3.x', 'name': 'name.x'}, inplace=True)\n",
							"\n",
							"    # Identify score columns\n",
							"    score_cols = [col for col in index_df.columns if col.endswith('_score')]\n",
							"    \n",
							"\n",
							"    # Interpolate missing values\n",
							"    for col in score_cols:\n",
							"        if index_df[col].isnull().any():\n",
							"            index_df[col] = index_df[col].interpolate(method='linear', limit_direction='both')\n",
							"\n",
							"    # Calculate domain score\n",
							"    index_df['domain_score'] = index_df[score_cols].sum(axis=1, skipna=True) / 10\n",
							"    index_df = index_df[['iso3.x', 'name.x', 'year', 'domain_score']]\n",
							"\n",
							"    return index_df"
						],
						"outputs": [],
						"execution_count": 51
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Gather Data\n",
							"\n",
							"USAFRICOM should collect new data on an annual basis since most of these data sources are updated on that cycle.\n",
							"\n",
							"## Social Cohesion Data\n",
							"\n",
							"| Data Source | URL | Indicator Domain | Notes |\n",
							"|-------------|-----|------------------|-------|\n",
							"| Notre Dame Global Adaptation Initiative (ND-GAIN) [4]    | <https://gain.nd.edu/our-work/country-index/download-data/> | Socioenvironmental Pressures | Annual Update |\n",
							"| The Commonwealth - Global Youth Index [5]    | <https://cwapiservices.thecommonwealth.org/index.html> | Socioenvironmental Pressures | Annual Update |\n",
							"| World Bank Literacy Rates [6]    | <https://data.worldbank.org/indicator/SE.ADT.LITR.ZS?most_recent_value_desc=true> | Socioenvironmental Pressures | Replacement for the United Nations Human Development Report -Education Index Score |\n",
							"| Fragile State IndexHuman Flight and Brain Drain score [7]    | <https://fragilestatesindex.org/indicators/e3/> | Socioenvironmental Pressures | Annual Update |\n",
							"| Fragile State IndexDemographic Pressures score [7]   | <https://fragilestatesindex.org/indicators/s1/> | Socioenvironmental Pressures | Annual Update |\n",
							"\n",
							"Table of IRI Social Cohesion Datasources\n",
							""
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Socioenvironmental Pressures Domain"
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### ND-Gain\n",
							"\n",
							"This dataset comes in a zip file containing multiple file. The required file to build the IRI is called `resources/gain/gain.csv`. After downloading the file, I renamed it to `nd_gain_country_index_2024.csv`."
						]
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"\n",
							"# Define the column names\n",
							"iri_col_names = [\"iso3\", \"name\", \"year\", \"value\"]\n",
							"\n",
							"# Read the CSV files\n",
							"environmental_adaptation_path = 'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/AFRICOM_Instability_Index/nd_gain_country_index_2024.csv'\n",
							"african_countries_path = 'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/AFRICOM_Instability_Index/African_Countries_ISO3.csv'\n",
							"environmental_adaptation = pd.read_csv(environmental_adaptation_path)\n",
							"\n",
							"african_countries = pd.read_csv(african_countries_path)\n",
							"african_countries.loc[african_countries['country'] == \"Cte d'Ivoire\", 'country'] = \"Cote d'Ivoire\"\n",
							"\n",
							"# Filter for African countries\n",
							"environmental_adaptation = environmental_adaptation[environmental_adaptation['ISO3'].isin(african_countries['iso3'])]\n",
							"environmental_adaptation.loc[environmental_adaptation['Name'] == \"Congo\", 'Name'] = \"Republic of the Congo\"\n",
							"environmental_adaptation.loc[environmental_adaptation['Name'] == \"Congo, the Democratic Republic o\", 'Name'] = \"Democratic Republic of the Congo\"\n",
							"environmental_adaptation.loc[environmental_adaptation['Name'] == \"Cape Verde\", 'Name'] = \"Cabo Verde\"\n",
							"environmental_adaptation.loc[environmental_adaptation['Name'] == \"Libyan Arab Jamahiriya\", 'Name'] = \"Libya\"\n",
							"environmental_adaptation.loc[environmental_adaptation['Name'] == \"Swaziland\", 'Name'] = \"Eswatini\"\n",
							"environmental_adaptation.loc[environmental_adaptation['Name'] == \"Tanzania, United Republic of\", 'Name'] = \"Tanzania\"\n",
							"\n",
							"\n",
							"# Reshape the data from wide to long format\n",
							"environmental_adaptation = environmental_adaptation.melt(\n",
							"    id_vars=[\"ISO3\", \"Name\"],\n",
							"    value_vars=[str(year) for year in range(1995, 2022 + 1)],\n",
							"    var_name=\"year\",\n",
							"    value_name=\"value\"\n",
							")\n",
							"\n",
							"# Rename columns\n",
							"environmental_adaptation.columns = iri_col_names\n",
							"\n",
							"# Compute 'adaptation_score'\n",
							"environmental_adaptation['adaptation_score'] = 2 - (2 * environmental_adaptation['value'] / 100)\n",
							"\n",
							"# Convert 'year' to numeric\n",
							"environmental_adaptation['year'] = pd.to_numeric(environmental_adaptation['year'])\n",
							"\n",
							"# Filter for years >= 2000\n",
							"environmental_adaptation = environmental_adaptation[environmental_adaptation['year'] >= 2000]\n",
							"\n",
							"print(environmental_adaptation.head())"
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"check_country_names(environmental_adaptation['name'], african_countries['country']) #used to check for spelling differences in country name sets"
						],
						"outputs": [],
						"execution_count": 21
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Commonwealth Youth Index"
						]
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"#Read in json file\n",
							"\n",
							"url = \"https://cwapiservices.thecommonwealth.org/CountryData/GetAllYDI_index_scores\"\n",
							"headers = {\"Accept\": \"application/json\"}\n",
							"\n",
							"response = requests.get(url, headers=headers)\n",
							"data = response.json()\n",
							"\n",
							"\n",
							"# Convert to DataFrame\n",
							"youth_underdevelopment = pd.json_normalize(data)\n",
							"youth_underdevelopment.loc[youth_underdevelopment['country'] == 'Cte dIvoire', 'country'] = \"Cote d'Ivoire\"\n",
							"youth_underdevelopment.loc[youth_underdevelopment['country'] == 'So Tom & Prncipe', 'country'] = \"Sao Tome and Principe\"\n",
							"youth_underdevelopment.loc[youth_underdevelopment['country'] =='Congo - Kinshasa', 'country'] = \"Democratic Republic of the Congo\"\n",
							"youth_underdevelopment.loc[youth_underdevelopment['country'] == 'Congo - Brazzaville', 'country'] = \"Republic of the Congo\"\n",
							"youth_underdevelopment.loc[youth_underdevelopment['country'] == 'Cape Verde', 'country'] = \"Cabo Verde\"\n",
							"\n",
							"# Filter for African countries\n",
							"youth_underdevelopment = youth_underdevelopment[youth_underdevelopment['iD_0'].isin(african_countries['iso3'])]\n",
							"\n",
							"#Select iD_0, country, year, overall_score\n",
							"youth_underdevelopment = youth_underdevelopment[['iD_0', 'country', 'year', 'overall_score']]\n",
							"\n",
							"# Rename columns\n",
							"youth_underdevelopment.columns = iri_col_names\n",
							"\n",
							"# Compute 'underdevelopment_score'\n",
							"youth_underdevelopment['underdevelopment_score'] = 2 - (2 * youth_underdevelopment['value'])\n",
							"\n",
							"# Convert 'year' to numeric\n",
							"youth_underdevelopment['year'] = pd.to_numeric(youth_underdevelopment['year'])\n",
							"\n",
							"# Filter for years >= 2000\n",
							"youth_underdevelopment = youth_underdevelopment[youth_underdevelopment['year'] >= 2000]\n",
							"\n",
							"print(youth_underdevelopment.head())\n",
							"\n",
							""
						],
						"outputs": [],
						"execution_count": 23
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"check_country_names(youth_underdevelopment['name'], african_countries['country'])"
						],
						"outputs": [],
						"execution_count": 24
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Illiteracy"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Read in Data\n",
							"\n",
							"# Define the indicator and countries (or use 'all')\n",
							"indicator = 'SE.ADT.LITR.ZS'\n",
							"\n",
							"# Fetch data for all countries\n",
							"illiteracy = wb.download(indicator=indicator, country='all', start=2000, end=2023)\n",
							"illiteracy = illiteracy.reset_index()\n",
							"illiteracy.loc[illiteracy['country'] == 'Congo, Dem. Rep.', 'country'] = 'Democratic Republic of the Congo'\n",
							"illiteracy.loc[illiteracy['country'] == 'Congo, Rep.', 'country'] = 'Republic of the Congo'\n",
							"\n",
							"\n",
							"\n",
							"#Get ISO3 values and filter for specific African countries\n",
							"illiteracy = pd.merge(illiteracy, african_countries, on='country', how='left')\n",
							"illiteracy = illiteracy[illiteracy['iso3'].isin(african_countries['iso3'])]\n",
							"\n",
							"#Rename columns\n",
							"illiteracy = illiteracy[['iso3', 'country', 'year', indicator]]\n",
							"illiteracy.columns = iri_col_names\n",
							"illiteracy = illiteracy.dropna(subset=['value'])\n",
							"illiteracy['value'] = 100 - illiteracy['value'] #want illiteracy percentage\n",
							"\n",
							"# Compute 'illiteracy_score'\n",
							"illiteracy['illiteracy_score'] = 2 * illiteracy['value'] / 100\n",
							"\n",
							"# Convert 'year' to numeric\n",
							"illiteracy['year'] = pd.to_numeric(illiteracy['year'])\n",
							"\n",
							"# Filter for years >= 2000\n",
							"illiteracy = illiteracy[illiteracy['year'] >= 2000]\n",
							"\n",
							"\n",
							"print(illiteracy.head())\n",
							""
						],
						"outputs": [],
						"execution_count": 25
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"check_country_names(illiteracy['name'], african_countries['country'])"
						],
						"outputs": [],
						"execution_count": 26
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Fragile State Index Data"
						]
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"file_list = mssparkutils.fs.ls(\"abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/AFRICOM_Instability_Index/fsi_data\")\n",
							"file_paths = []\n",
							"\n",
							"for file_path in file_list:\n",
							"    if '.xlsx' in file_path.path:\n",
							"        file_paths.append(file_path.path)\n",
							"\n",
							"dfs = []\n",
							"\n",
							"\n",
							"for path in file_paths:\n",
							"    df = spark.read.format(\"com.crealytics.spark.excel\") \\\n",
							"        .option(\"header\", \"true\") \\\n",
							"        .option(\"inferSchema\", \"true\") \\\n",
							"        .load(path)\n",
							"    df = df.select(df.columns[:16]) #Data from 2009 onwards has an extra column\n",
							"    \n",
							"# Cast all columns to string to ensure compatibility\n",
							"    for col_name in df.columns:\n",
							"        df = df.withColumn(col_name, df[col_name].cast(\"string\"))\n",
							"\n",
							"    dfs.append(df)\n",
							"\n",
							"# Union all DataFrames\n",
							"combined_df = dfs[0]\n",
							"for df in dfs[1:]:\n",
							"    combined_df = combined_df.unionByName(df)\n",
							"\n",
							"\n",
							"# Cast the first three columns\n",
							"fsi_data = combined_df \\\n",
							"    .withColumn(\"Country\", col(\"Country\").cast(\"string\")) \\\n",
							"    .withColumn(\"Year\", year(col(\"Year\")).cast(\"int\")) \\\n",
							"    .withColumn(\"Rank\", col(\"Rank\").cast(\"string\"))\n",
							"\n",
							"\n",
							"# Cast the remaining columns to double\n",
							"for col_name in fsi_data.columns[3:]:\n",
							"    fsi_data = fsi_data.withColumn(col_name, col(col_name).cast(\"double\"))\n",
							"\n",
							"fsi_data = fsi_data.toPandas()\n",
							"fsi_data[\"Year\"] = fsi_data[\"Year\"].fillna(0).astype(int)\n",
							"\n",
							"\n",
							"print(fsi_data.head())\n",
							""
						],
						"outputs": [],
						"execution_count": 27
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Human Flight (FSI E3)\n",
							"\n",
							"This is a subsection of the `fsi` dataset, thus a similar methodology will be used for other `fsi` subsets."
						]
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"#Extract appropriate column and format the rest of the data\n",
							"selected_col = 'E3: Human Flight and Brain Drain'\n",
							"human_flight = fsi_data[['Country', 'Year', selected_col]]\n",
							"human_flight.loc[human_flight['Country'] == 'Congo Democratic Republic', 'Country'] = 'Democratic Republic of the Congo'\n",
							"human_flight = pd.merge(human_flight, african_countries, left_on='Country',  right_on='country', how='left')\n",
							"human_flight = human_flight[human_flight['iso3'].isin(african_countries['iso3'])]\n",
							"human_flight = human_flight[['iso3', 'Country', 'Year', selected_col]]\n",
							"human_flight.columns = iri_col_names\n",
							"human_flight = human_flight.drop_duplicates(subset=['iso3', 'year'], keep=\"first\")\n",
							"\n",
							"# Compute 'human_flight_score'\n",
							"human_flight['human_flight_score'] = 2 * human_flight['value'] / 10\n",
							"\n",
							"# Convert 'year' to numeric\n",
							"human_flight['year'] = pd.to_numeric(human_flight['year'])\n",
							"\n",
							"# Filter for years >= 2000\n",
							"human_flight = human_flight[human_flight['year'] >= 2000]\n",
							"\n",
							"print(human_flight.head())"
						],
						"outputs": [],
						"execution_count": 42
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"check_country_names(human_flight['name'], african_countries['country'])"
						],
						"outputs": [],
						"execution_count": 43
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Demographic Pressures (S1)"
						]
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"#Extract appropriate column and format the rest of the data\n",
							"selected_col = 'S1: Demographic Pressures'\n",
							"demographic_pressure = fsi_data[['Country', 'Year', selected_col]]\n",
							"demographic_pressure.loc[demographic_pressure['Country'] == 'Congo Democratic Republic', 'Country'] = 'Democratic Republic of the Congo'\n",
							"demographic_pressure = pd.merge(demographic_pressure, african_countries, left_on='Country',  right_on='country', how='left')\n",
							"demographic_pressure = demographic_pressure[demographic_pressure['iso3'].isin(african_countries['iso3'])]\n",
							"demographic_pressure = demographic_pressure[['iso3', 'Country', 'Year', selected_col]]\n",
							"demographic_pressure.columns = iri_col_names\n",
							"demographic_pressure = demographic_pressure.drop_duplicates(subset=['iso3', 'year'], keep=\"first\")\n",
							"\n",
							"# Compute 'demographic_pressure_score'\n",
							"demographic_pressure['demographic_pressure_score'] = 2 * demographic_pressure['value'] / 10\n",
							"\n",
							"# Convert 'year' to numeric\n",
							"demographic_pressure['year'] = pd.to_numeric(demographic_pressure['year'])\n",
							"\n",
							"# Filter for years >= 2000\n",
							"demographic_pressure = demographic_pressure[demographic_pressure['year'] >= 2000]\n",
							"\n",
							"print(demographic_pressure.head())"
						],
						"outputs": [],
						"execution_count": 44
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"check_country_names(demographic_pressure['name'], african_countries['country'])"
						],
						"outputs": [],
						"execution_count": 45
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Socioenvironmental Pressures Index"
						]
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"\n",
							"\n",
							"def capture_original_variable_names(var_dict):\n",
							"    df_values = [value for value in var_dict.values() if isinstance(value, pd.DataFrame)]\n",
							"    matched_names = []\n",
							"\n",
							"    for name, obj in globals().items():\n",
							"        if isinstance(obj, pd.DataFrame) and any(obj is val for val in df_values):\n",
							"            matched_names.append(name)\n",
							"\n",
							"    return matched_names\n",
							"\n",
							"\n",
							"\n",
							"\n",
							"# Dynamically passing variables\n",
							"variables = {\n",
							"    \"df1\": environmental_adaptation,\n",
							"    \"df2\": youth_underdevelopment,\n",
							"    \"df3\": illiteracy,\n",
							"    \"df4\": human_flight,\n",
							"    \"df5\": demographic_pressure\n",
							"}\n",
							"\n",
							"df_values = [value for value in variables.values() if isinstance(value, pd.DataFrame)]\n",
							"for name, obj in globals().items():\n",
							"    if isinstance(obj, pd.DataFrame) and any(obj is val for val in df_values):\n",
							"        print(name)\n",
							""
						],
						"outputs": [],
						"execution_count": 73
					},
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"df_names = [name for name, obj in globals().items() if isinstance(obj, pd.DataFrame)]\n",
							"print(df_names)"
						],
						"outputs": [],
						"execution_count": 63
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### "
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"\n",
							"### References\n",
							"[1] USAFRICOM J54. (2025). *Africa Instability Risk Assessment*. USAFRICOM.\n",
							"\n",
							"[2] Wikipedia. (2025). *Autoregressive integrated moving average*. http://en.wikipedia.org/w/index.php?title=Autoregressive\\%20integrated\\%20moving\\%20average&oldid=1286449544, accessed 07 May 2025.\n",
							"\n",
							"[3] Wikipedia. (2025). *Metalog distribution*. http://en.wikipedia.org/w/index.php?title=Metalog\\%20distribution&oldid=1278020484, accessed 07 May 2025.\n",
							"\n",
							"[4] University of Notre Dame. (2025). *Notre Dame Global Adaptation Initiative Country Index (ND-GAIN)*. https://gain.nd.edu/our-work/country-index/download-data/\n",
							"\n",
							"[5] The Commonwealth. (2025). *Youth Development Index*. https://cwapiservices.thecommonwealth.org/index.html\n",
							"\n",
							"[6] World Bank. (2025). *Literacy rate, adult total (% of people ages 15 and above)*. https://data.worldbank.org/indicator/SE.ADT.LITR.ZS?most_recent_value_desc=true\n",
							"\n",
							"[7] The Fund for Peace. (2022). *Fragile State Index*. https://fragilestatesindex.org/excel/\n",
							"\n",
							"[8] Next Reference\n",
							"\n",
							""
						]
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AfroBarometer_AllSurvey_Pull')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ac2sparkpooldev",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "7400c9a8-83cd-4420-85d3-55caf651b5ee"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Synapse/workspaces/ac2-synapse-ws-dev/bigDataPools/ac2sparkpooldev",
						"name": "ac2sparkpooldev",
						"type": "Spark",
						"endpoint": "https://ac2-synapse-ws-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ac2sparkpooldev",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"print(\"Im Online\")"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"!pip install pyreadstat"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import requests\r\n",
							"import pandas as pd\r\n",
							"import pyreadstat\r\n",
							"\r\n",
							"# URL of the .sav file\r\n",
							"url = 'https://www.afrobarometer.org/wp-content/uploads/2024/09/MOZ_R9.data_.final_.wtd_release.20Jun24.sav'\r\n",
							"\r\n",
							"# Fetch the .sav file\r\n",
							"response = requests.get(url)\r\n",
							"\r\n",
							"# Save the file locally\r\n",
							"with open('data.sav', 'wb') as file:\r\n",
							"    file.write(response.content)\r\n",
							"\r\n",
							"# Read the .sav file into a pandas DataFrame\r\n",
							"df, meta = pyreadstat.read_sav('data.sav')\r\n",
							"\r\n",
							"# Display the DataFrame\r\n",
							"print(df.head())"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import requests\r\n",
							"from bs4 import BeautifulSoup\r\n",
							"\r\n",
							"# URL of the webpage\r\n",
							"url = 'https://www.afrobarometer.org/data/data-sets/?current-page=1#listing'\r\n",
							"\r\n",
							"# Fetch the webpage content\r\n",
							"response = requests.get(url)\r\n",
							"\r\n",
							"if response.status_code == 200:\r\n",
							"    html_content = response.text\r\n",
							"    soup = BeautifulSoup(html_content, 'html.parser')\r\n",
							"    \r\n",
							"    # Find all links to datasets\r\n",
							"    dataset_links = soup.find_all('a', href=True)\r\n",
							"    \r\n",
							"    # Filter and print dataset URLs\r\n",
							"    for link in dataset_links:\r\n",
							"        href = link['href']\r\n",
							"        if 'data-sets' in href:\r\n",
							"            print(href)\r\n",
							"else:\r\n",
							"    print(\"Failed to retrieve the webpage\")"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import requests\r\n",
							"from bs4 import BeautifulSoup\r\n",
							"\r\n",
							"base_url = 'https://www.afrobarometer.org/data/data-sets/?current-page='\r\n",
							"urls_with_survey_resource = []\r\n",
							"\r\n",
							"# Loop through pages 1 to 30\r\n",
							"for page in range(1, 31):\r\n",
							"    url = f'{base_url}{page}#listing'\r\n",
							"    response = requests.get(url)\r\n",
							"    \r\n",
							"    if response.status_code == 200:\r\n",
							"        soup = BeautifulSoup(response.text, 'html.parser')\r\n",
							"        \r\n",
							"        # Find all links\r\n",
							"        links = soup.find_all('a', href=True)\r\n",
							"        \r\n",
							"        # Filter links containing \"survey-resource\"\r\n",
							"        for link in links:\r\n",
							"            href = link['href']\r\n",
							"            if 'survey-resource' in href:\r\n",
							"                urls_with_survey_resource.append(href)\r\n",
							"    else:\r\n",
							"        print(f\"Failed to retrieve page {page}\")\r\n",
							"\r\n",
							"# Print all URLs containing \"survey-resource\"\r\n",
							"for url in urls_with_survey_resource:\r\n",
							"    print(url)\r\n",
							""
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Loop through urls_with_survey_resource and retrieve all URLs with .sav\r\n",
							"sav_urls = []\r\n",
							"\r\n",
							"for survey_url in urls_with_survey_resource:\r\n",
							"    response = requests.get(survey_url)\r\n",
							"    \r\n",
							"    if response.status_code == 200:\r\n",
							"        soup = BeautifulSoup(response.text, 'html.parser')\r\n",
							"        \r\n",
							"        # Find all links\r\n",
							"        links = soup.find_all('a', href=True)\r\n",
							"        \r\n",
							"        # Filter links containing \".sav\"\r\n",
							"        for link in links:\r\n",
							"            href = link['href']\r\n",
							"            if '.sav' in href:\r\n",
							"                sav_urls.append(href)\r\n",
							"    else:\r\n",
							"        print(f\"Failed to retrieve survey resource page: {survey_url}\")\r\n",
							"\r\n",
							"# Print all URLs containing \".sav\"\r\n",
							"for url in sav_urls:\r\n",
							"    print(url)"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Dictionary to store pandas DataFrames with file names as keys\r\n",
							"data_frames = {}\r\n",
							"\r\n",
							"# Loop through sav_urls, download each .sav file, and convert it to a pandas DataFrame\r\n",
							"for sav_url in sav_urls:\r\n",
							"    try:\r\n",
							"        response = requests.get(sav_url)\r\n",
							"        \r\n",
							"        if response.status_code == 200:\r\n",
							"            # Extract the file name from the URL\r\n",
							"            file_name = sav_url.split('/')[-1]\r\n",
							"            \r\n",
							"            # Save the .sav file locally\r\n",
							"            with open(file_name, 'wb') as file:\r\n",
							"                file.write(response.content)\r\n",
							"            \r\n",
							"            # Read the .sav file into a pandas DataFrame\r\n",
							"            df, meta = pyreadstat.read_sav(file_name)\r\n",
							"            \r\n",
							"            # Store the DataFrame in the dictionary with the file name as the key\r\n",
							"            data_frames[file_name] = df\r\n",
							"        else:\r\n",
							"            print(f\"Failed to retrieve .sav file from: {sav_url}\")\r\n",
							"    except pyreadstat.ReadstatError as e:\r\n",
							"        print(f\"Failed to read .sav file from: {sav_url} due to ReadstatError: {e}\")\r\n",
							"\r\n",
							"\r\n",
							"# Display the DataFrames with their names\r\n",
							"#for file_name, df in data_frames.items():\r\n",
							" #   print(f\"DataFrame for {file_name}:\")\r\n",
							"  #  print(df.head())"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import io\r\n",
							"\"\"\"     #Blocked to Prevent Overwrite.\r\n",
							"for key, data in data_frames.items():\r\n",
							"    try:\r\n",
							"        csv_buffer = io.StringIO()\r\n",
							"        data.to_csv(csv_buffer, index=False)\r\n",
							"        csv_string = csv_buffer.getvalue()\r\n",
							"        file_path = f\"abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/AfroBarometerSurvey/{key}\"\r\n",
							"        mssparkutils.fs.put(file_path, csv_string, overwrite=True)\r\n",
							"    except Exception as e:\r\n",
							"        print(f\"Failed to save {key}: {e}\")\r\n",
							"\"\"\"\r\n",
							"print(\"Complete\")"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"print(\"ALL DONE\")"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						]
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AfroBarometer_Survey_Socumentation')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ac2sparkpooldev",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "9c587dad-e470-44ce-aba9-6ee4b1d8104b"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Synapse/workspaces/ac2-synapse-ws-dev/bigDataPools/ac2sparkpooldev",
						"name": "ac2sparkpooldev",
						"type": "Spark",
						"endpoint": "https://ac2-synapse-ws-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ac2sparkpooldev",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"print (\"Initiate\")"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import requests\r\n",
							"from bs4 import BeautifulSoup\r\n",
							"\r\n",
							"base_url = \"https://www.afrobarometer.org/data/codebooks/?current-page=\"\r\n",
							"urls = []\r\n",
							"\r\n",
							"for page in range(1, 28):\r\n",
							"    url = f\"{base_url}{page}\"\r\n",
							"    response = requests.get(url)\r\n",
							"    soup = BeautifulSoup(response.content, 'html.parser')\r\n",
							"    for link in soup.find_all('a', href=True):\r\n",
							"        if \"round\" in link['href'].lower():\r\n",
							"            urls.append(link['href'])\r\n",
							"\r\n",
							"print(urls)"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import requests\r\n",
							"\r\n",
							"url = \"https://www.afrobarometer.org/survey-resource/tunisia-round-9-codebook-2022/\"\r\n",
							"response = requests.get(url)\r\n",
							"\r\n",
							"# Save the content to a file\r\n",
							"with open(\"Tunisia_Round_9_Codebook_2022.pdf\", \"wb\") as file:\r\n",
							"    file.write(response.content)\r\n",
							"\r\n",
							"print(\"Download complete\")"
						],
						"outputs": [],
						"execution_count": 4
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Chancification')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ac2sparkpooldev",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "c470db5f-ce36-4c4d-9995-ef03abb33e6f"
					}
				},
				"metadata": {
					"saveOutput": true,
					"synapse_widget": {
						"version": "0.1"
					},
					"enableDebugMode": false,
					"language_info": {
						"name": "r"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Synapse/workspaces/ac2-synapse-ws-dev/bigDataPools/ac2sparkpooldev",
						"name": "ac2sparkpooldev",
						"type": "Spark",
						"endpoint": "https://ac2-synapse-ws-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ac2sparkpooldev",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Install packages"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"install.packages(\"rmetalog\")"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Instantiate Libraries"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"library(rmetalog)"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Read Data"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"schema <- structType(structField(\"weight\", \"double\"))\r\n",
							"\r\n",
							"fish_data <- read.df(\r\n",
							"    'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Metalog-Fish-Data.csv', \r\n",
							"    'csv',\r\n",
							"    schema,\r\n",
							"    header=TRUE\r\n",
							")\r\n",
							"\r\n",
							"fish_data <- as.data.frame(fish_data)"
						],
						"outputs": [],
						"execution_count": 79
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"summary(fish_data$weight)"
						],
						"outputs": [],
						"execution_count": 81
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Create Metalog\r\n",
							"\r\n",
							"Metalogs are a useful tool to create distributions in which CDF data is known and a flexible, simple, and easy-to-use continuous probability distribution is needed to represent that data. More details can be found [here](http://www.metalogdistributions.com/applications.html).\r\n",
							"\r\n",
							"For this notebook, we will use the `rmetalog` package in which the repository can be found [here](https://github.com/isaacfab/RMetalog/)."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"my_metalog <- metalog(\r\n",
							"  fish_data$weight,\r\n",
							"  term_limit = 9,\r\n",
							"  term_lower_bound = 2,\r\n",
							"  bounds = c(0, 60),\r\n",
							"  boundedness = 'b',\r\n",
							"  step_len = 0.01\r\n",
							"  )\r\n",
							"\r\n",
							"summary(my_metalog)"
						],
						"outputs": [],
						"execution_count": 82
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Plots"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"plot(my_metalog)$pdf"
						],
						"outputs": [],
						"execution_count": 90
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"plot(my_metalog)$cdf"
						],
						"outputs": [],
						"execution_count": 91
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Create Samples from a Metalog Term"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"s <- rmetalog(my_metalog, n = 1000, term = 9)\r\n",
							"hist(s)"
						],
						"outputs": [],
						"execution_count": 92
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"You can also retrieve quantile, density, and probability values similar to other R distributions."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"qmetalog(my_metalog, c(0.25, 0.5, 0.75), term = 9)"
						],
						"outputs": [],
						"execution_count": 93
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Probabilities from a quantile."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"pmetalog(my_metalog, c(3,10,25), term = 9)"
						],
						"outputs": [],
						"execution_count": 95
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Density from a quantile"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"dmetalog(my_metalog, c(3,10,25), term = 9)"
						],
						"outputs": [],
						"execution_count": 96
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Military Activity Impact Metric\r\n",
							"\r\n",
							"## Metric Scale\r\n",
							"\r\n",
							"For this metric, we will develop an impact score on a 0 to 1 scale. \r\n",
							"- **1** represents a fully successful outcome.\r\n",
							"- **0** represents failure or no meaningful impact.\r\n",
							"- Scores between 0 and 1 represent varying degrees of partial success.\r\n",
							"\r\n",
							"## Metric Metalog Distribution\r\n",
							"\r\n",
							"The Metalog for this metric will use three values representing the 10-50-90 percentiles of the proposed distribution. The technical term is a [Symetric Percentile Triplet (SPT)](http://www.metalogdistributions.com/software/sptmetalogsworkbook.html).\r\n",
							""
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"oai_metalog <- metalog(\r\n",
							"  c(.3,.4,.6),\r\n",
							"  term_limit = 3,\r\n",
							"  term_lower_bound = 2,\r\n",
							"  bounds = c(0, 1),\r\n",
							"  boundedness = 'b',\r\n",
							"  step_len = 0.01\r\n",
							"  )\r\n",
							"\r\n",
							"summary(oai_metalog)"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Plots"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"plot(oai_metalog)$pdf"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"oai_quality_samples <- rmetalog(n = 1000, oai_metalog, term = 3)\r\n",
							"hist(oai_quality_samples)"
						],
						"outputs": [],
						"execution_count": 8
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/EORA Analysis')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ac2sparkpooldev",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "b6036375-0f52-4584-a0f5-b60897ac1469"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Synapse/workspaces/ac2-synapse-ws-dev/bigDataPools/ac2sparkpooldev",
						"name": "ac2sparkpooldev",
						"type": "Spark",
						"endpoint": "https://ac2-synapse-ws-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ac2sparkpooldev",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#!pip install pymrio\r\n",
							"#!pip install country_converter"
						],
						"outputs": [],
						"execution_count": 92
					},
					{
						"cell_type": "code",
						"source": [
							"import pandas as pd\r\n",
							"import numpy as np\r\n",
							"import pymrio as pmr\r\n",
							"import matplotlib.pyplot as plt\r\n",
							"import seaborn as sns\r\n",
							"import seaborn.objects as so\r\n",
							"from collections import namedtuple\r\n",
							"from notebookutils import mssparkutils\r\n",
							"import country_converter as coco"
						],
						"outputs": [],
						"execution_count": 93
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Read Data"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"analysis_year = \"2022\"\r\n",
							"country_stats_path = 'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_Country_Statistics/eora26-country-stats-'+analysis_year+'.csv'\r\n",
							"country_label_path = 'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA_Labels/country-labels.csv'\r\n",
							"country_labels = spark.read.load(country_label_path, format='csv',sep=\",\").toPandas()\r\n",
							"country_stats = spark.read.load(country_stats_path, format='csv', sep=\",\", header = 'True').toPandas()\r\n",
							"obj_columns = country_stats.select_dtypes(include='object').columns\r\n",
							"country_stats[obj_columns] = country_stats[obj_columns].astype(\"float\")\r\n",
							"country_stats.index = country_labels.squeeze()\r\n",
							"country_stats.index.name = 'Country'"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Global Value Chain"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"country_stats['gvc-part'] = (country_stats['exports-foreign-value-added'] + country_stats['exports-used-for-export-production'])/country_stats['gross-exports']\r\n",
							"gvc_pos_term1 = np.log(1 + (country_stats['exports-used-for-export-production']/country_stats['gross-exports']))\r\n",
							"gvc_pos_term2 = np.log(1 + (country_stats['exports-foreign-value-added']/country_stats['gross-exports']))\r\n",
							"country_stats['gvc-pos'] = gvc_pos_term1 - gvc_pos_term2\r\n",
							"country_stats"
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countries = ['USA', 'DEU', 'RUS','CHN','LBY']\r\n",
							"country_stats['gvc-pos'] = country_stats['gvc-pos'].fillna(0)\r\n",
							"country_stats_filtered = country_stats.loc[countries]\r\n",
							"country_stats_filtered['countries'] = countries\r\n",
							"x = country_stats_filtered['gvc-pos']\r\n",
							"y = country_stats_filtered['gvc-part']\r\n",
							"\r\n",
							"so.Plot(country_stats_filtered, \"gvc-pos\", \"gvc-part\", text=\"countries\")\\\r\n",
							"   .add(so.Dots(), so.Jitter(x=0.5, y=0.3))\\\r\n",
							"   .add(so.Text(halign=\"left\"))"
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## pymrio Package"
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Build MRIO without a parser"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"_sectors = [\"sector1\", \"sector2\"]\r\n",
							"_regions = [\"reg1\"]\r\n",
							"_Z_multiindex = pd.MultiIndex.from_product(\r\n",
							"    [_regions, _sectors], names=[\"region\", \"sector\"]\r\n",
							")"
						],
						"outputs": [],
						"execution_count": 33
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Z = pd.DataFrame(\r\n",
							"    data=np.array([[150, 500], [200, 100]]), index=_Z_multiindex, columns=_Z_multiindex\r\n",
							")\r\n",
							"Z"
						],
						"outputs": [],
						"execution_count": 34
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"_categories = [\"final demand\"]\r\n",
							"_fd_multiindex = pd.MultiIndex.from_product(\r\n",
							"    [_regions, _categories], names=[\"region\", \"category\"]\r\n",
							")"
						],
						"outputs": [],
						"execution_count": 35
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Y = pd.DataFrame(\n",
							"    data=np.array([[350], [1700]]), index=_Z_multiindex, columns=_fd_multiindex\n",
							")\n",
							"Y"
						],
						"outputs": [],
						"execution_count": 36
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"F = pd.DataFrame(\n",
							"    data=np.array([[650, 1400]]), index=[\"Payments_sectors\"], columns=_Z_multiindex\n",
							")\n",
							"F"
						],
						"outputs": [],
						"execution_count": 37
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"io = pmr.IOSystem()\n",
							"io.Z = Z\n",
							"io.Y = Y"
						],
						"outputs": [],
						"execution_count": 39
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"factor_input = pmr.Extension(name=\"Factor Input\", F=F)\n",
							"io.factor_input = factor_input\n",
							"io.factor_input.unit = pd.DataFrame(data=[\"USD\"], index=F.index, columns=[\"unit\"])\n",
							"str(io)"
						],
						"outputs": [],
						"execution_count": 41
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"io.calc_all()"
						],
						"outputs": [],
						"execution_count": 43
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"io.A"
						],
						"outputs": [],
						"execution_count": 44
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"io.L"
						],
						"outputs": [],
						"execution_count": 45
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## EORA Data"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def parse_eora_mod(path, year=None, price=\"bp\", country_names=\"eora\"):\r\n",
							"\r\n",
							"    row_name = \"ROW\"\r\n",
							"\r\n",
							"    IDX_NAMES = {\r\n",
							"    \"Z_col\": [\"region\", \"sector\"],\r\n",
							"    \"Z_row\": [\"region\", \"sector\"],\r\n",
							"    \"Z_row_unit\": [\"region\", \"sector\", \"unit\"],\r\n",
							"    \"A_col\": [\"region\", \"sector\"],\r\n",
							"    \"A_row\": [\"region\", \"sector\"],\r\n",
							"    \"A_row_unit\": [\"region\", \"sector\", \"unit\"],\r\n",
							"    \"Y_col1\": [\"region\"],\r\n",
							"    \"Y_col2\": [\"region\", \"category\"],\r\n",
							"    \"Y_row\": [\"region\", \"sector\"],\r\n",
							"    \"Y_row_unit\": [\"region\", \"sector\", \"unit\"],\r\n",
							"    \"F_col\": [\"region\", \"sector\"],\r\n",
							"    \"F_row_single\": [\"stressor\"],\r\n",
							"    \"F_row_unit\": [\"stressor\", \"unit\"],\r\n",
							"    \"F_row_comp_unit\": [\"stressor\", \"compartment\", \"unit\"],\r\n",
							"    \"F_row_src_unit\": [\"stressor\", \"source\", \"unit\"],\r\n",
							"    \"F_row_src\": [\"stressor\", \"source\"],\r\n",
							"    \"VA_row_single\": [\"inputtype\"],\r\n",
							"    \"VA_row_unit\": [\"inputtype\", \"unit\"],\r\n",
							"    \"VA_row_unit_cat\": [\"inputtype\", \"category\"],\r\n",
							"    \"unit\": [\"unit\"],\r\n",
							"    \"_reg_sec_unit\": [\"region\", \"sector\", \"unit\"],\r\n",
							"    }\r\n",
							"\r\n",
							"    #eora file specs\r\n",
							"    eora_sep = \"\\t\"\r\n",
							"    ZY_col = namedtuple(\"ZY\", \"full eora system name\")(0,1,2,3)\r\n",
							"\r\n",
							"    eora_files = {\r\n",
							"    \"Z\": path + \"Eora26_{year}_{price}_T.txt\".format(year=str(year), price=price),\r\n",
							"    \"Q\": path + \"Eora26_{year}_{price}_Q.txt\".format(year=str(year), price=price),\r\n",
							"    \"QY\": path + \"Eora26_{year}_{price}_QY.txt\".format(year=str(year), price=price),\r\n",
							"    \"VA\": path + \"Eora26_{year}_{price}_VA.txt\".format(year=str(year), price=price),\r\n",
							"    \"Y\": path + \"Eora26_{year}_{price}_FD.txt\".format(year=str(year), price=price),\r\n",
							"    \"labels_Z\": path + \"labels_T.txt\",\r\n",
							"    \"labels_Y\": path + \"labels_FD.txt\",\r\n",
							"    \"labels_Q\": path + \"labels_Q.txt\",\r\n",
							"    \"labels_VA\": path + \"labels_VA.txt\"\r\n",
							"    }\r\n",
							"\r\n",
							"    header = namedtuple(\"header\", \"index columns index_names, column_names\")\r\n",
							"\r\n",
							"    eora_header_spec = {\r\n",
							"        \"Z\": header(\r\n",
							"            index=\"labels_Z\",\r\n",
							"            columns=\"labels_Z\",\r\n",
							"            index_names=IDX_NAMES[\"Z_row\"],\r\n",
							"            column_names=IDX_NAMES[\"Z_col\"],\r\n",
							"        ),\r\n",
							"        \"Q\": header(\r\n",
							"            index=\"labels_Q\",\r\n",
							"            columns=\"labels_Z\",\r\n",
							"            index_names=IDX_NAMES[\"F_row_src\"],\r\n",
							"            column_names=IDX_NAMES[\"F_col\"],\r\n",
							"        ),\r\n",
							"        \"QY\": header(\r\n",
							"            index=\"labels_Q\",\r\n",
							"            columns=\"labels_Y\",\r\n",
							"            index_names=IDX_NAMES[\"F_row_src\"],\r\n",
							"            column_names=IDX_NAMES[\"Y_col2\"],\r\n",
							"        ),\r\n",
							"        \"VA\": header(\r\n",
							"            index=\"labels_VA\",\r\n",
							"            columns=\"labels_Z\",\r\n",
							"            index_names=IDX_NAMES[\"VA_row_unit_cat\"],\r\n",
							"            column_names=IDX_NAMES[\"F_col\"],\r\n",
							"        ),\r\n",
							"        \"Y\": header(\r\n",
							"            index=\"labels_Z\",\r\n",
							"            columns=\"labels_Y\",\r\n",
							"            index_names=IDX_NAMES[\"Y_row\"],\r\n",
							"            column_names=IDX_NAMES[\"Y_col2\"],\r\n",
							"        )\r\n",
							"        }\r\n",
							"    \r\n",
							"    if mssparkutils.fs.exists(path):\r\n",
							"        eora_data = {\r\n",
							"            key: (\r\n",
							"                spark.read.load(filepath, format='csv',sep=\"\\t\").toPandas()\r\n",
							"            )\r\n",
							"            for key, filepath in eora_files.items()\r\n",
							"        }\r\n",
							"\r\n",
							"    eora_data['Z'] = eora_data['Z'].astype(\"float\")\r\n",
							"    eora_data['Q'] = eora_data['Q'].astype(\"float\")\r\n",
							"    eora_data['QY'] = eora_data['QY'].astype(\"float\")\r\n",
							"    eora_data['VA'] = eora_data['VA'].astype(\"float\")\r\n",
							"    eora_data['Y'] = eora_data['Y'].astype(\"float\")\r\n",
							"\r\n",
							"    eora_data[\"labels_Z\"] = eora_data[\"labels_Z\"].iloc[\r\n",
							"        :, [getattr(ZY_col, country_names), ZY_col.name]\r\n",
							"    ]\r\n",
							"    eora_data[\"labels_Y\"] = eora_data[\"labels_Y\"].iloc[\r\n",
							"        :, [getattr(ZY_col, country_names), ZY_col.name]\r\n",
							"    ]\r\n",
							"    eora_data[\"labels_VA\"] = eora_data[\"labels_VA\"].iloc[\r\n",
							"        :, : len(eora_header_spec[\"VA\"].column_names)\r\n",
							"    ]\r\n",
							"\r\n",
							"    labQ = eora_data[\"labels_Q\"].iloc[:, : len(eora_header_spec[\"Q\"].column_names)]\r\n",
							"    labQ.columns = IDX_NAMES[\"F_row_src\"]\r\n",
							"    Q_unit = pd.DataFrame(labQ[\"stressor\"].str.extract(r\"\\((.*)\\)\", expand=False))\r\n",
							"    Q_unit.columns = IDX_NAMES[\"unit\"]\r\n",
							"\r\n",
							"    labQ = labQ.copy()\r\n",
							"    labQ.loc[:, \"stressor\"] = labQ[\"stressor\"].str.replace(r\"\\s\\((.*)\\)\", \"\", regex=True)\r\n",
							"    eora_data[\"labels_Q\"] = labQ\r\n",
							"\r\n",
							"    for key in eora_header_spec.keys():\r\n",
							"        eora_data[key].columns = (\r\n",
							"            eora_data[eora_header_spec[key].columns]\r\n",
							"            .set_index(list(eora_data[eora_header_spec[key].columns]))\r\n",
							"            .index\r\n",
							"        )\r\n",
							"        eora_data[key].columns.names = eora_header_spec[key].column_names\r\n",
							"        eora_data[key].index = (\r\n",
							"            eora_data[eora_header_spec[key].index]\r\n",
							"            .set_index(list(eora_data[eora_header_spec[key].index]))\r\n",
							"            .index\r\n",
							"        )\r\n",
							"        eora_data[key].index.names = eora_header_spec[key].index_names\r\n",
							"\r\n",
							"        try:\r\n",
							"            row_mask = ~eora_data[key].index.get_level_values('region').str.startswith(row_name)\r\n",
							"            col_mask = ~eora_data[key].columns.get_level_values('region').str.startswith(row_name)\r\n",
							"            eora_data[key] = eora_data[key].loc[row_mask , :]\r\n",
							"            eora_data[key] = eora_data[key].loc[: , col_mask]\r\n",
							"        except KeyError:\r\n",
							"            pass\r\n",
							"\r\n",
							"    #This is a quick fix to remove all the \"ROW\" columns in these dataframes\r\n",
							"\r\n",
							"    eora_data['Q'] = eora_data['Q'].loc[:,~eora_data['Q'].columns.get_level_values('region').str.startswith(row_name)]\r\n",
							"    eora_data['QY'] = eora_data['QY'].loc[:,~eora_data['QY'].columns.get_level_values('region').str.startswith(row_name)]\r\n",
							"    eora_data['VA'] = eora_data['VA'].loc[:,~eora_data['VA'].columns.get_level_values('region').str.startswith(row_name)]\r\n",
							"\r\n",
							"    \r\n",
							"    Q_unit.index = eora_data[\"Q\"].index\r\n",
							"\r\n",
							"    Z_unit = pd.DataFrame(\r\n",
							"        data=[\"Mill USD\"] * len(eora_data[\"Z\"].index),\r\n",
							"        index=eora_data[\"Z\"].index,\r\n",
							"        columns=[\"unit\"],\r\n",
							"    )\r\n",
							"\r\n",
							"    VA_unit = pd.DataFrame(\r\n",
							"        data=[\"Mill USD\"] * len(eora_data[\"VA\"].index),\r\n",
							"        index=eora_data[\"VA\"].index,\r\n",
							"        columns=[\"unit\"],\r\n",
							"    )\r\n",
							"\r\n",
							"    eora = pmr.IOSystem(\r\n",
							"        Z=eora_data[\"Z\"],\r\n",
							"        Y=eora_data[\"Y\"],\r\n",
							"        unit=Z_unit,\r\n",
							"        Q={\"name\": \"Q\", \"unit\": Q_unit, \"F\": eora_data[\"Q\"], \"F_Y\": eora_data[\"QY\"]},\r\n",
							"        VA={\r\n",
							"            \"name\": \"VA\",\r\n",
							"            \"F\": eora_data[\"VA\"],\r\n",
							"            \"unit\": VA_unit,\r\n",
							"        },\r\n",
							"    )\r\n",
							"\r\n",
							"\r\n",
							"    return(eora)\r\n",
							"\r\n",
							""
						],
						"outputs": [],
						"execution_count": 169
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"year = \"2022\"\r\n",
							"price=\"bp\"\r\n",
							"path = 'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_{year}_{price}/'.format(year=year, price=price)\r\n",
							"\r\n",
							"\r\n",
							"\r\n",
							"eora_data = parse_eora_mod(path, year=year)"
						],
						"outputs": [],
						"execution_count": 160
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"eora_data.aggregate(\r\n",
							"    region_agg=coco.agg_conc(\r\n",
							"        original_countries=\"Eora\", aggregates=[\"OECD\"], missing_countries=\"NON_OECD\"\r\n",
							"    )\r\n",
							")"
						],
						"outputs": [],
						"execution_count": 165
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"eora_data.get_regions()"
						],
						"outputs": [],
						"execution_count": 166
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"eora_data.calc_all()"
						],
						"outputs": [],
						"execution_count": 164
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import matplotlib.pyplot as plt\r\n",
							"\r\n",
							"with plt.style.context(\"ggplot\"):\r\n",
							"    eora_data.Q.plot_account((\"Total cropland area\", \"Total\"), figsize=(8, 5))\r\n",
							"    plt.show()"
						],
						"outputs": [],
						"execution_count": 168
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/EORA-General-Statistics-By-Year')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ac2sparkpooldev",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "47e69eec-ce7c-4d51-85c0-09030265a644"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Synapse/workspaces/ac2-synapse-ws-dev/bigDataPools/ac2sparkpooldev",
						"name": "ac2sparkpooldev",
						"type": "Spark",
						"endpoint": "https://ac2-synapse-ws-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ac2sparkpooldev",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"import numpy as np\r\n",
							"from scipy.linalg import block_diag\r\n",
							"import warnings\r\n",
							"import pandas as pd\r\n",
							"import io"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Compute Stats"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Parameters\r\n",
							"num_cntry = 189\r\n",
							"num_sectors = 26\r\n",
							"num_fd_components = 6\r\n",
							"year_start = 1990\r\n",
							"year_end = 2022\r\n",
							"\r\n",
							"eora_years = np.linspace(year_start, year_end, num = year_end - year_start + 1).astype(int).astype(str)\r\n",
							"\r\n",
							"for i in range(len(eora_years)):\r\n",
							"    #Read in the data\r\n",
							"    fd_matrix_path = 'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_'+eora_years[i]+'_bp/Eora26_'+eora_years[i]+'_bp_FD.txt'\r\n",
							"    id_matrix_path = 'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_'+eora_years[i]+'_bp/Eora26_'+eora_years[i]+'_bp_T.txt'\r\n",
							"    va_matrix_path = 'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_'+eora_years[i]+'_bp/Eora26_'+eora_years[i]+'_bp_VA.txt'\r\n",
							"\r\n",
							"    fd_matrix = spark.read.load(fd_matrix_path, format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"    id_matrix = spark.read.load(id_matrix_path, format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"    va_matrix = spark.read.load(va_matrix_path, format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"    print(\"Data read for year: \" + eora_years[i])\r\n",
							"\r\n",
							"    # Compute Stats\r\n",
							"    va_total_cs = va_matrix.sum(axis = 0)\r\n",
							"    FD = fd_matrix.reshape((num_cntry*num_sectors + 1), num_fd_components, -1)\r\n",
							"    FD = FD.sum(axis=1)\r\n",
							"    FD = np.squeeze(FD) # Squeeze to remove single-dimensional entries\r\n",
							"\r\n",
							"    GRTR_INT_cs_cs = id_matrix[0:(num_cntry*num_sectors), 0:(num_cntry*num_sectors)]\r\n",
							"    GRTR_FNL_cs_c = FD[0:num_cntry*num_sectors,0:num_cntry]\r\n",
							"    VALUE_cs = va_total_cs[0:(num_cntry*num_sectors)]\r\n",
							"\r\n",
							"    # Initialize empty list to hold blocks\r\n",
							"    imtx_cs_c = []\r\n",
							"    imtx_cs_cs = []\r\n",
							"    imtx_c_cs=[]\r\n",
							"    imtx_cs_ck = []\r\n",
							"\r\n",
							"    # Create block matrix\r\n",
							"    iblk_cs_c = np.ones((num_sectors, 1))  # Create num_sectors x 1 vector of ones\r\n",
							"    iblk_cs_cs = np.ones((num_sectors,num_sectors))\r\n",
							"    ivector = np.ones((1, num_sectors))\r\n",
							"    iblk_cs_ck = np.ones((num_sectors, num_fd_components))\r\n",
							"\r\n",
							"    # Construct block diagonal matrix\r\n",
							"    for j in range(num_cntry):\r\n",
							"        if j == 0:\r\n",
							"            imtx_cs_c = iblk_cs_c  # Initialize with the first block\r\n",
							"            imtx_cs_cs = iblk_cs_cs\r\n",
							"            imtx_c_cs = ivector\r\n",
							"            imtx_cs_ck = iblk_cs_ck\r\n",
							"\r\n",
							"        else:\r\n",
							"            imtx_cs_c = block_diag(imtx_cs_c, iblk_cs_c) \r\n",
							"            imtx_cs_cs = block_diag(imtx_cs_cs, iblk_cs_cs) \r\n",
							"            imtx_c_cs = block_diag(imtx_c_cs, ivector)\r\n",
							"            imtx_cs_ck = block_diag(imtx_cs_ck, iblk_cs_ck)\r\n",
							"\r\n",
							"    imtx_c_c = np.eye(num_cntry)\r\n",
							"\r\n",
							"    #Gross Output\r\n",
							"    GO_cs_c = GRTR_INT_cs_cs.reshape(num_cntry*num_sectors, num_sectors, -1)\r\n",
							"    GO_cs_c = GO_cs_c.sum(axis = 1)\r\n",
							"    GO_cs_c = np.squeeze(GO_cs_c)\r\n",
							"    GO_cs_c = GO_cs_c + GRTR_FNL_cs_c\r\n",
							"    GO_cs = GO_cs_c.sum(axis = 1)\r\n",
							"    GO_c_c = np.matmul(imtx_c_cs,GO_cs_c)\r\n",
							"    elementwise_GO_product =  np.tile(GO_cs[:, np.newaxis],(1,num_cntry)) * imtx_cs_c\r\n",
							"    summed_GO_result = elementwise_GO_product.sum(axis=0)\r\n",
							"    GO_c = summed_GO_result.T\r\n",
							"\r\n",
							"    #Value Added\r\n",
							"    elementwise_VALUE_product = np.tile(VALUE_cs[:, np.newaxis], (1, num_cntry)) * imtx_cs_c\r\n",
							"    summed_VALUE_result = elementwise_VALUE_product.sum(axis=0)\r\n",
							"    VALUE_c = summed_VALUE_result.T\r\n",
							"\r\n",
							"    #Derived value added\r\n",
							"    Inputs_cs = GRTR_INT_cs_cs.sum(axis = 0)\r\n",
							"    replicated_Inputs_cs = np.tile(Inputs_cs[:, np.newaxis], (1, num_cntry)) \r\n",
							"    elementwise_INPUTS_product = replicated_Inputs_cs * imtx_cs_c\r\n",
							"    summed_INPUTS_result = elementwise_INPUTS_product.sum(axis = 0)\r\n",
							"    Inputs_c = summed_INPUTS_result.T\r\n",
							"\r\n",
							"    #VA = Gross Outputs - Inputs\r\n",
							"    VALUE_derived_cs = GO_cs - Inputs_cs\r\n",
							"    replicated_VALUE_derived_cs = np.tile(VALUE_derived_cs[:, np.newaxis], (1, num_cntry))\r\n",
							"    elementwise_VALUE_derived_product = replicated_VALUE_derived_cs * imtx_cs_c\r\n",
							"    summed_VALUE_derived_result = elementwise_VALUE_derived_product.sum(axis = 0)\r\n",
							"    VALUE_derived_c = summed_VALUE_derived_result.T\r\n",
							"\r\n",
							"    #Gross Exports\r\n",
							"    ones_cs_cs_array = np.ones((num_cntry*num_sectors))\r\n",
							"    EXGR_INT_cs_cs = GRTR_INT_cs_cs * (ones_cs_cs_array - imtx_cs_cs)\r\n",
							"\r\n",
							"    EXGR_INT_cs_c = np.full((num_cntry * num_sectors, num_cntry), np.nan)\r\n",
							"    for k in range(num_cntry):\r\n",
							"        EXGR_INT_cs_c[:, k] = np.sum(EXGR_INT_cs_cs[:, (k * num_sectors):(num_sectors * (k + 1))], axis=1)\r\n",
							"\r\n",
							"    EXGR_INT_cs = EXGR_INT_cs_cs.sum(axis = 1)\r\n",
							"\r\n",
							"    replicated_EXGR_INT_cs = np.tile(EXGR_INT_cs[:, np.newaxis], (1, num_cntry))\r\n",
							"    elementwise_EXGR_INT_cs_product = replicated_EXGR_INT_cs * imtx_cs_c\r\n",
							"    summed_EXGR_INT_cs_result = elementwise_EXGR_INT_cs_product.sum(axis = 0)\r\n",
							"    EXGR_INT_c = summed_EXGR_INT_cs_result.T\r\n",
							"\r\n",
							"    ones_cs_c_array = np.ones((num_cntry*num_sectors, num_cntry))\r\n",
							"    EXGR_FNL_cs_c = GRTR_FNL_cs_c * (ones_cs_c_array - imtx_cs_c)\r\n",
							"\r\n",
							"    EXGR_FNL_cs = EXGR_FNL_cs_c * (ones_cs_c_array - imtx_cs_c)\r\n",
							"    EXGR_FNL_cs = EXGR_FNL_cs.sum(axis = 1)\r\n",
							"\r\n",
							"    EXGR_FNL_c = np.tile(EXGR_FNL_cs[:, np.newaxis],(1, num_cntry)) * imtx_cs_c\r\n",
							"    EXGR_FNL_c = EXGR_FNL_c.sum(axis = 0).T\r\n",
							"\r\n",
							"    EXGR_cs_c = EXGR_INT_cs_c + EXGR_FNL_cs_c\r\n",
							"    EXGR_c_c = np.matmul(imtx_c_cs, EXGR_cs_c)\r\n",
							"\r\n",
							"    EXGR_cs = EXGR_INT_cs + EXGR_FNL_cs\r\n",
							"    EXGR_c = EXGR_INT_c + EXGR_FNL_c\r\n",
							"\r\n",
							"    #Gross Imports\r\n",
							"    ones_cs_array = np.ones((num_cntry * num_sectors))\r\n",
							"    IMGR_INT_cs = GRTR_INT_cs_cs * (ones_cs_array - imtx_cs_cs)\r\n",
							"    IMGR_INT_cs = IMGR_INT_cs.sum(axis = 0)\r\n",
							"\r\n",
							"    IMGR_INT_c = np.tile(IMGR_INT_cs[:, np.newaxis],(1, num_cntry)) * imtx_cs_c\r\n",
							"    IMGR_INT_c = IMGR_INT_c.sum(axis = 0).T\r\n",
							"\r\n",
							"    ones_cs_c_array = np.ones((num_cntry * num_sectors, num_cntry))\r\n",
							"    IMGR_FNL_c = GRTR_FNL_cs_c * (ones_cs_c_array - imtx_cs_c)\r\n",
							"    IMGR_FNL_c = IMGR_FNL_c.sum(axis = 0).T\r\n",
							"\r\n",
							"    IMGR_c = IMGR_INT_c + IMGR_FNL_c\r\n",
							"\r\n",
							"    #Gross Trade Balance\r\n",
							"    BALGR_c = EXGR_c - IMGR_c\r\n",
							"\r\n",
							"    #Demand for Domestic Inputs (Use of Domestic Intermediates)\r\n",
							"    DDGR_INT_cs = GRTR_INT_cs_cs * imtx_cs_cs\r\n",
							"    DDGR_INT_cs = DDGR_INT_cs.sum(axis = 0).T\r\n",
							"\r\n",
							"    DDGR_INT_c = np.tile(DDGR_INT_cs[:, np.newaxis],(1, num_cntry)) * imtx_cs_c\r\n",
							"    DDGR_INT_c = DDGR_INT_c.sum(axis = 0).T\r\n",
							"\r\n",
							"    DDGR_FNL_c = GRTR_FNL_cs_c * imtx_cs_c\r\n",
							"    DDGR_FNL_c = DDGR_FNL_c.sum(axis = 0).T\r\n",
							"\r\n",
							"    #Domestic and Foreign Final Demand\r\n",
							"    GRTR_FNL_DOM_cs_c = GRTR_FNL_cs_c * imtx_cs_c\r\n",
							"    GRTR_FNL_DOM_cs = GRTR_FNL_DOM_cs_c.sum(axis = 1)\r\n",
							"\r\n",
							"    #By sector\r\n",
							"    GRTR_FNL_DOM_cs_ck = fd_matrix[0:num_cntry*num_sectors, 0:num_cntry*num_fd_components] * imtx_cs_ck\r\n",
							"\r\n",
							"    ##Sum across the third dimension, across countries for each of the 6 components of final demand\r\n",
							"    GRTR_FNL_DOM_cs_nfd = GRTR_FNL_DOM_cs_ck.reshape((num_cntry*num_sectors), num_fd_components, -1)\r\n",
							"    GRTR_FNL_DOM_cs_nfd = GRTR_FNL_DOM_cs_nfd.sum(axis = 2)\r\n",
							"\r\n",
							"    #Foreign Demand\r\n",
							"    GRTR_FNL_FOR_cs_c = GRTR_FNL_cs_c * (ones_cs_c_array - imtx_cs_c)\r\n",
							"    GRTR_FNL_FOR_cs = GRTR_FNL_FOR_cs_c.sum(axis = 1)\r\n",
							"\r\n",
							"    ##By sector\r\n",
							"    ones_cs_ck_array = np.ones((num_cntry*num_sectors, num_cntry*num_fd_components))\r\n",
							"    GRTR_FNL_FOR_cs_ck = fd_matrix[0:num_cntry*num_sectors, 0:num_cntry*num_fd_components] * (ones_cs_ck_array - imtx_cs_ck)\r\n",
							"\r\n",
							"    ##Sum across the third dimension, across countries for each of the 6 components of final demand\r\n",
							"    GRTR_FNL_FOR_cs_nfd = GRTR_FNL_FOR_cs_ck.reshape((num_cntry*num_sectors), num_fd_components, -1)\r\n",
							"    GRTR_FNL_FOR_cs_nfd = GRTR_FNL_FOR_cs_nfd.sum(axis = 2)\r\n",
							"\r\n",
							"    #VA Vector\r\n",
							"    with warnings.catch_warnings():\r\n",
							"        warnings.simplefilter('ignore')\r\n",
							"        Amat = GRTR_INT_cs_cs / np.tile(GO_cs[:, np.newaxis], (1, num_cntry * num_sectors))\r\n",
							"\r\n",
							"    Amat[np.isnan(Amat)] = 0\r\n",
							"    Amat[np.isinf(Amat)] = 0\r\n",
							"\r\n",
							"    #VA shares\r\n",
							"    va_vec_cs = 1 - np.sum(Amat)\r\n",
							"    V_hat = np.eye((num_cntry * num_sectors)) - np.diag(Amat.sum(axis = 0))\r\n",
							"\r\n",
							"    #Leontief inverse\r\n",
							"    IminusA = np.eye((num_cntry * num_sectors)) - Amat\r\n",
							"    Bmat = np.linalg.inv(IminusA)\r\n",
							"\r\n",
							"    #Total Value Added by country-sector\r\n",
							"    BY = np.matmul(Bmat, GRTR_FNL_cs_c.sum(axis = 1))\r\n",
							"    va_cs = va_vec_cs * BY\r\n",
							"\r\n",
							"    #DVA and FVA of gross exports (From V*B*E)\r\n",
							"    TiVA = V_hat @ Bmat @ np.diag(EXGR_cs)\r\n",
							"\r\n",
							"    EXGR_DVA_cs = np.sum(TiVA * imtx_cs_cs, axis = 0).T\r\n",
							"    EXGR_FVA_cs = np.sum(TiVA * (ones_cs_array - imtx_cs_cs), axis = 0).T\r\n",
							"\r\n",
							"    EXGR_DVA_c = np.tile(EXGR_DVA_cs[:, np.newaxis],(1, num_cntry)) * imtx_cs_c\r\n",
							"    EXGR_DVA_c = EXGR_DVA_c.sum(axis = 0).T\r\n",
							"\r\n",
							"    EXGR_FVA_c = np.tile(EXGR_FVA_cs[:, np.newaxis],(1, num_cntry)) * imtx_cs_c\r\n",
							"    EXGR_FVA_c = EXGR_FVA_c.sum(axis = 0).T\r\n",
							"\r\n",
							"    VS1_cs = np.sum(TiVA * (ones_cs_array - imtx_cs_cs), axis = 1)\r\n",
							"    VS1_c = np.tile(VS1_cs[:, np.newaxis], (1, num_cntry)) * imtx_cs_c\r\n",
							"    VS1_c = VS1_c.sum(axis = 0).T\r\n",
							"\r\n",
							"    #Compute VA matrices (from V*B*Y)\r\n",
							"    VA_cs_c = V_hat @ Bmat @ GRTR_FNL_cs_c\r\n",
							"\r\n",
							"    ones_c_c_array = np.ones((num_cntry, num_cntry))\r\n",
							"    VAX_cs_c = VA_cs_c * (ones_cs_c_array - imtx_cs_c)\r\n",
							"    VA_c_c = np.matmul(imtx_c_cs, VA_cs_c)\r\n",
							"\r\n",
							"    #Value added of exports only (exclude value_added of demestic goods)\r\n",
							"    VAX_c_c = VA_c_c * (ones_c_c_array - np.eye(num_cntry))\r\n",
							"\r\n",
							"    VAX_c = VAX_c_c.sum(axis = 1)\r\n",
							"\r\n",
							"    #Koopman et al. Equation 36 Terms\r\n",
							"    VAX1_cs_c = V_hat @ (Bmat * imtx_cs_cs) @ (GRTR_FNL_cs_c * (ones_cs_c_array - imtx_cs_c))\r\n",
							"    VAX1_c_c = np.matmul(imtx_c_cs, VAX1_cs_c) # aggregate across rows by country\r\n",
							"    VAX1_c = VAX1_c_c.sum(axis = 1)\r\n",
							"\r\n",
							"    VAX2_cs_c = V_hat @ (Bmat * (ones_cs_array - imtx_cs_cs)) @ (GRTR_FNL_cs_c  - imtx_cs_c)\r\n",
							"    VAX2_c_c = np.matmul(imtx_c_cs, VAX2_cs_c) # aggregate across rows by country\r\n",
							"    VAX2_c = VAX2_c_c.sum(axis = 1)\r\n",
							"\r\n",
							"    VAX3_cs_c_sum1 = V_hat @ (Bmat * (ones_cs_array - imtx_cs_cs)) @ (GRTR_FNL_cs_c * (ones_cs_c_array - imtx_cs_c))\r\n",
							"    VAX3_cs_c_sum2 = VAX3_cs_c_sum1 * (ones_cs_c_array - imtx_cs_c)\r\n",
							"    VAX3_c_c = np.matmul(imtx_c_cs, VAX3_cs_c_sum2) # aggregate across rows by country\r\n",
							"    VAX3_c = VAX3_c_c.sum(axis = 1)\r\n",
							"\r\n",
							"    DVA4_cs_c = V_hat @ (Bmat * (ones_cs_array - imtx_cs_cs)) @ (GRTR_FNL_cs_c * (ones_cs_c_array - imtx_cs_c))\r\n",
							"    DVA4_c_c = np.matmul(imtx_c_cs,DVA4_cs_c) * imtx_c_c # aggregate across rows by country, and take just the diagonal elements\r\n",
							"    DVA4_c = DVA4_c_c.sum(axis = 1)\r\n",
							"\r\n",
							"    eye_inverse = np.linalg.inv(np.eye((num_cntry * num_sectors)))\r\n",
							"    DVA5_cs_c = V_hat @ (Bmat * (ones_cs_array - imtx_cs_cs)) @ (Amat * (ones_cs_array - imtx_cs_cs)) @\\\r\n",
							"                ((eye_inverse - Amat) * imtx_cs_cs) @ (GRTR_FNL_cs_c * imtx_cs_c)\r\n",
							"    DVA5_c_c = np.matmul(imtx_c_cs,DVA5_cs_c) * imtx_c_c # aggregate across rows by country, and take just the diagonal elements\r\n",
							"    DVA5_c = DVA5_c_c.sum(axis = 1)\r\n",
							"\r\n",
							"    DVA6_c = EXGR_DVA_c - VAX_c - DVA4_c - DVA5_c\r\n",
							"\r\n",
							"    #Foreign Value Added in Domestic Final Demand\r\n",
							"    DFD_FVA_c = VAX_c_c.sum(axis = 0)\r\n",
							"\r\n",
							"    #Export Country Data\r\n",
							"    print(\"Exporting Country Statistics for year: \" + eora_years[i])\r\n",
							"\r\n",
							"    country_data = {\r\n",
							"    'year': eora_years[i],\r\n",
							"    'gross_output': GO_c,\r\n",
							"    'gross_exports_intermediate': EXGR_INT_c,\r\n",
							"    'gross_exports_final': EXGR_FNL_c,\r\n",
							"    'gross_exports': EXGR_c,\r\n",
							"    'gross_imports_intermediate': IMGR_INT_c,\r\n",
							"    'gross_imports_final': IMGR_FNL_c,\r\n",
							"    'gross_imports': IMGR_c,\r\n",
							"    'gross_trade_balance': BALGR_c,\r\n",
							"    'gross_domestic_demand_intermediate': DDGR_INT_c,\r\n",
							"    'gross_domestic_demand_final': DDGR_FNL_c,\r\n",
							"    'exports_domesitc_value_added': EXGR_DVA_c,\r\n",
							"    'exports_foreign_value_added' : EXGR_FVA_c,\r\n",
							"    'exports_used_for_export_production': VS1_c,\r\n",
							"    'value_added_exports': VAX_c,\r\n",
							"    'foreign_value_added_domestic_demand': DFD_FVA_c,\r\n",
							"    'export_value_added_one': VAX1_c,\r\n",
							"    'export_value_added_two': VAX2_c,\r\n",
							"    'export_value_added_three': VAX3_c,\r\n",
							"    'domestic_value_added_four': DVA4_c,\r\n",
							"    'domestic_value_added_five': DVA5_c,\r\n",
							"    'domestic_value_added_six': DVA6_c,\r\n",
							"    'gross_value_added': VALUE_c,\r\n",
							"    'gross_derived_value_added': VALUE_derived_c\r\n",
							"    }\r\n",
							"\r\n",
							"    country_data_file_path = 'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_Country_Statistics/eora26-country-stats-'+ eora_years[i] +'.csv'\r\n",
							"    country_data_frame = pd.DataFrame(country_data)\r\n",
							"\r\n",
							"    # Convert DataFrame to CSV strings, export to folders\r\n",
							"    country_data_csv_buffer = io.StringIO()\r\n",
							"    country_data_frame.to_csv(country_data_csv_buffer, index=False)\r\n",
							"    country_data_csv_string = country_data_csv_buffer.getvalue()\r\n",
							"    mssparkutils.fs.put(country_data_file_path, country_data_csv_string, overwrite=True)\r\n",
							"\r\n",
							"    #Export Country Sector Data\r\n",
							"    print(\"Exporting Country-Sector Statistics for year: \" + eora_years[i])\r\n",
							"    country_sector_data = {\r\n",
							"    'year': eora_years[i],\r\n",
							"    'gross_output': GO_cs,\r\n",
							"    'gross_exports_intermediate': EXGR_INT_cs,\r\n",
							"    'gross_exports_final': EXGR_FNL_cs,\r\n",
							"    'gross_exports': EXGR_cs,\r\n",
							"    'gross_imports_intermediate': IMGR_INT_cs,\r\n",
							"    'gross_intermediate_domestic_demand': DDGR_INT_cs,\r\n",
							"    'exports_domesitc_value_added': EXGR_DVA_cs,\r\n",
							"    'exports_foreign_value_added': EXGR_FVA_cs,\r\n",
							"    'exports_used_for_export_production': VS1_cs,\r\n",
							"    'gross_value_added': VALUE_cs,\r\n",
							"    'gross_derived_value_added': VALUE_derived_cs\r\n",
							"    }\r\n",
							"\r\n",
							"    country_sector_data_file_path = 'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_Country_Sector_Statistics/eora26-country-sector-stats-'+ eora_years[i] +'.csv' \r\n",
							"    country_sector_data_frame = pd.DataFrame(country_sector_data)\r\n",
							"\r\n",
							"    # Convert DataFrame to CSV strings, export to folders\r\n",
							"    country_sector_data_csv_buffer = io.StringIO()\r\n",
							"    country_sector_data_frame.to_csv(country_sector_data_csv_buffer, index=False)\r\n",
							"    country_sector_data_csv_string = country_sector_data_csv_buffer.getvalue()\r\n",
							"    mssparkutils.fs.put(country_sector_data_file_path, country_sector_data_csv_string, overwrite=True)\r\n",
							"\r\n",
							"print(\"Done!\")\r\n",
							"\r\n",
							"\r\n",
							""
						],
						"outputs": [],
						"execution_count": 2
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/EORA_Country_Sector_Explorer')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ac2sparkpooldev",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "27f5b68d-f1a3-4f15-bd15-910d5f3189d2"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Synapse/workspaces/ac2-synapse-ws-dev/bigDataPools/ac2sparkpooldev",
						"name": "ac2sparkpooldev",
						"type": "Spark",
						"endpoint": "https://ac2-synapse-ws-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ac2sparkpooldev",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"print(\"Im Awake\")"
						],
						"outputs": [],
						"execution_count": 65
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import pandas as pd"
						],
						"outputs": [],
						"execution_count": 88
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"dataframes = []\r\n",
							"files = mssparkutils.fs.ls(f\"abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_Country_Sector_Statistics/\")\r\n",
							"for file in files:\r\n",
							"    # Check if the file is a CSV file\r\n",
							"    if file.name.endswith(\".csv\"):\r\n",
							"        # Import the CSV file into a DataFrame\r\n",
							"        df = spark.read.csv(f\"abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_Country_Sector_Statistics/{file.name}\", header=\"true\", inferSchema=\"true\")\r\n",
							"\r\n",
							"        # Add the DataFrame to the list\r\n",
							"        dataframes.append(df)"
						],
						"outputs": [],
						"execution_count": 105
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"new_column_df = spark.read.csv(f\"abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA_Labels/Country+Sector_Labels.csv\", header=\"true\", inferSchema=\"true\")\r\n",
							"\r\n",
							"# Iterate through the list of dataframes\r\n",
							"for i in range(len(dataframes)):\r\n",
							"    # Convert the Spark dataframe to a pandas dataframe\r\n",
							"    frame_pd = dataframes[i].toPandas()\r\n",
							"    # Add the new column to the pandas dataframe\r\n",
							"    frame_pd[\"Country+Sector\"] = new_column_df.toPandas()[\"Country+Sector\"]\r\n",
							"    # Move the new column to the first position\r\n",
							"    cols = frame_pd.columns.tolist()\r\n",
							"    cols = [\"Country+Sector\"] + [col for col in cols if col != \"Country+Sector\"]\r\n",
							"    frame_pd = frame_pd[cols]"
						],
						"outputs": [],
						"execution_count": 110
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/EORA_Domestic_Trade')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ac2sparkpooldev",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "df86d2e0-f8de-4688-a803-2e37af9876d2"
					}
				},
				"metadata": {
					"saveOutput": true,
					"synapse_widget": {
						"version": "0.1"
					},
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Synapse/workspaces/ac2-synapse-ws-dev/bigDataPools/ac2sparkpooldev",
						"name": "ac2sparkpooldev",
						"type": "Spark",
						"endpoint": "https://ac2-synapse-ws-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ac2sparkpooldev",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import numpy as np\r\n",
							"import pandas as pd"
						],
						"outputs": [],
						"execution_count": 40
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"fd_matrix = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_1990_bp/Eora26_1990_bp_FD.txt', format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"q_matrix = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_1990_bp/Eora26_1990_bp_Q.txt', format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"qy_matrix = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_1990_bp/Eora26_1990_bp_QY.txt', format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"t_matrix = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_1990_bp/Eora26_1990_bp_T.txt', format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"va_matrix = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_1990_bp/Eora26_1990_bp_VA.txt', format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)"
						],
						"outputs": [],
						"execution_count": 38
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Define the size of each chunk (26 columns)\r\n",
							"chunk_size = 26\r\n",
							"\r\n",
							"# Get the number of rows and columns in the original matrix\r\n",
							"t_num_rows, t_num_columns = t_matrix.shape\r\n",
							"\r\n",
							"# Calculate the number of chunks (excluding the last column)\r\n",
							"t_num_chunks = (t_num_columns - 1) // chunk_size\r\n",
							"\r\n",
							"# Initialize a new matrix to store the sums\r\n",
							"t_sum_matrix = np.zeros((t_num_rows, t_num_chunks + 1))\r\n",
							"\r\n",
							"# Sum every 26 columns for each row (excluding the last column)\r\n",
							"for i in range(num_chunks):\r\n",
							"    start_col = i * chunk_size\r\n",
							"    end_col = (i + 1) * chunk_size\r\n",
							"    t_sum_matrix[:, i] = np.sum(t_matrix[:, start_col:end_col], axis=1)"
						],
						"outputs": [],
						"execution_count": 25
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Add the values from the last column to the new matrix\r\n",
							"t_sum_matrix[:, -1] = t_matrix[:, -1]\r\n",
							"\r\n",
							"# Display the shape of the new sum matrix\r\n",
							"print(f\"T Sum Matrix Shape: {t_sum_matrix.shape}\")\r\n",
							"\r\n",
							"# Get the number of rows and columns in the sum_matrix\r\n",
							"t_sum_num_rows, t_sum_num_columns = t_sum_matrix.shape"
						],
						"outputs": [],
						"execution_count": 29
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Initialize a new square matrix to store the sums\r\n",
							"t_final_matrix = np.zeros((t_num_chunks + 1, t_num_chunks + 1))\r\n",
							"\r\n",
							"# Sum every 26 rows for each column (excluding the last row)\r\n",
							"for i in range(num_chunks):\r\n",
							"    start_row = i * chunk_size\r\n",
							"    end_row = (i + 1) * chunk_size\r\n",
							"    t_final_matrix[i, :] = np.sum(t_sum_matrix[start_row:end_row, :], axis=0)"
						],
						"outputs": [],
						"execution_count": 30
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Add the values from the last row to the new matrix\r\n",
							"t_final_matrix[-1, :] = t_sum_matrix[-1, :]\r\n",
							"\r\n",
							"print(f\"Final T Matrix Shape: {t_final_matrix.shape}\")"
						],
						"outputs": [],
						"execution_count": 31
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Define the one_diagonal_matrix\r\n",
							"t_one_diag_matrix = np.eye(t_final_matrix.shape[0])\r\n",
							"\r\n",
							"# Multiply final_matrix with one_diagonal_matrix element-wise\r\n",
							"t_result_matrix = np.multiply(t_final_matrix, t_one_diag_matrix)"
						],
						"outputs": [],
						"execution_count": 35
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"print(f\"T Result Matrix Shape: {t_result_matrix.shape}\")"
						],
						"outputs": [],
						"execution_count": 36
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Define the size of each chunk (6 columns)\r\n",
							"fd_chunk_size = 6\r\n",
							"\r\n",
							"# Get the number of rows and columns in the original matrix\r\n",
							"fd_num_rows, fd_num_columns = fd_matrix.shape\r\n",
							"\r\n",
							"# Calculate the number of chunks (excluding the last column)\r\n",
							"fd_num_chunks = (fd_num_columns - 1) // fd_chunk_size\r\n",
							"\r\n",
							"# Initialize a new matrix to store the sums\r\n",
							"fd_sum_matrix = np.zeros((fd_num_rows, fd_num_chunks + 1))\r\n",
							"\r\n",
							"# Sum every 26 columns for each row (excluding the last column)\r\n",
							"for i in range(fd_num_chunks):\r\n",
							"    start_col = i * fd_chunk_size\r\n",
							"    end_col = (i + 1) * fd_chunk_size\r\n",
							"    fd_sum_matrix[:, i] = np.sum(fd_matrix[:, start_col:end_col], axis=1)\r\n",
							"\r\n",
							"# Add the values from the last column to the new matrix\r\n",
							"fd_sum_matrix[:, -1] = fd_matrix[:, -1]\r\n",
							"\r\n",
							"# Define the size of each chunk (26 rows)\r\n",
							"fd_sum_chunk_size = 26\r\n",
							"\r\n",
							"# Get the number of rows and columns in the sum_matrix\r\n",
							"fd_sum_num_rows, fd_sum_num_columns = fd_sum_matrix.shape\r\n",
							"\r\n",
							"# Calculate the number of chunks (excluding the last row)\r\n",
							"fd_sum_num_chunks = (fd_sum_num_rows - 1) // fd_sum_chunk_size\r\n",
							"\r\n",
							"# Initialize a new square matrix to store the sums\r\n",
							"fd_final_matrix = np.zeros((fd_sum_num_chunks + 1, fd_sum_num_chunks + 1))\r\n",
							"\r\n",
							"# Sum every 26 rows for each column (excluding the last row)\r\n",
							"for i in range(fd_sum_num_chunks):\r\n",
							"    start_row = i * fd_sum_chunk_size\r\n",
							"    end_row = (i + 1) * fd_sum_chunk_size\r\n",
							"    fd_final_matrix[i, :] = np.sum(fd_sum_matrix[start_row:end_row, :], axis=0)\r\n",
							"\r\n",
							"# Add the values from the last row to the new matrix\r\n",
							"fd_final_matrix[-1, :] = fd_sum_matrix[-1, :]\r\n",
							"\r\n",
							"# Create a square matrix of size 190 by 190 with ones on the non-diagonal elements\r\n",
							"fd_one_diag_matrix = np.ones((190, 190)) - np.eye(190)\r\n",
							"\r\n",
							"# Multiply final_matrix with one_diagonal_matrix element-wise\r\n",
							"fd_result_matrix = np.multiply(fd_final_matrix, fd_one_diag_matrix)\r\n",
							"\r\n",
							"# Display the shape of the result2 matrix\r\n",
							"print(f\"FD Result Matrix Shape: {fd_result_matrix.shape}\")"
						],
						"outputs": [],
						"execution_count": 39
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"chunk_size = 26\r\n",
							"sum_matrix = np.zeros((t_matrix.shape[0], (t_matrix.shape[1] - 1) // chunk_size + 1))\r\n",
							"for i in range((t_matrix.shape[1] - 1) // chunk_size):\r\n",
							"    sum_matrix[:, i] = np.sum(t_matrix[:, i * chunk_size:(i + 1) * chunk_size], axis=1)\r\n",
							"sum_matrix[:, -1] = t_matrix[:, -1]"
						],
						"outputs": []
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/EORA_FD_T_Matrices_Generation')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ac2sparkpooldev",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "00187183-4978-4eca-89fb-b13392dbca46"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Synapse/workspaces/ac2-synapse-ws-dev/bigDataPools/ac2sparkpooldev",
						"name": "ac2sparkpooldev",
						"type": "Spark",
						"endpoint": "https://ac2-synapse-ws-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ac2sparkpooldev",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import numpy as np\r\n",
							"import pandas as pd\r\n",
							"import os\r\n",
							"import io"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"2 OCT 2024\r\n",
							"\r\n",
							"I need to put labels back on these/create them. For the 190x190, thats pretty easy as its just the countries against the countries. The full-scale is harder, BUT I think it works like this: For the T matrix, it's the T labels symmetrically. So take the labels, and CtrlC/CtrlV against the rows and columns. For the FD, I think (given its 4915*1140 dim) its FD along the top, T labels on the rows.\r\n",
							"\r\n",
							"The why is to have something when query against when trying to find gross output (X = AX + Y, where X is the gross output AX is the intermediate demand, and Y is the final demand). So if we want to find the monetary value of the gross output of Swedish metal products we'd (pseudocode): \r\n",
							"\r\n",
							"SELECT * FROM T_2022 WHERE ISO3 == \"SWE\" AND SECTOR == \"Metal Products\"\r\n",
							"SELECT * FROM FD_2022 WHERE ISO3 == \"SWE\" AND SECTOR == \"Metal Products\"\r\n",
							"\r\n",
							"SUM (somewhere and somehow)\r\n",
							"\r\n",
							"Result!\r\n",
							"\r\n",
							"Gross exports is trickier. The logic is the same (pick country and sector, sum to the right), but (per page 7 of the IMF working paper) we need to remove cells from the T matrix that are internal consumption (so metal products that are used to make more metal products) matrix, and we need to remove the values from the FD matrix where those goods were internally consumed as final demand.\r\n",
							"\r\n",
							"For the FD matrix, I'm assuming this means we'd need to zero out the 6 columns relating to (continuing the example above) Sweden. So the values in the \"SWE, Final demand, Household final consumption P.3h\tSWE, Final demand, Non-profit institutions serving households P.3n\tSWE, Final demand, Government final consumption P.3g\tSWE, Final demand, Gross fixed capital formation P.51\tSWE, Final demand, Changes in inventories P.52\tSWE, Final demand, Acquisitions less disposals of valuables P.53\" would all get set to zeros for this specific calculation. For the T matrix, there would be 26 values (one for each sector)\r\n",
							"\r\n",
							"I think."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"outputs_hidden": false
							}
						},
						"source": [
							"#Creates the consolidated (190x190, so sector summed, per country) T (Intermediate Demand) Matrices for the EORA Data. ***WARNING*** Depending on size of cluster and number of years, running this cell can take several minutes.\r\n",
							"\r\n",
							"source_dir = \"abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/\"\r\n",
							"destination_dir = \"abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA26/Intermediate Demand (T) Matrices/\"\r\n",
							"\r\n",
							"for year in range(1990, 2023):\r\n",
							"    # Construct the folder and file paths\r\n",
							"    subfolder = f\"Eora26_{year}_bp\"\r\n",
							"    folder_path = os.path.join(source_dir, subfolder)\r\n",
							"    file_path = os.path.join(folder_path, f\"Eora26_{year}_bp_T.txt\")\r\n",
							"    \r\n",
							"    matrix = spark.read.load(file_path, format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"\r\n",
							"    print(f\"Original Matrix Shape for {year}: {matrix.shape}\")\r\n",
							"\r\n",
							"    chunk_size = 26\r\n",
							"\r\n",
							"    # Get the number of rows and columns in the original matrix\r\n",
							"    num_rows, num_columns = matrix.shape\r\n",
							"\r\n",
							"    # Calculate the number of chunks (excluding the last column)\r\n",
							"    num_chunks = (num_columns - 1) // chunk_size\r\n",
							"\r\n",
							"    # Initialize a new matrix to store the sums\r\n",
							"    sum_matrix = np.zeros((num_rows, num_chunks + 1))\r\n",
							"\r\n",
							"    # Sum every 26 columns for each row (excluding the last column)\r\n",
							"    for i in range(num_chunks):\r\n",
							"        start_col = i * chunk_size\r\n",
							"        end_col = (i + 1) * chunk_size\r\n",
							"        sum_matrix[:, i] = np.sum(matrix[:, start_col:end_col], axis=1)\r\n",
							"\r\n",
							"    sum_matrix[:, -1] = matrix[:, -1]\r\n",
							"\r\n",
							"    print(f\"T Sum Matrix Shape: {sum_matrix.shape}\")\r\n",
							"\r\n",
							"    # Get the number of rows and columns in the sum_matrix\r\n",
							"    num_rows, num_columns = sum_matrix.shape\r\n",
							"\r\n",
							"    # Calculate the number of chunks (excluding the last row)\r\n",
							"    num_chunks = (num_rows - 1) // chunk_size\r\n",
							"\r\n",
							"    # Initialize a new square matrix to store the sums\r\n",
							"    final_matrix = np.zeros((num_chunks + 1, num_columns))\r\n",
							"\r\n",
							"    # Sum every 26 rows for each column (excluding the last row)\r\n",
							"    for i in range(num_chunks):\r\n",
							"        start_row = i * chunk_size\r\n",
							"        end_row = (i + 1) * chunk_size\r\n",
							"        final_matrix[i, :] = np.sum(sum_matrix[start_row:end_row, :], axis=0)\r\n",
							"\r\n",
							"    # Add the values from the last row to the new matrix\r\n",
							"    final_matrix[-1, :] = sum_matrix[-1, :]\r\n",
							"\r\n",
							"    print(f\"Final Matrix Shape for {year}: {final_matrix.shape}\")\r\n",
							"    \r\n",
							"    # Define the one_diagonal_matrix (replace this with your actual matrix)\r\n",
							"    one_diagonal_matrix = np.eye(final_matrix.shape[0])\r\n",
							"\r\n",
							"    # Multiply final_matrix with one_diagonal_matrix element-wise\r\n",
							"    result_matrix = np.multiply(final_matrix, one_diagonal_matrix)\r\n",
							"\r\n",
							"    print(f\"Result Matrix Shape for {year}: {result_matrix.shape}\")\r\n",
							"\r\n",
							"    output = StringIO()\r\n",
							"    np.savetxt(output, result_matrix, delimiter=\",\")\r\n",
							"\r\n",
							"    # Save the result_matrix as a CSV file\r\n",
							"    output_folder = os.path.join(destination_dir, f\"T_{year}.csv\")\r\n",
							"    mssparkutils.fs.put(output_folder, output.getvalue())"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Creates the consolidated (190x190, so sector summed, per country) FD (Intermediate Demand) Matrices for the EORA Data. ***WARNING*** Depending on size of cluster and number of years, running this cell can take several minutes.\r\n",
							"\r\n",
							"source_dir = \"abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/\"\r\n",
							"destination_dir = \"abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA26/Final Demand (FD) Matrices/\"\r\n",
							"\r\n",
							"for year in range(1990, 2023):\r\n",
							"    # Construct the folder and file paths\r\n",
							"    subfolder = f\"Eora26_{year}_bp\"\r\n",
							"    folder_path = os.path.join(source_dir, subfolder)\r\n",
							"    file_path = os.path.join(folder_path, f\"Eora26_{year}_bp_FD.txt\")\r\n",
							"    \r\n",
							"    matrix = spark.read.load(file_path, format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"\r\n",
							"    print(f\"Original Matrix Shape for {year}: {matrix.shape}\")\r\n",
							"\r\n",
							"    # Define the size of each chunk (6 columns)\r\n",
							"    chunk_size = 6\r\n",
							"\r\n",
							"    # Get the number of rows and columns in the original matrix\r\n",
							"    num_rows, num_columns = matrix.shape\r\n",
							"\r\n",
							"    # Calculate the number of chunks (excluding the last column)\r\n",
							"    num_chunks = (num_columns - 1) // chunk_size\r\n",
							"\r\n",
							"    # Initialize a new matrix to store the sums\r\n",
							"    sum_matrix = np.zeros((num_rows, num_chunks + 1))\r\n",
							"\r\n",
							"    # Sum every 26 columns for each row (excluding the last column)\r\n",
							"    for i in range(num_chunks):\r\n",
							"        start_col = i * chunk_size\r\n",
							"        end_col = (i + 1) * chunk_size\r\n",
							"        sum_matrix[:, i] = np.sum(matrix[:, start_col:end_col], axis=1)\r\n",
							"\r\n",
							"    # Add the values from the last column to the new matrix\r\n",
							"    sum_matrix[:, -1] = matrix[:, -1]\r\n",
							"\r\n",
							"    # Define the size of each chunk (26 rows)\r\n",
							"    chunk_size = 26\r\n",
							"\r\n",
							"    # Get the number of rows and columns in the sum_matrix\r\n",
							"    num_rows, num_columns = sum_matrix.shape\r\n",
							"\r\n",
							"    # Calculate the number of chunks (excluding the last row)\r\n",
							"    num_chunks = (num_rows - 1) // chunk_size\r\n",
							"\r\n",
							"    # Initialize a new square matrix to store the sums\r\n",
							"    final_matrix = np.zeros((num_chunks + 1, num_chunks + 1))\r\n",
							"\r\n",
							"    # Sum every 26 rows for each column (excluding the last row)\r\n",
							"    for i in range(num_chunks):\r\n",
							"        start_row = i * chunk_size\r\n",
							"        end_row = (i + 1) * chunk_size\r\n",
							"        final_matrix[i, :] = np.sum(sum_matrix[start_row:end_row, :], axis=0)\r\n",
							"\r\n",
							"    # Add the values from the last row to the new matrix\r\n",
							"    final_matrix[-1, :] = sum_matrix[-1, :]\r\n",
							"\r\n",
							"    # Create a square matrix of size 190 by 190 with ones on the non-diagonal elements\r\n",
							"    one_diagonal_matrix = np.ones((190, 190)) - np.eye(190)\r\n",
							"\r\n",
							"    # Multiply final_matrix with one_diagonal_matrix element-wise\r\n",
							"    result_matrix = np.multiply(final_matrix, one_diagonal_matrix)\r\n",
							"\r\n",
							"    # Display the shape of the result2 matrix\r\n",
							"    print(f\"Result Matrix Shape for {year}: {result_matrix.shape}\")\r\n",
							"\r\n",
							"    output = StringIO()\r\n",
							"    np.savetxt(output, result_matrix, delimiter=\",\")\r\n",
							"\r\n",
							"    # Save the result_matrix as a CSV file\r\n",
							"    output_folder = os.path.join(destination_dir, f\"FD_{year}.csv\")\r\n",
							"    mssparkutils.fs.put(output_folder, output.getvalue())"
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Prepping the Labels"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"t_labels = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA_Labels/labels_T.txt', format='csv', sep=\"\\t\").toPandas()\r\n",
							"fd_labels = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA_Labels/labels_FD.txt', format='csv', sep=\"\\t\").toPandas()"
						],
						"outputs": [],
						"execution_count": 23
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Reducing the labels down to one, concatenated, column of type \"ISO3, \"Sector\", \"Sub-sector\"\r\n",
							"t_labels = t_labels.drop(labels = [\"_c1\", \"_c4\"], axis=1)\r\n",
							"t_labels[\"Combined\"] = t_labels[[\"_c0\", \"_c2\", \"_c3\"]].apply(\", \".join, axis=1)\r\n",
							"t_labels = t_labels.drop(labels = [\"_c0\", \"_c2\", \"_c3\"], axis=1)\r\n",
							"\r\n",
							"fd_labels = fd_labels.drop(labels = [\"_c1\", \"_c4\"], axis=1)\r\n",
							"fd_labels[\"Combined\"] = fd_labels[[\"_c0\", \"_c2\", \"_c3\"]].apply(\", \".join, axis=1)\r\n",
							"fd_labels = fd_labels.drop(labels = [\"_c0\", \"_c2\", \"_c3\"], axis=1)"
						],
						"outputs": [],
						"execution_count": 25
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"t_matrix = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_1990_bp/Eora26_1990_bp_T.txt', format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"fd_matrix = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_1990_bp/Eora26_1990_bp_FD.txt', format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)"
						],
						"outputs": [],
						"execution_count": 63
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"T Matrix Labels"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Convert the array to Dataframe and insert the concated row labels\r\n",
							"t_matrixframe = pd.DataFrame(t_matrix)\r\n",
							"t_matrixframe.insert(0, \"Combined\", t_labels['Combined'])\r\n",
							"\r\n",
							"#Transpose the row lables and convert to list\r\n",
							"t_labels_Transposed = t_labels.T\r\n",
							"t_new_headers = [\"0\"] + t_labels_Transposed.iloc[0].tolist()\r\n",
							"\r\n",
							"#Create new dataframe with the new headers. Matrix is not symmetric as the index counts as a column\r\n",
							"t_finalframe = pd.DataFrame(t_matrixframe.values, columns = t_new_headers)"
						],
						"outputs": [],
						"execution_count": 32
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"FD Matrix Labels"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Convert the array to Dataframe and insert the concated row labels\r\n",
							"fd_matrixframe = pd.DataFrame(fd_matrix)\r\n",
							"fd_matrixframe.insert(0, \"Combined\", t_labels['Combined'])\r\n",
							"\r\n",
							"#Transpose the row lables and convert to list\r\n",
							"fd_labels_Transposed = fd_labels.T\r\n",
							"fd_new_headers = [\"0\"] + fd_labels_Transposed.iloc[0].tolist()\r\n",
							"\r\n",
							"#Create new dataframe with the new headers. Matrix is not symmetric as the index counts as a column\r\n",
							"fd_finalframe = pd.DataFrame(fd_matrixframe.values, columns = fd_new_headers)"
						],
						"outputs": [],
						"execution_count": 64
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Convert DataFrames to CSV strings, export to folders\r\n",
							"t_csv_buffer = io.StringIO()\r\n",
							"t_finalframe.to_csv(t_csv_buffer, index=False)\r\n",
							"t_csv_string = t_csv_buffer.getvalue()\r\n",
							"mssparkutils.fs.put(\"abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA26/T_Labeled.csv\", t_csv_string, overwrite=True)\r\n",
							"\r\n",
							"fd_csv_buffer = io.StringIO()\r\n",
							"fd_finalframe.to_csv(fd_csv_buffer, index=False)\r\n",
							"fd_csv_string = fd_csv_buffer.getvalue()\r\n",
							"mssparkutils.fs.put(\"abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA26/FD_Labeled.csv\", fd_csv_string, overwrite=True)"
						],
						"outputs": [],
						"execution_count": 61
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/EORA_Net_Trade')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ac2sparkpooldev",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "853a32b1-a47e-405b-a41d-d4720d33728e"
					}
				},
				"metadata": {
					"saveOutput": true,
					"synapse_widget": {
						"version": "0.1"
					},
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Synapse/workspaces/ac2-synapse-ws-dev/bigDataPools/ac2sparkpooldev",
						"name": "ac2sparkpooldev",
						"type": "Spark",
						"endpoint": "https://ac2-synapse-ws-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ac2sparkpooldev",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import numpy as np"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"source": [
							"fd_matrix = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_1990_bp/Eora26_1990_bp_FD.txt', format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"q_matrix = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_1990_bp/Eora26_1990_bp_Q.txt', format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"qy_matrix = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_1990_bp/Eora26_1990_bp_QY.txt', format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"t_matrix = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_1990_bp/Eora26_1990_bp_T.txt', format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"va_matrix = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_1990_bp/Eora26_1990_bp_VA.txt', format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"\r\n",
							"#print(\"FD Shape: \", np.shape(fd_matrix))\r\n",
							"#print(\"FD Type: \", fd_matrix.dtype)\r\n",
							"#print(\"Q Shape: \", np.shape(q_matrix))\r\n",
							"#print(\"Q Type: \", q_matrix.dtype)\r\n",
							"#print(\"QY Shape: \", np.shape(qy_matrix))\r\n",
							"#print(\"QY Type: \", qy_matrix.dtype)\r\n",
							"#print(\"T Shape: \", np.shape(t_matrix))\r\n",
							"#print(\"T Type: \", t_matrix.dtype)\r\n",
							"#print(\"VA Shape: \", np.shape(va_matrix))\r\n",
							"#print(\"VA Type: \", va_matrix.dtype)"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Calculate result_matrix from t_matrix\r\n",
							"chunk_size = 26\r\n",
							"sum_matrix = np.zeros((t_matrix.shape[0], (t_matrix.shape[1] - 1) // chunk_size + 1))\r\n",
							"for i in range((t_matrix.shape[1] - 1) // chunk_size):\r\n",
							"    sum_matrix[:, i] = np.sum(t_matrix[:, i * chunk_size:(i + 1) * chunk_size], axis=1)\r\n",
							"sum_matrix[:, -1] = t_matrix[:, -1]\r\n",
							"\r\n",
							"final_matrix = np.zeros(((sum_matrix.shape[0] - 1) // chunk_size + 1, sum_matrix.shape[1]))\r\n",
							"for i in range((sum_matrix.shape[0] - 1) // chunk_size):\r\n",
							"    final_matrix[i, :] = np.sum(sum_matrix[i * chunk_size:(i + 1) * chunk_size, :], axis=0)\r\n",
							"final_matrix[-1, :] = sum_matrix[-1, :]\r\n",
							"one_diagonal_matrix = np.eye(final_matrix.shape[0])\r\n",
							"result_matrix = np.multiply(final_matrix, one_diagonal_matrix)\r\n",
							"\r\n",
							"# Calculate result2_matrix from fd_matrix\r\n",
							"chunk_size2 = 6\r\n",
							"sum2_matrix = np.zeros((fd_matrix.shape[0], (fd_matrix.shape[1] - 1) // chunk_size2 + 1))\r\n",
							"for i in range((fd_matrix.shape[1] - 1) // chunk_size2):\r\n",
							"    sum2_matrix[:, i] = np.sum(fd_matrix[:, i * chunk_size2:(i + 1) * chunk_size2], axis=1)\r\n",
							"sum2_matrix[:, -1] = fd_matrix[:, -1]\r\n",
							"\r\n",
							"final2_matrix = np.zeros(((sum2_matrix.shape[0] - 1) // chunk_size + 1, sum2_matrix.shape[1]))\r\n",
							"for i in range((sum2_matrix.shape[0] - 1) // chunk_size):\r\n",
							"    final2_matrix[i, :] = np.sum(sum2_matrix[i * chunk_size:(i + 1) * chunk_size, :], axis=0)\r\n",
							"final2_matrix[-1, :] = sum2_matrix[-1, :]\r\n",
							"one_diagonal_matrix = np.ones((190, 190)) - np.eye(190)\r\n",
							"result2_matrix = np.multiply(final2_matrix, one_diagonal_matrix)\r\n",
							"\r\n",
							"# Combine result_matrix and result2_matrix if shapes match, otherwise print a warning\r\n",
							"if result_matrix.shape == result2_matrix.shape:\r\n",
							"    combined_result_matrix = np.add(result_matrix, result2_matrix)\r\n",
							"else:\r\n",
							"    print(f\"Warning: Matrices for year {year} have different shapes and cannot be added.\")\r\n",
							"\r\n",
							"# Step 1: Sum up the rows to get exports\r\n",
							"exports = np.sum(combined_result_matrix, axis=1)\r\n",
							"\r\n",
							"# Step 2: Sum up the columns to get imports\r\n",
							"imports = np.sum(combined_result_matrix, axis=0)\r\n",
							"\r\n",
							"# Step 3: Calculate net trade (exports minus imports)\r\n",
							"net_trade_matrix = np.subtract.outer(exports, imports)\r\n",
							"\r\n",
							"# Step 4: Set diagonal elements to zero to avoid self-loops\r\n",
							"np.fill_diagonal(net_trade_matrix, 0)\r\n",
							"\r\n",
							"# Step 5: Ensure total imports / total exports is 1\r\n",
							"total_exports = np.sum(exports)\r\n",
							"total_imports = np.sum(imports)\r\n",
							"verify = total_imports / total_exports\r\n",
							"print(f\"Net Trade Matrix Shape: {net_trade_matrix.shape}\")\r\n",
							"print(f\"Total Exports: {total_exports}\")\r\n",
							"print(f\"Total Imports: {total_imports}\")\r\n",
							"print(f\"Total Imports / Total Exports: {verify}\")"
						],
						"outputs": [],
						"execution_count": 20
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/EORA_PyMRIO')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ac2sparkpooldev",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "2521301c-2014-4b40-b888-25a997757bcc"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Synapse/workspaces/ac2-synapse-ws-dev/bigDataPools/ac2sparkpooldev",
						"name": "ac2sparkpooldev",
						"type": "Spark",
						"endpoint": "https://ac2-synapse-ws-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ac2sparkpooldev",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"!pip install pymrio"
						],
						"outputs": [],
						"execution_count": 110
					},
					{
						"cell_type": "code",
						"source": [
							"print(\"Im Awake\")\r\n",
							"\r\n",
							"import pymrio as pmr\r\n",
							"from notebookutils import mssparkutils\r\n",
							"import os\r\n",
							"import io\r\n",
							"from collections import namedtuple\r\n",
							"import pandas as pd\r\n",
							"import numpy as np\r\n",
							"import plotly.graph_objects as go\r\n",
							"from scipy.linalg import block_diag\r\n",
							"import warnings\r\n",
							"\r\n",
							"pd.set_option('display.max_columns', 30)\r\n",
							"pd.set_option('display.expand_frame_repr', False)\r\n",
							"pd.set_option('max_colwidth', None)"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def parse_eora_mod(path, year=None, price=\"bp\", country_names=\"eora\"):\r\n",
							"\r\n",
							"    row_name = \"ROW\"\r\n",
							"\r\n",
							"    IDX_NAMES = {\r\n",
							"    \"Z_col\": [\"region\", \"sector\"],\r\n",
							"    \"Z_row\": [\"region\", \"sector\"],\r\n",
							"    \"Z_row_unit\": [\"region\", \"sector\", \"unit\"],\r\n",
							"    \"A_col\": [\"region\", \"sector\"],\r\n",
							"    \"A_row\": [\"region\", \"sector\"],\r\n",
							"    \"A_row_unit\": [\"region\", \"sector\", \"unit\"], \r\n",
							"    \"Y_col1\": [\"region\"],\r\n",
							"    \"Y_col2\": [\"region\", \"category\"],\r\n",
							"    \"Y_row\": [\"region\", \"sector\"],\r\n",
							"    \"Y_row_unit\": [\"region\", \"sector\", \"unit\"],\r\n",
							"    \"F_col\": [\"region\", \"sector\"],\r\n",
							"    \"F_row_single\": [\"stressor\"],\r\n",
							"    \"F_row_unit\": [\"stressor\", \"unit\"],\r\n",
							"    \"F_row_comp_unit\": [\"stressor\", \"compartment\", \"unit\"],\r\n",
							"    \"F_row_src_unit\": [\"stressor\", \"source\", \"unit\"],\r\n",
							"    \"F_row_src\": [\"stressor\", \"source\"],\r\n",
							"    \"VA_row_single\": [\"inputtype\"],\r\n",
							"    \"VA_row_unit\": [\"inputtype\", \"unit\"],\r\n",
							"    \"VA_row_unit_cat\": [\"inputtype\", \"category\"],\r\n",
							"    \"unit\": [\"unit\"],\r\n",
							"    \"_reg_sec_unit\": [\"region\", \"sector\", \"unit\"],\r\n",
							"    }\r\n",
							"\r\n",
							"    #eora file specs\r\n",
							"    eora_sep = \"\\t\"\r\n",
							"    ZY_col = namedtuple(\"ZY\", \"full eora system name\")(0,1,2,3)\r\n",
							"\r\n",
							"    eora_files = {\r\n",
							"    \"Z\": path + \"Eora26_{year}_{price}_T.txt\".format(year=str(year), price=price),\r\n",
							"    \"Q\": path + \"Eora26_{year}_{price}_Q.txt\".format(year=str(year), price=price),\r\n",
							"    \"QY\": path + \"Eora26_{year}_{price}_QY.txt\".format(year=str(year), price=price),\r\n",
							"    \"VA\": path + \"Eora26_{year}_{price}_VA.txt\".format(year=str(year), price=price),\r\n",
							"    \"Y\": path + \"Eora26_{year}_{price}_FD.txt\".format(year=str(year), price=price),\r\n",
							"    \"labels_Z\": path + \"labels_T.txt\",\r\n",
							"    \"labels_Y\": path + \"labels_FD.txt\",\r\n",
							"    \"labels_Q\": path + \"labels_Q.txt\",\r\n",
							"    \"labels_VA\": path + \"labels_VA.txt\"\r\n",
							"    }\r\n",
							"\r\n",
							"    header = namedtuple(\"header\", \"index columns index_names, column_names\")\r\n",
							"\r\n",
							"    eora_header_spec = {\r\n",
							"        \"Z\": header(\r\n",
							"            index=\"labels_Z\",\r\n",
							"            columns=\"labels_Z\",\r\n",
							"            index_names=IDX_NAMES[\"Z_row\"],\r\n",
							"            column_names=IDX_NAMES[\"Z_col\"],\r\n",
							"        ),\r\n",
							"        \"Q\": header(\r\n",
							"            index=\"labels_Q\",\r\n",
							"            columns=\"labels_Z\",\r\n",
							"            index_names=IDX_NAMES[\"F_row_src\"],\r\n",
							"            column_names=IDX_NAMES[\"F_col\"],\r\n",
							"        ),\r\n",
							"        \"QY\": header(\r\n",
							"            index=\"labels_Q\",\r\n",
							"            columns=\"labels_Y\",\r\n",
							"            index_names=IDX_NAMES[\"F_row_src\"],\r\n",
							"            column_names=IDX_NAMES[\"Y_col2\"],\r\n",
							"        ),\r\n",
							"        \"VA\": header(\r\n",
							"            index=\"labels_VA\",\r\n",
							"            columns=\"labels_Z\",\r\n",
							"            index_names=IDX_NAMES[\"VA_row_unit_cat\"],\r\n",
							"            column_names=IDX_NAMES[\"F_col\"],\r\n",
							"        ),\r\n",
							"        \"Y\": header(\r\n",
							"            index=\"labels_Z\",\r\n",
							"            columns=\"labels_Y\",\r\n",
							"            index_names=IDX_NAMES[\"Y_row\"],\r\n",
							"            column_names=IDX_NAMES[\"Y_col2\"],\r\n",
							"        )\r\n",
							"        }\r\n",
							"    \r\n",
							"    if mssparkutils.fs.exists(path):\r\n",
							"        eora_data = {\r\n",
							"            key: (\r\n",
							"                spark.read.load(filepath, format='csv',sep=\"\\t\").toPandas()\r\n",
							"            )\r\n",
							"            for key, filepath in eora_files.items()\r\n",
							"        }\r\n",
							"\r\n",
							"    eora_data['Z'] = eora_data['Z'].astype(\"float\")\r\n",
							"    eora_data['Q'] = eora_data['Q'].astype(\"float\")\r\n",
							"    eora_data['QY'] = eora_data['QY'].astype(\"float\")\r\n",
							"    eora_data['VA'] = eora_data['VA'].astype(\"float\")\r\n",
							"    eora_data['Y'] = eora_data['Y'].astype(\"float\")\r\n",
							"\r\n",
							"    eora_data[\"labels_Z\"] = eora_data[\"labels_Z\"].iloc[\r\n",
							"        :, [getattr(ZY_col, country_names), ZY_col.name]\r\n",
							"    ]\r\n",
							"    eora_data[\"labels_Y\"] = eora_data[\"labels_Y\"].iloc[\r\n",
							"        :, [getattr(ZY_col, country_names), ZY_col.name]\r\n",
							"    ]\r\n",
							"    eora_data[\"labels_VA\"] = eora_data[\"labels_VA\"].iloc[\r\n",
							"        :, : len(eora_header_spec[\"VA\"].column_names)\r\n",
							"    ]\r\n",
							"\r\n",
							"    labQ = eora_data[\"labels_Q\"].iloc[:, : len(eora_header_spec[\"Q\"].column_names)]\r\n",
							"    labQ.columns = IDX_NAMES[\"F_row_src\"]\r\n",
							"    Q_unit = pd.DataFrame(labQ[\"stressor\"].str.extract(r\"\\((.*)\\)\", expand=False))\r\n",
							"    Q_unit.columns = IDX_NAMES[\"unit\"]\r\n",
							"\r\n",
							"    labQ = labQ.copy()\r\n",
							"    labQ.loc[:, \"stressor\"] = labQ[\"stressor\"].str.replace(r\"\\s\\((.*)\\)\", \"\", regex=True)\r\n",
							"    eora_data[\"labels_Q\"] = labQ\r\n",
							"\r\n",
							"    for key in eora_header_spec.keys():\r\n",
							"        eora_data[key].columns = (\r\n",
							"            eora_data[eora_header_spec[key].columns]\r\n",
							"            .set_index(list(eora_data[eora_header_spec[key].columns]))\r\n",
							"            .index\r\n",
							"        )\r\n",
							"        eora_data[key].columns.names = eora_header_spec[key].column_names\r\n",
							"        eora_data[key].index = (\r\n",
							"            eora_data[eora_header_spec[key].index]\r\n",
							"            .set_index(list(eora_data[eora_header_spec[key].index]))\r\n",
							"            .index\r\n",
							"        )\r\n",
							"        eora_data[key].index.names = eora_header_spec[key].index_names\r\n",
							"\r\n",
							"        try:\r\n",
							"            row_mask = ~eora_data[key].index.get_level_values('region').str.startswith(row_name)\r\n",
							"            col_mask = ~eora_data[key].columns.get_level_values('region').str.startswith(row_name)\r\n",
							"            eora_data[key] = eora_data[key].loc[row_mask , :]\r\n",
							"            eora_data[key] = eora_data[key].loc[: , col_mask]\r\n",
							"        except KeyError:\r\n",
							"            pass\r\n",
							"\r\n",
							"    #This is a quick fix to remove all the \"ROW\" columns in these dataframes\r\n",
							"\r\n",
							"    eora_data['Q'] = eora_data['Q'].loc[:,~eora_data['Q'].columns.get_level_values('region').str.startswith(row_name)]\r\n",
							"    eora_data['QY'] = eora_data['QY'].loc[:,~eora_data['QY'].columns.get_level_values('region').str.startswith(row_name)]\r\n",
							"    eora_data['VA'] = eora_data['VA'].loc[:,~eora_data['VA'].columns.get_level_values('region').str.startswith(row_name)]\r\n",
							"\r\n",
							"    \r\n",
							"    Q_unit.index = eora_data[\"Q\"].index\r\n",
							"\r\n",
							"    Z_unit = pd.DataFrame(\r\n",
							"        data=[\"Mill USD\"] * len(eora_data[\"Z\"].index),\r\n",
							"        index=eora_data[\"Z\"].index,\r\n",
							"        columns=[\"unit\"],\r\n",
							"    )\r\n",
							"\r\n",
							"    VA_unit = pd.DataFrame(\r\n",
							"        data=[\"Mill USD\"] * len(eora_data[\"VA\"].index),\r\n",
							"        index=eora_data[\"VA\"].index,\r\n",
							"        columns=[\"unit\"],\r\n",
							"    )\r\n",
							"\r\n",
							"    eora = pmr.IOSystem(\r\n",
							"        Z=eora_data[\"Z\"],\r\n",
							"        Y=eora_data[\"Y\"],\r\n",
							"        unit=Z_unit,\r\n",
							"        Q={\"name\": \"Q\", \"unit\": Q_unit, \"F\": eora_data[\"Q\"], \"F_Y\": eora_data[\"QY\"]},\r\n",
							"        VA={\r\n",
							"            \"name\": \"VA\",\r\n",
							"            \"F\": eora_data[\"VA\"],\r\n",
							"            \"unit\": VA_unit,\r\n",
							"        },\r\n",
							"    )\r\n",
							"\r\n",
							"\r\n",
							"    return(eora)"
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"year = \"2022\"\r\n",
							"price = \"bp\"\r\n",
							"path = 'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_{year}_{price}/'.format(year=year, price=price)\r\n",
							"\r\n",
							"eora_data = parse_eora_mod(path = path, year = year)\r\n",
							"\r\n",
							"eora_data.calc_all()"
						],
						"outputs": [],
						"execution_count": 18
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#various variables so I dont have to change them mulitple times. Country values are ISO3 (ISO 3166-1 Alpha-3) country codes. \r\n",
							"Z = eora_data.Z\r\n",
							"Y = eora_data.Y\r\n",
							"\r\n",
							"exporter = 'RUS'\r\n",
							"importer = 'CHN'\r\n",
							"\r\n",
							"country = \"VNM\"\r\n",
							"sector = \"Retail Trade\"\r\n",
							"\r\n",
							"eora26sectors = ['Agriculture', 'Fishing', 'Mining and Quarrying', 'Food & Beverages', 'Textiles and Wearing Apparel', 'Wood and Paper',\r\n",
							" 'Petroleum, Chemical and Non-Metallic Mineral Products', 'Metal Products', 'Electrical and Machinery', 'Transport Equipment', 'Other Manufacturing', 'Recycling',\r\n",
							" 'Electricity, Gas and Water', 'Construction', 'Maintenance and Repair', 'Wholesale Trade', 'Retail Trade', 'Hotels and Restraurants', 'Transport', 'Post and Telecommunications',\r\n",
							" 'Finacial Intermediation and Business Activities', 'Public Administration', 'Education, Health and Other Services', 'Private Households', 'Others',  'Re-export & Re-import']"
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Z"
						],
						"outputs": [],
						"execution_count": 95
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Country A to Country B Z (T) matrix calc"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countryZ_row_filter = eora_data.Z.index.get_level_values('region').str.startswith(exporter)\r\n",
							"countryZ_column_filter = eora_data.Z.columns.get_level_values('region').str.startswith(importer)\r\n",
							"\r\n",
							"countryZ = eora_data.Z.loc[countryZ_row_filter, countryZ_column_filter]\r\n",
							"\r\n",
							"pd.DataFrame(data = countryZ)"
						],
						"outputs": [],
						"execution_count": 21
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Country A to Country B Z (T) matrix calc (Row Sums)"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countryZ_row_filter = eora_data.Z.index.get_level_values('region').str.startswith(str(exporter))\r\n",
							"countryZ_column_filter = eora_data.Z.columns.get_level_values('region').str.startswith(str(importer))\r\n",
							"\r\n",
							"countryZ = eora_data.Z.loc[countryZ_row_filter, countryZ_column_filter]\r\n",
							"\r\n",
							"# Calculate row sums\r\n",
							"Zrow_sums = countryZ.sum(axis=1)\r\n",
							"\r\n",
							"# Create a new DataFrame with row sums\r\n",
							"Zrow_sums_df = pd.DataFrame(data = Zrow_sums)\r\n",
							"\r\n",
							"# Rename the column in the new DataFrame\r\n",
							"Zrow_sums_df.columns = [importer]\r\n",
							"Zrow_sums_df"
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Country A to Country B Y (FD) matrix calc"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countryY_row_filter = eora_data.Z.index.get_level_values('region').str.startswith(exporter)\r\n",
							"countryY_column_filter = eora_data.Y.columns.get_level_values('region').str.startswith(importer)\r\n",
							"\r\n",
							"countryY = eora_data.Y.loc[countryY_row_filter, countryY_column_filter]\r\n",
							"\r\n",
							"pd.DataFrame(data = countryY)"
						],
						"outputs": [],
						"execution_count": 23
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Country A to Country B Y (FD) matrix calc row sums"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countryY_row_filter = eora_data.Z.index.get_level_values('region').str.startswith(exporter)\r\n",
							"countryY_column_filter = eora_data.Y.columns.get_level_values('region').str.startswith(importer)\r\n",
							"\r\n",
							"countryY = eora_data.Y.loc[countryY_row_filter, countryY_column_filter]\r\n",
							"\r\n",
							"# Calculate row sums\r\n",
							"Yrow_sums = countryY.sum(axis=1)\r\n",
							"\r\n",
							"# Create a new DataFrame with row sums\r\n",
							"Yrow_sums_df = pd.DataFrame(data = Yrow_sums)\r\n",
							"\r\n",
							"# Rename the column in the new DataFrame\r\n",
							"Yrow_sums_df.columns = [importer]\r\n",
							"Yrow_sums_df"
						],
						"outputs": [],
						"execution_count": 24
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Top 10 countries contriubting agriculture products to the Vietnamese construction sector."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"intermediate_flows = Z.xs((sector, country), level=(\"sector\", \"region\"), axis=1)\r\n",
							"intermediate_flows = intermediate_flows.groupby(level=\"sector\", axis=1).sum()\r\n",
							"\r\n",
							"#Shows all of the flows, from all countries, into X country's sector\r\n",
							"#print(intermediate_flows)\r\n",
							"\r\n",
							"agriculture_flows = Z.xs((sector, sector), level=(\"sector\", \"sector\"), axis=1)\r\n",
							"flowToAgSector = agriculture_flows.loc[(slice(None), sector), :].xs('VNM', level='region', axis=1)\r\n",
							"\r\n",
							"flowToAgSector = flowToAgSector.sort_index()\r\n",
							"flowToAgSector = flowToAgSector.drop(country)\r\n",
							"\r\n",
							"sorted_values = flowToAgSector.sort_values(sector, ascending=False).head(10)\r\n",
							"sorted_values"
						],
						"outputs": [],
						"execution_count": 25
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Sankey chart showing the top 10 contributors of agricultural products to the U.S. agricultural sector."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"labels = sorted_values.index.tolist()\r\n",
							"labels.append(country)\r\n",
							"values = sorted_values[sector].tolist()\r\n",
							"values.append(sorted_values[sector].sum())\r\n",
							"\r\n",
							"source = [i for i in range(len(values) - 1)]\r\n",
							"target = [len(values) - 1] * (len(values) - 1)\r\n",
							"\r\n",
							"data = dict(\r\n",
							"    type='sankey',\r\n",
							"    node=dict(\r\n",
							"      pad=15,\r\n",
							"      thickness=20,\r\n",
							"      line=dict(color=\"black\", width=0.5),\r\n",
							"      label=labels,\r\n",
							"      color=\"blue\"\r\n",
							"    ),\r\n",
							"    link=dict(\r\n",
							"      source=source,\r\n",
							"      target=target,\r\n",
							"      value=values\r\n",
							"  ))\r\n",
							"\r\n",
							"fig = go.Figure(data=[data])\r\n",
							"fig.show()"
						],
						"outputs": [],
						"execution_count": 26
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Parameters\r\n",
							"num_cntry = 189\r\n",
							"num_sectors = 26\r\n",
							"num_fd_components = 6\r\n",
							"year_start = 2022\r\n",
							"year_end = 2022\r\n",
							"\r\n",
							"eora_years = np.linspace(year_start, year_end, num = year_end - year_start + 1).astype(int).astype(str)\r\n",
							"\r\n",
							"for i in range(len(eora_years)):\r\n",
							"    #Read in the data\r\n",
							"    fd_matrix_path = 'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_'+eora_years[i]+'_bp/Eora26_'+eora_years[i]+'_bp_FD.txt'\r\n",
							"    id_matrix_path = 'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_'+eora_years[i]+'_bp/Eora26_'+eora_years[i]+'_bp_T.txt'\r\n",
							"    va_matrix_path = 'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_'+eora_years[i]+'_bp/Eora26_'+eora_years[i]+'_bp_VA.txt'\r\n",
							"\r\n",
							"    fd_matrix = spark.read.load(fd_matrix_path, format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"    id_matrix = spark.read.load(id_matrix_path, format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"    va_matrix = spark.read.load(va_matrix_path, format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"    print(\"Data read for year: \" + eora_years[i])\r\n",
							"\r\n",
							"    # Compute Stats\r\n",
							"    va_total_cs = va_matrix.sum(axis = 0)\r\n",
							"    FD = fd_matrix.reshape((num_cntry*num_sectors + 1), num_fd_components, -1)\r\n",
							"    FD = FD.sum(axis=1)\r\n",
							"    FD = np.squeeze(FD) # Squeeze to remove single-dimensional entries\r\n",
							"\r\n",
							"    GRTR_INT_cs_cs = id_matrix[0:(num_cntry*num_sectors), 0:(num_cntry*num_sectors)]\r\n",
							"    GRTR_FNL_cs_c = FD[0:num_cntry*num_sectors,0:num_cntry]\r\n",
							"    VALUE_cs = va_total_cs[0:(num_cntry*num_sectors)]\r\n",
							"\r\n",
							"    # Initialize empty list to hold blocks\r\n",
							"    imtx_cs_c = []\r\n",
							"    imtx_cs_cs = []\r\n",
							"    imtx_c_cs=[]\r\n",
							"    imtx_cs_ck = []\r\n",
							"\r\n",
							"    # Create block matrix\r\n",
							"    iblk_cs_c = np.ones((num_sectors, 1))  # Create num_sectors x 1 vector of ones\r\n",
							"    iblk_cs_cs = np.ones((num_sectors,num_sectors))\r\n",
							"    ivector = np.ones((1, num_sectors))\r\n",
							"    iblk_cs_ck = np.ones((num_sectors, num_fd_components))\r\n",
							"\r\n",
							"    # Construct block diagonal matrix\r\n",
							"    for j in range(num_cntry):\r\n",
							"        if j == 0:\r\n",
							"            imtx_cs_c = iblk_cs_c  # Initialize with the first block\r\n",
							"            imtx_cs_cs = iblk_cs_cs\r\n",
							"            imtx_c_cs = ivector\r\n",
							"            imtx_cs_ck = iblk_cs_ck\r\n",
							"\r\n",
							"        else:\r\n",
							"            imtx_cs_c = block_diag(imtx_cs_c, iblk_cs_c) \r\n",
							"            imtx_cs_cs = block_diag(imtx_cs_cs, iblk_cs_cs) \r\n",
							"            imtx_c_cs = block_diag(imtx_c_cs, ivector)\r\n",
							"            imtx_cs_ck = block_diag(imtx_cs_ck, iblk_cs_ck)\r\n",
							"\r\n",
							"    imtx_c_c = np.eye(num_cntry)\r\n",
							"\r\n",
							"    #Gross Output\r\n",
							"    GO_cs_c = GRTR_INT_cs_cs.reshape(num_cntry*num_sectors, num_sectors, -1)\r\n",
							"    GO_cs_c = GO_cs_c.sum(axis = 1)\r\n",
							"    GO_cs_c = np.squeeze(GO_cs_c)\r\n",
							"    GO_cs_c = GO_cs_c + GRTR_FNL_cs_c\r\n",
							"    GO_cs = GO_cs_c.sum(axis = 1)\r\n",
							"    GO_c_c = np.matmul(imtx_c_cs,GO_cs_c)\r\n",
							"    elementwise_GO_product =  np.tile(GO_cs[:, np.newaxis],(1,num_cntry)) * imtx_cs_c\r\n",
							"    summed_GO_result = elementwise_GO_product.sum(axis=0)\r\n",
							"    GO_c = summed_GO_result.T\r\n",
							"\r\n",
							"    #Value Added\r\n",
							"    elementwise_VALUE_product = np.tile(VALUE_cs[:, np.newaxis], (1, num_cntry)) * imtx_cs_c\r\n",
							"    summed_VALUE_result = elementwise_VALUE_product.sum(axis=0)\r\n",
							"    VALUE_c = summed_VALUE_result.T\r\n",
							"\r\n",
							"    #Derived value added\r\n",
							"    Inputs_cs = GRTR_INT_cs_cs.sum(axis = 0)\r\n",
							"    replicated_Inputs_cs = np.tile(Inputs_cs[:, np.newaxis], (1, num_cntry)) \r\n",
							"    elementwise_INPUTS_product = replicated_Inputs_cs * imtx_cs_c\r\n",
							"    summed_INPUTS_result = elementwise_INPUTS_product.sum(axis = 0)\r\n",
							"    Inputs_c = summed_INPUTS_result.T\r\n",
							"\r\n",
							"    #VA = Gross Outputs - Inputs\r\n",
							"    VALUE_derived_cs = GO_cs - Inputs_cs\r\n",
							"    replicated_VALUE_derived_cs = np.tile(VALUE_derived_cs[:, np.newaxis], (1, num_cntry))\r\n",
							"    elementwise_VALUE_derived_product = replicated_VALUE_derived_cs * imtx_cs_c\r\n",
							"    summed_VALUE_derived_result = elementwise_VALUE_derived_product.sum(axis = 0)\r\n",
							"    VALUE_derived_c = summed_VALUE_derived_result.T\r\n",
							"\r\n",
							"    #Gross Exports\r\n",
							"    ones_cs_cs_array = np.ones((num_cntry*num_sectors))\r\n",
							"    EXGR_INT_cs_cs = GRTR_INT_cs_cs * (ones_cs_cs_array - imtx_cs_cs)\r\n",
							"\r\n",
							"    EXGR_INT_cs_c = np.full((num_cntry * num_sectors, num_cntry), np.nan)\r\n",
							"    for k in range(num_cntry):\r\n",
							"        EXGR_INT_cs_c[:, k] = np.sum(EXGR_INT_cs_cs[:, (k * num_sectors):(num_sectors * (k + 1))], axis=1)\r\n",
							"\r\n",
							"    EXGR_INT_cs = EXGR_INT_cs_cs.sum(axis = 1)\r\n",
							"\r\n",
							"    replicated_EXGR_INT_cs = np.tile(EXGR_INT_cs[:, np.newaxis], (1, num_cntry))\r\n",
							"    elementwise_EXGR_INT_cs_product = replicated_EXGR_INT_cs * imtx_cs_c\r\n",
							"    summed_EXGR_INT_cs_result = elementwise_EXGR_INT_cs_product.sum(axis = 0)\r\n",
							"    EXGR_INT_c = summed_EXGR_INT_cs_result.T\r\n",
							"\r\n",
							"    ones_cs_c_array = np.ones((num_cntry*num_sectors, num_cntry))\r\n",
							"    EXGR_FNL_cs_c = GRTR_FNL_cs_c * (ones_cs_c_array - imtx_cs_c)\r\n",
							"\r\n",
							"    EXGR_FNL_cs = EXGR_FNL_cs_c * (ones_cs_c_array - imtx_cs_c)\r\n",
							"    EXGR_FNL_cs = EXGR_FNL_cs.sum(axis = 1)\r\n",
							"\r\n",
							"    EXGR_FNL_c = np.tile(EXGR_FNL_cs[:, np.newaxis],(1, num_cntry)) * imtx_cs_c\r\n",
							"    EXGR_FNL_c = EXGR_FNL_c.sum(axis = 0).T\r\n",
							"\r\n",
							"    EXGR_cs_c = EXGR_INT_cs_c + EXGR_FNL_cs_c\r\n",
							"    EXGR_c_c = np.matmul(imtx_c_cs, EXGR_cs_c)\r\n",
							"\r\n",
							"    EXGR_cs = EXGR_INT_cs + EXGR_FNL_cs\r\n",
							"    EXGR_c = EXGR_INT_c + EXGR_FNL_c\r\n",
							"\r\n",
							"    #Gross Imports\r\n",
							"    ones_cs_array = np.ones((num_cntry * num_sectors))\r\n",
							"    IMGR_INT_cs = GRTR_INT_cs_cs * (ones_cs_array - imtx_cs_cs)\r\n",
							"    IMGR_INT_cs = IMGR_INT_cs.sum(axis = 0)\r\n",
							"\r\n",
							"    IMGR_INT_c = np.tile(IMGR_INT_cs[:, np.newaxis],(1, num_cntry)) * imtx_cs_c\r\n",
							"    IMGR_INT_c = IMGR_INT_c.sum(axis = 0).T\r\n",
							"\r\n",
							"    ones_cs_c_array = np.ones((num_cntry * num_sectors, num_cntry))\r\n",
							"    IMGR_FNL_c = GRTR_FNL_cs_c * (ones_cs_c_array - imtx_cs_c)\r\n",
							"    IMGR_FNL_c = IMGR_FNL_c.sum(axis = 0).T\r\n",
							"\r\n",
							"    IMGR_c = IMGR_INT_c + IMGR_FNL_c\r\n",
							"\r\n",
							"    #Gross Trade Balance\r\n",
							"    BALGR_c = EXGR_c - IMGR_c\r\n",
							"\r\n",
							"    #Demand for Domestic Inputs (Use of Domestic Intermediates)\r\n",
							"    DDGR_INT_cs = GRTR_INT_cs_cs * imtx_cs_cs\r\n",
							"    DDGR_INT_cs = DDGR_INT_cs.sum(axis = 0).T\r\n",
							"\r\n",
							"    DDGR_INT_c = np.tile(DDGR_INT_cs[:, np.newaxis],(1, num_cntry)) * imtx_cs_c\r\n",
							"    DDGR_INT_c = DDGR_INT_c.sum(axis = 0).T\r\n",
							"\r\n",
							"    DDGR_FNL_c = GRTR_FNL_cs_c * imtx_cs_c\r\n",
							"    DDGR_FNL_c = DDGR_FNL_c.sum(axis = 0).T\r\n",
							"\r\n",
							"    #Domestic and Foreign Final Demand\r\n",
							"    GRTR_FNL_DOM_cs_c = GRTR_FNL_cs_c * imtx_cs_c\r\n",
							"    GRTR_FNL_DOM_cs = GRTR_FNL_DOM_cs_c.sum(axis = 1)\r\n",
							"\r\n",
							"    #By sector\r\n",
							"    GRTR_FNL_DOM_cs_ck = fd_matrix[0:num_cntry*num_sectors, 0:num_cntry*num_fd_components] * imtx_cs_ck\r\n",
							"\r\n",
							"    ##Sum across the third dimension, across countries for each of the 6 components of final demand\r\n",
							"    GRTR_FNL_DOM_cs_nfd = GRTR_FNL_DOM_cs_ck.reshape((num_cntry*num_sectors), num_fd_components, -1)\r\n",
							"    GRTR_FNL_DOM_cs_nfd = GRTR_FNL_DOM_cs_nfd.sum(axis = 2)\r\n",
							"\r\n",
							"    #Foreign Demand\r\n",
							"    GRTR_FNL_FOR_cs_c = GRTR_FNL_cs_c * (ones_cs_c_array - imtx_cs_c)\r\n",
							"    GRTR_FNL_FOR_cs = GRTR_FNL_FOR_cs_c.sum(axis = 1)\r\n",
							"\r\n",
							"    ##By sector\r\n",
							"    ones_cs_ck_array = np.ones((num_cntry*num_sectors, num_cntry*num_fd_components))\r\n",
							"    GRTR_FNL_FOR_cs_ck = fd_matrix[0:num_cntry*num_sectors, 0:num_cntry*num_fd_components] * (ones_cs_ck_array - imtx_cs_ck)\r\n",
							"\r\n",
							"    ##Sum across the third dimension, across countries for each of the 6 components of final demand\r\n",
							"    GRTR_FNL_FOR_cs_nfd = GRTR_FNL_FOR_cs_ck.reshape((num_cntry*num_sectors), num_fd_components, -1)\r\n",
							"    GRTR_FNL_FOR_cs_nfd = GRTR_FNL_FOR_cs_nfd.sum(axis = 2)\r\n",
							"\r\n",
							"    #VA Vector\r\n",
							"    with warnings.catch_warnings():\r\n",
							"        warnings.simplefilter('ignore')\r\n",
							"        Amat = GRTR_INT_cs_cs / np.tile(GO_cs[:, np.newaxis], (1, num_cntry * num_sectors))\r\n",
							"\r\n",
							"    Amat[np.isnan(Amat)] = 0\r\n",
							"    Amat[np.isinf(Amat)] = 0\r\n",
							"\r\n",
							"    #VA shares\r\n",
							"    va_vec_cs = 1 - np.sum(Amat)\r\n",
							"    V_hat = np.eye((num_cntry * num_sectors)) - np.diag(Amat.sum(axis = 0))\r\n",
							"\r\n",
							"    #Leontief inverse\r\n",
							"    IminusA = np.eye((num_cntry * num_sectors)) - Amat\r\n",
							"    Bmat = np.linalg.inv(IminusA)\r\n",
							"\r\n",
							"    #Total Value Added by country-sector\r\n",
							"    BY = np.matmul(Bmat, GRTR_FNL_cs_c.sum(axis = 1))\r\n",
							"    va_cs = va_vec_cs * BY\r\n",
							"\r\n",
							"    #DVA and FVA of gross exports (From V*B*E)\r\n",
							"    TiVA = V_hat @ Bmat @ np.diag(EXGR_cs)\r\n",
							"\r\n",
							"    EXGR_DVA_cs = np.sum(TiVA * imtx_cs_cs, axis = 0).T\r\n",
							"    EXGR_FVA_cs = np.sum(TiVA * (ones_cs_array - imtx_cs_cs), axis = 0).T\r\n",
							"\r\n",
							"    EXGR_DVA_c = np.tile(EXGR_DVA_cs[:, np.newaxis],(1, num_cntry)) * imtx_cs_c\r\n",
							"    EXGR_DVA_c = EXGR_DVA_c.sum(axis = 0).T\r\n",
							"\r\n",
							"    EXGR_FVA_c = np.tile(EXGR_FVA_cs[:, np.newaxis],(1, num_cntry)) * imtx_cs_c\r\n",
							"    EXGR_FVA_c = EXGR_FVA_c.sum(axis = 0).T\r\n",
							"\r\n",
							"    VS1_cs = np.sum(TiVA * (ones_cs_array - imtx_cs_cs), axis = 1)\r\n",
							"    VS1_c = np.tile(VS1_cs[:, np.newaxis], (1, num_cntry)) * imtx_cs_c\r\n",
							"    VS1_c = VS1_c.sum(axis = 0).T\r\n",
							"\r\n",
							"    #Compute VA matrices (from V*B*Y)\r\n",
							"    VA_cs_c = V_hat @ Bmat @ GRTR_FNL_cs_c\r\n",
							"\r\n",
							"    ones_c_c_array = np.ones((num_cntry, num_cntry))\r\n",
							"    VAX_cs_c = VA_cs_c * (ones_cs_c_array - imtx_cs_c)\r\n",
							"    VA_c_c = np.matmul(imtx_c_cs, VA_cs_c)\r\n",
							"\r\n",
							"    #Value added of exports only (exclude value_added of demestic goods)\r\n",
							"    VAX_c_c = VA_c_c * (ones_c_c_array - np.eye(num_cntry))\r\n",
							"\r\n",
							"    VAX_c = VAX_c_c.sum(axis = 1)\r\n",
							"\r\n",
							"    #Koopman et al. Equation 36 Terms\r\n",
							"    VAX1_cs_c = V_hat @ (Bmat * imtx_cs_cs) @ (GRTR_FNL_cs_c * (ones_cs_c_array - imtx_cs_c))\r\n",
							"    VAX1_c_c = np.matmul(imtx_c_cs, VAX1_cs_c) # aggregate across rows by country\r\n",
							"    VAX1_c = VAX1_c_c.sum(axis = 1)\r\n",
							"\r\n",
							"    VAX2_cs_c = V_hat @ (Bmat * (ones_cs_array - imtx_cs_cs)) @ (GRTR_FNL_cs_c  - imtx_cs_c)\r\n",
							"    VAX2_c_c = np.matmul(imtx_c_cs, VAX2_cs_c) # aggregate across rows by country\r\n",
							"    VAX2_c = VAX2_c_c.sum(axis = 1)\r\n",
							"\r\n",
							"    VAX3_cs_c_sum1 = V_hat @ (Bmat * (ones_cs_array - imtx_cs_cs)) @ (GRTR_FNL_cs_c * (ones_cs_c_array - imtx_cs_c))\r\n",
							"    VAX3_cs_c_sum2 = VAX3_cs_c_sum1 * (ones_cs_c_array - imtx_cs_c)\r\n",
							"    VAX3_c_c = np.matmul(imtx_c_cs, VAX3_cs_c_sum2) # aggregate across rows by country\r\n",
							"    VAX3_c = VAX3_c_c.sum(axis = 1)\r\n",
							"\r\n",
							"    DVA4_cs_c = V_hat @ (Bmat * (ones_cs_array - imtx_cs_cs)) @ (GRTR_FNL_cs_c * (ones_cs_c_array - imtx_cs_c))\r\n",
							"    DVA4_c_c = np.matmul(imtx_c_cs,DVA4_cs_c) * imtx_c_c # aggregate across rows by country, and take just the diagonal elements\r\n",
							"    DVA4_c = DVA4_c_c.sum(axis = 1)\r\n",
							"\r\n",
							"    eye_inverse = np.linalg.inv(np.eye((num_cntry * num_sectors)))\r\n",
							"    DVA5_cs_c = V_hat @ (Bmat * (ones_cs_array - imtx_cs_cs)) @ (Amat * (ones_cs_array - imtx_cs_cs)) @\\\r\n",
							"                ((eye_inverse - Amat) * imtx_cs_cs) @ (GRTR_FNL_cs_c * imtx_cs_c)\r\n",
							"    DVA5_c_c = np.matmul(imtx_c_cs,DVA5_cs_c) * imtx_c_c # aggregate across rows by country, and take just the diagonal elements\r\n",
							"    DVA5_c = DVA5_c_c.sum(axis = 1)\r\n",
							"\r\n",
							"    DVA6_c = EXGR_DVA_c - VAX_c - DVA4_c - DVA5_c\r\n",
							"\r\n",
							"    #Foreign Value Added in Domestic Final Demand\r\n",
							"    DFD_FVA_c = VAX_c_c.sum(axis = 0)\r\n",
							"\r\n",
							"print(\"Done!\")"
						],
						"outputs": [],
						"execution_count": 27
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Gross Exports by sector per country "
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countrySectorExports = pd.DataFrame(EXGR_cs_c)\r\n",
							"countryCountryExports = pd.DataFrame(EXGR_c_c)\r\n",
							"\r\n",
							"countrySectorLabels = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA_Labels/Country+Sector_Labels.csv', format='csv', sep=\"\\t\").toPandas()\r\n",
							"countryLabels = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA_Labels/country-labels.csv', format='csv', sep=\"\\t\").toPandas()"
						],
						"outputs": [],
						"execution_count": 28
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countryCountryExports.sum(axis = 1)"
						],
						"outputs": [],
						"execution_count": 29
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countrySectorExports.set_axis(countryLabels.values.squeeze(), axis = 1, inplace = True)\r\n",
							"\r\n",
							"countrySectorLabels = countrySectorLabels.iloc[1:]\r\n",
							"countrySectorLabels = countrySectorLabels.reset_index(drop = True)\r\n",
							"countrySectorExports = countrySectorExports.assign(_c0 = countrySectorLabels['_c0'])\r\n",
							"\r\n",
							"countrySectorExports = countrySectorExports.reindex(columns =[countrySectorExports.columns[-1]] + countrySectorExports.columns[:-1].tolist())\r\n",
							"\r\n",
							"countrySectorExports['_c0'] = countrySectorExports['_c0'].str.replace('Industries, ', '')\r\n",
							"countrySectorExports['_c0'] = countrySectorExports['_c0'].str.replace('Commodities, ', '')"
						],
						"outputs": [],
						"execution_count": 30
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countryCountryExports.set_axis(countryLabels.values.squeeze(), axis = 1, inplace = True)\r\n",
							"countryCountryExports = countryCountryExports.assign(_c0 = countryLabels['_c0'])\r\n",
							"countryCountryExports = countryCountryExports.reindex(columns = [countryCountryExports.columns[-1]] + countryCountryExports.columns[:-1].tolist())\r\n",
							"countryCountryExports.set_index('_c0', inplace = True)"
						],
						"outputs": [],
						"execution_count": 31
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"First up is finding out what are the most \"valuable\" export sectors for each country (Percentage)."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Splitting these out so that I can do a match between the two dataframes\r\n",
							"countrySectorExports[['Country_Code', 'Industry']] = countrySectorExports['_c0'].str.split(', ', n=1, expand=True)\r\n",
							"\r\n",
							"#Setting the index for both equal to the country codes\r\n",
							"countrySectorExports.set_index('Country_Code', inplace = True)\r\n",
							"\r\n",
							"#Saving this to put it back in later\r\n",
							"c0 = pd.DataFrame(countrySectorExports['_c0'])\r\n",
							"\r\n",
							"countrySectorExports = countrySectorExports.drop(['_c0', 'Industry'], axis = 1)\r\n",
							"\r\n",
							"countryCountryExports_repeated = countryCountryExports.reindex(countryCountryExports.index.repeat(26))\r\n",
							"countrySectorExportsPercentOfTotal = (countrySectorExports/ countryCountryExports_repeated) * 100\r\n",
							"countrySectorExportsPercentOfTotal = countrySectorExportsPercentOfTotal.reindex(columns=countrySectorExports.columns)\r\n",
							"\r\n",
							"countrySectorExportsPercentOfTotal = countrySectorExportsPercentOfTotal.assign(Country_Industry = c0['_c0'])\r\n",
							"countrySectorExportsPercentOfTotal = countrySectorExportsPercentOfTotal.reindex(columns=[countrySectorExportsPercentOfTotal.columns[-1]] + countrySectorExportsPercentOfTotal.columns[:-1].tolist())\r\n",
							"countrySectorExportsPercentOfTotal.set_index('Country_Industry', inplace = True)"
						],
						"outputs": [],
						"execution_count": 32
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"(Assuming I'm doing this right) This shows, in percentage terms, where the bulk of trade flows between DEU and BEL are."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"mask_rows = countrySectorExportsPercentOfTotal.index.str.contains(\"DEU\")\r\n",
							"mask_cols = ['BEL' in col for col in countrySectorExportsPercentOfTotal.columns]\r\n",
							"\r\n",
							"filtered_df = countrySectorExportsPercentOfTotal.loc[mask_rows, mask_cols]\r\n",
							"pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x))\r\n",
							"filtered_df"
						],
						"outputs": [],
						"execution_count": 33
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"And now gross imports per sector for each country"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Gross imports by sector for each country\r\n",
							"countrySectorImports = pd.DataFrame(IMGR_INT_cs)\r\n",
							"countrySectorImports = countrySectorImports.assign(_c0 = countrySectorLabels['_c0'])\r\n",
							"countrySectorImports = countrySectorImports.reindex(columns =[countrySectorImports.columns[-1]] + countrySectorImports.columns[:-1].tolist())"
						],
						"outputs": [],
						"execution_count": 34
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countrySectorImports['_c0'] = countrySectorImports['_c0'].str.replace('Industries, ', '')\r\n",
							"countrySectorImports['_c0'] = countrySectorImports['_c0'].str.replace('Commodities, ', '')"
						],
						"outputs": [],
						"execution_count": 35
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countrySectorImports[['Country_Code', 'Industry']] = countrySectorImports['_c0'].str.split(', ', n=1, expand=True)\r\n",
							"countrySectorImports = countrySectorImports.drop(['_c0', 'Industry'], axis = 1)\r\n",
							"countrySectorImports = countrySectorImports.reindex(columns =[countrySectorImports.columns[-1]] + countrySectorImports.columns[:-1].tolist())\r\n",
							"countrySectorImports.set_index('Country_Code', inplace = True)"
						],
						"outputs": [],
						"execution_count": 36
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countryGrossImports = pd.DataFrame(IMGR_c)\r\n",
							"countryGrossImports = countryGrossImports.set_index(countryLabels['_c0'])"
						],
						"outputs": [],
						"execution_count": 37
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countryGrossImports_repeated = countryGrossImports.reindex(countryGrossImports.index.repeat(26))\r\n",
							"countrySectorImportsPercentOfTotal = (countrySectorImports/ countryGrossImports_repeated) * 100\r\n",
							"countrySectorImportsPercentOfTotal = countrySectorImportsPercentOfTotal.assign(Country_Industry = c0['_c0'])\r\n",
							"countrySectorImportsPercentOfTotal.set_index('Country_Industry', inplace = True)"
						],
						"outputs": [],
						"execution_count": 38
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"mask_rows = countrySectorImportsPercentOfTotal.index.str.contains(\"CHN\")\r\n",
							"\r\n",
							"filtered_df = countrySectorImportsPercentOfTotal.loc[mask_rows, :]\r\n",
							"pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x))\r\n",
							"filtered_df"
						],
						"outputs": [],
						"execution_count": 39
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"I want to calculate the value contributed of a country's sector to another.\r\n",
							"\r\n",
							"Example: I want to find out the value contributed of Venezulean oil to country A.\r\n",
							"- I have the gross imports of oil of a country (country sector imports)\r\n",
							"- The total consumption of imported oil from Venezuela to country A should be the row sum of the FD + the row sum of T.\r\n",
							"- I can calculate from this, how much oil is \"Venezuelan\" (sum of imported oil/gross imports of oil)\r\n",
							"\r\n",
							"- Cost of a sector: columnsum of intermediate matrix\r\n",
							"- Total value: gross output of the sector\r\n",
							"- Profit: total - cost"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def importRelianceCalculator(exporter, importer, sector):\r\n",
							"    countrySectorImports = pd.DataFrame(IMGR_INT_cs)\r\n",
							"    countrySectorImports = countrySectorImports.assign(_c0 = countrySectorLabels['_c0'])\r\n",
							"    countrySectorImports = countrySectorImports.reindex(columns =[countrySectorImports.columns[-1]] + countrySectorImports.columns[:-1].tolist())\r\n",
							"\r\n",
							"    countrySectorImportsLabels = ['Country_Sector', 'Value']\r\n",
							"    countrySectorImports = countrySectorImports.rename(columns={countrySectorImports.columns[i]: countrySectorImportsLabels[i] for i in range(len(countrySectorImports.columns))})\r\n",
							"\r\n",
							"    countrySectorImports[['Country_Code', 'Sector']] = countrySectorImports['Country_Sector'].str.split(', ', n=1, expand=True)\r\n",
							"    countrySectorImports.drop(['Country_Sector'], axis = 1, inplace = True)\r\n",
							"    countrySectorImports = countrySectorImports[['Country_Code', 'Sector', 'Value']]\r\n",
							"    countrySectorImports['Sector'] = countrySectorImports['Sector'].str.replace('Industries, ', '')\r\n",
							"    countrySectorImports['Sector'] = countrySectorImports['Sector'].str.replace('Commodities, ', '')\r\n",
							" \r\n",
							"    countryZ_row_filter = eora_data.Z.index.get_level_values('region').str.startswith(str(exporter))\r\n",
							"    countryZ_column_filter = eora_data.Z.columns.get_level_values('region').str.startswith(str(importer))\r\n",
							"\r\n",
							"    countryZ = eora_data.Z.loc[countryZ_row_filter, countryZ_column_filter]\r\n",
							"\r\n",
							"    Zrow_sums = countryZ.sum(axis=1)\r\n",
							"\r\n",
							"    Zrow_sums_df = pd.DataFrame(data = Zrow_sums)\r\n",
							"\r\n",
							"    Zrow_sums_df.columns = [importer]\r\n",
							"\r\n",
							"    countryY_row_filter = eora_data.Z.index.get_level_values('region').str.startswith(str(exporter))\r\n",
							"    countryY_column_filter = eora_data.Y.columns.get_level_values('region').str.startswith(str(importer))\r\n",
							"\r\n",
							"    countryY = eora_data.Y.loc[countryY_row_filter, countryY_column_filter]\r\n",
							"\r\n",
							"    Yrow_sums = countryY.sum(axis=1)\r\n",
							"\r\n",
							"    Yrow_sums_df = pd.DataFrame(data = Yrow_sums)\r\n",
							"\r\n",
							"    Yrow_sums_df.columns = [importer]\r\n",
							"\r\n",
							"    Zspecific_index = (str(exporter), str(sector))\r\n",
							"    Zvalue = Zrow_sums_df.xs(Zspecific_index, level=('region', 'sector'))[str(importer)]\r\n",
							"\r\n",
							"    Yspecific_index = (str(exporter), str(sector))\r\n",
							"    Yvalue = Yrow_sums_df.xs(Yspecific_index, level=('region', 'sector'))[str(importer)]\r\n",
							"\r\n",
							"    sectorImport = Zvalue.values[0] + Yvalue.values[0]\r\n",
							"\r\n",
							"    mask = (countrySectorImports['Country_Code'] == str(importer)) & (countrySectorImports['Sector'] == str(sector))\r\n",
							"    filteredGrossSectorImport = countrySectorImports.loc[mask]\r\n",
							"    shareOfImport = filteredGrossSectorImport['Value']\r\n",
							"    shareOfImport = shareOfImport.values[0]\r\n",
							"\r\n",
							"    importReliance = (sectorImport / shareOfImport)\r\n",
							"    pd.set_option('display.float_format', lambda x: '{:.3f}'.format(x))\r\n",
							"    return importReliance"
						],
						"outputs": [],
						"execution_count": 40
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"importRelianceCalculator('RUS', 'CHN', 'Petroleum, Chemical and Non-Metallic Mineral Products')"
						],
						"outputs": [],
						"execution_count": 41
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countryZ_row_filter = eora_data.Z.index.get_level_values('region').str.startswith('RUS')\r\n",
							"countryZ_column_filter = eora_data.Z.columns.get_level_values('region').str.startswith('CHN')\r\n",
							"\r\n",
							"countryZ = eora_data.Z.loc[countryZ_row_filter, countryZ_column_filter]\r\n",
							"Zcolumn_sums = pd.DataFrame(countryZ.sum(axis=0), columns = ['value'])\r\n",
							"Zcolumn_sums.index.get_level_values('sector').str.contains('Petroleum, Chemical and Non-Metallic Mineral Products')\r\n",
							"\r\n",
							"importCost = Zcolumn_sums.loc[Zcolumn_sums.index.get_level_values('sector').str.contains('Petroleum, Chemical and Non-Metallic Mineral Products'), 'value'].values[0]\r\n",
							"importCost"
						],
						"outputs": [],
						"execution_count": 42
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countrySectorExports = countrySectorExports.loc[countrySectorExports.index.str.contains(\"CHN\")]\r\n",
							"countryTotalExports = countrySectorExports.drop('CHN', axis = 1)\r\n",
							"countryTotalExports = pd.DataFrame(countryTotalExports.sum(axis = 1), columns = ['Value'])"
						],
						"outputs": [],
						"execution_count": 43
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"exporterValue = countryTotalExports['Value'].apply(lambda x: x * (importRelianceCalculator('RUS', 'CHN', 'Petroleum, Chemical and Non-Metallic Mineral Products')))\r\n",
							"exporterValue = pd.DataFrame(exporterValue, columns = ['Value'])"
						],
						"outputs": [],
						"execution_count": 44
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"- $A = GrossOutputs_{Sector}$\r\n",
							"- $B = \\sum_{col} Sector$\r\n",
							"- $C = Z_{CountryA, Country B} / B$\r\n",
							"- $ Result = \\sum \\limits _{Sector 1} ^{Sector 26}[(A-B)*C]$"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Data Import and Prep. THIS ONE WORKS. USE IT.\r\n",
							"Z = eora_data.Z\r\n",
							"\r\n",
							"importer = 'BEL'\r\n",
							"exporter = 'DEU'\r\n",
							"sector = 'Transport'\r\n",
							"\r\n",
							"countrySectorGrossOutput = pd.DataFrame(GO_cs)\r\n",
							"\r\n",
							"countrySectorLabels = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA_Labels/Country+Sector_Labels.csv', format='csv', sep=\"\\t\").toPandas()\r\n",
							"countryLabels = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA_Labels/country-labels.csv', format='csv', sep=\"\\t\").toPandas()\r\n",
							"\r\n",
							"countrySectorLabels = countrySectorLabels.iloc[1:]\r\n",
							"countrySectorLabels = countrySectorLabels.reset_index(drop = True)\r\n",
							"countrySectorGrossOutput  = countrySectorGrossOutput .assign(_c0 = countrySectorLabels['_c0'])\r\n",
							"\r\n",
							"countrySectorGrossOutput  = countrySectorGrossOutput .reindex(columns =[countrySectorGrossOutput .columns[-1]] + countrySectorGrossOutput .columns[:-1].tolist())\r\n",
							"\r\n",
							"countrySectorGrossOutput ['_c0'] = countrySectorGrossOutput ['_c0'].str.replace('Industries, ', '')\r\n",
							"countrySectorGrossOutput ['_c0'] = countrySectorGrossOutput ['_c0'].str.replace('Commodities, ', '')\r\n",
							"\r\n",
							"countrySectorGrossOutput [['country_code', 'sector']] = countrySectorGrossOutput['_c0'].str.split(', ', expand=True,n=1)\r\n",
							"countrySectorGrossOutput = countrySectorGrossOutput .drop('_c0', axis=1)\r\n",
							"\r\n",
							"countrySectorGrossOutput  = countrySectorGrossOutput .rename(columns={0: 'Value'})\r\n",
							"countrySectorGrossOutput  = countrySectorGrossOutput .reindex(columns=['country_code', 'sector', 'Value'])\r\n",
							"\r\n",
							"countrySectorGrossOutput "
						],
						"outputs": [],
						"execution_count": 45
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Gross Exports Data Import and Prep. THIS ONE WORKS. USE IT.\r\n",
							"Z = eora_data.Z\r\n",
							"importer = 'BEL'\r\n",
							"exporter = 'DEU'\r\n",
							"sector = 'Transport'\r\n",
							"\r\n",
							"countrySectorGrossExports = pd.DataFrame(EXGR_cs)\r\n",
							"\r\n",
							"countrySectorLabels = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA_Labels/Country+Sector_Labels.csv', format='csv', sep=\"\\t\").toPandas()\r\n",
							"countryLabels = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA_Labels/country-labels.csv', format='csv', sep=\"\\t\").toPandas()\r\n",
							"\r\n",
							"countrySectorLabels = countrySectorLabels.iloc[1:]\r\n",
							"countrySectorLabels = countrySectorLabels.reset_index(drop = True)\r\n",
							"countrySectorGrossExports = countrySectorGrossExports.assign(_c0 = countrySectorLabels['_c0'])\r\n",
							"\r\n",
							"countrySectorGrossExports = countrySectorGrossExports.reindex(columns =[countrySectorGrossExports.columns[-1]] + countrySectorGrossExports.columns[:-1].tolist())\r\n",
							"\r\n",
							"countrySectorGrossExports['_c0'] = countrySectorGrossExports['_c0'].str.replace('Industries, ', '')\r\n",
							"countrySectorGrossExports['_c0'] = countrySectorGrossExports['_c0'].str.replace('Commodities, ', '')\r\n",
							"\r\n",
							"countrySectorGrossExports[['country_code', 'sector']] = countrySectorGrossExports['_c0'].str.split(', ', expand=True,n=1)\r\n",
							"countrySectorGrossExports = countrySectorGrossExports.drop('_c0', axis=1)\r\n",
							"\r\n",
							"countrySectorGrossExports = countrySectorGrossExports.rename(columns={0: 'Value'})\r\n",
							"countrySectorGrossExports = countrySectorGrossExports.reindex(columns=['country_code', 'sector', 'Value'])\r\n",
							"\r\n",
							"countrySectorGrossExports"
						],
						"outputs": [],
						"execution_count": 46
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Equation A, Gross Ouputs\r\n",
							"countrySectorGrossOutputValue = countrySectorGrossOutput.loc[(countrySectorGrossOutput['country_code'] == 'BEL') & (countrySectorGrossOutput['sector'] == 'Transport'), 'Value'].squeeze()\r\n",
							"countrySectorGrossOutputValue"
						],
						"outputs": [],
						"execution_count": 96
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Equation A (VAR, Gross Ouputs)\r\n",
							"countrySectorOutputGrossValueVAR = countrySectorGrossOutput.loc[(countrySectorGrossOutput['country_code'] == importer) & (countrySectorGrossOutput['sector'] == sector), 'Value'].squeeze()\r\n",
							"countrySectorOutputGrossValueVAR"
						],
						"outputs": [],
						"execution_count": 98
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Equation A (GrossExports)\r\n",
							"countrySectorGrossExportsValue = countrySectorGrossExports.loc[(countrySectorGrossExports['country_code'] == 'BEL') & (countrySectorGrossExports['sector'] == 'Transport'), 'Value'].squeeze()\r\n",
							"countrySectorGrossExportsValue"
						],
						"outputs": [],
						"execution_count": 99
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Equation A (VAR, Gross Exports)\r\n",
							"countrySectorGrossExportsValueVAR = countrySectorGrossExports.loc[(countrySectorGrossExports['country_code'] == importer) & (countrySectorGrossExports['sector'] == sector), 'Value'].squeeze()\r\n",
							"countrySectorGrossExportsValueVAR"
						],
						"outputs": [],
						"execution_count": 100
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Equation B\r\n",
							"sectorColSum = Z.loc[:, [('BEL', 'Transport')]].sum().values[0]\r\n",
							"sectorColSum"
						],
						"outputs": [],
						"execution_count": 101
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Equation B (VAR)\r\n",
							"sectorColSumVAR = Z.loc[:, (importer, sector)].sum()\r\n",
							"sectorColSumVAR"
						],
						"outputs": [],
						"execution_count": 102
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Equation C\r\n",
							"countryZ_row_filter = eora_data.Z.index.get_level_values('region').str.startswith('DEU')\r\n",
							"countryZ_column_filter = eora_data.Z.columns.get_level_values('region').str.startswith('BEL')\r\n",
							"\r\n",
							"countryZ = Z.loc[countryZ_row_filter, countryZ_column_filter]\r\n",
							"importContributions = (countryZ.loc[('DEU', 'Transport'), [('BEL', 'Transport')]].values[0]) / sectorColSum\r\n",
							"importContributions"
						],
						"outputs": [],
						"execution_count": 103
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Equation C (VAR)\r\n",
							"countryZ_row_filter = eora_data.Z.index.get_level_values('region').str.startswith(exporter)\r\n",
							"countryZ_column_filter = eora_data.Z.columns.get_level_values('region').str.startswith(importer)\r\n",
							"\r\n",
							"countryZ = Z.loc[countryZ_row_filter, countryZ_column_filter]\r\n",
							"importContributionsVAR = (countryZ.loc[(exporter, sector), [(importer, sector)]].values[0]) / sectorColSum\r\n",
							"importContributionsVAR"
						],
						"outputs": [],
						"execution_count": 104
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"(countrySectorGrossOutputValue-sectorColSum) * importContributions"
						],
						"outputs": [],
						"execution_count": 105
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"(countrySectorOutputGrossValueVAR-sectorColSumVAR) * importContributionsVAR"
						],
						"outputs": [],
						"execution_count": 106
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def importCalculatorSingleSectorGrossOutput(importer, exporter, sector):\r\n",
							"    # Filter the countrySectorGrossOutput DataFrame to get the output value for the importer and sector\r\n",
							"    countrySectorGrossOutputValue = countrySectorGrossOutput.loc[(countrySectorGrossOutput['country_code'] == importer) & (countrySectorGrossOutput['sector'] == sector), 'Value'].squeeze()\r\n",
							"\r\n",
							"    # Calculate the total output for the sector\r\n",
							"    sectorColSum = Z.loc[:, (importer, sector)].sum()\r\n",
							"\r\n",
							"    # Filter the eora_data.Z DataFrame to get the relevant rows and columns\r\n",
							"    countryZ_row_filter = eora_data.Z.index.get_level_values('region').str.match(exporter)\r\n",
							"    countryZ_column_filter = eora_data.Z.columns.get_level_values('region').str.match(importer)\r\n",
							"\r\n",
							"    countryZ = Z.loc[countryZ_row_filter, countryZ_column_filter]\r\n",
							"    importContributions = (countryZ.loc[(exporter, sector), [(importer, sector)]].values[0]) / sectorColSum\r\n",
							"\r\n",
							"    result = (countrySectorGrossOutputValue-sectorColSum) * importContributions\r\n",
							"    return result"
						],
						"outputs": [],
						"execution_count": 107
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"importCalculatorSingleSectorGrossOutput('BEL', 'DEU', 'Transport')"
						],
						"outputs": [],
						"execution_count": 109
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def importCalculatorGrossOutputVector(importer, exporter, sectors):\r\n",
							"    result = []\r\n",
							"    for sector in sectors:\r\n",
							"        # Filter the countrySectorOutput DataFrame to get the output value for the importer and sector\r\n",
							"        countrySectorGrossOutputValue = countrySectorGrossOutput.loc[(countrySectorGrossOutput['country_code'] == importer) & (countrySectorGrossOutput['sector'] == sector), 'Value'].squeeze()\r\n",
							"\r\n",
							"        # Calculate the total output for the sector\r\n",
							"        sectorColSum = Z.loc[:, (importer, sector)].sum()\r\n",
							"\r\n",
							"        # Filter the eora_data.Z DataFrame to get the relevant rows and columns\r\n",
							"        countryZ_row_filter = eora_data.Z.index.get_level_values('region').str.match(exporter)\r\n",
							"        countryZ_column_filter = eora_data.Z.columns.get_level_values('region').str.match(importer)\r\n",
							"\r\n",
							"        countryZ = Z.loc[countryZ_row_filter, countryZ_column_filter]\r\n",
							"        importContributions = (countryZ.loc[(exporter, sector), [(importer, sector)]].values[0]) / sectorColSum\r\n",
							"\r\n",
							"        result.append((countrySectorGrossOutputValue-sectorColSum) * importContributions)\r\n",
							"    return result"
						],
						"outputs": [],
						"execution_count": 69
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"sectors = ['Agriculture', 'Fishing', 'Mining and Quarrying', 'Food & Beverages', 'Textiles and Wearing Apparel','Wood and Paper', 'Petroleum, Chemical and Non-Metallic Mineral Products', 'Metal Products','Electrical and Machinery', 'Transport Equipment', 'Other Manufacturing', 'Recycling','Electricity, Gas and Water', 'Construction', 'Maintenance and Repair',\t'Wholesale Trade', 'Retail Trade', 'Hotels and Restraurants', 'Transport', 'Post and Telecommunications','Finacial Intermediation and Business Activities', 'Public Administration', 'Education, Health and Other Services', 'Private Households', 'Others','Re-export & Re-import']\r\n",
							"importContributionVector = importCalculatorGrossOutputVector('BEL', 'DEU', sectors)\r\n",
							"#importContributionVector\r\n",
							"importContributionSum = np.squeeze(np.sum(importContributionVector))\r\n",
							"\r\n",
							"importContributionSum"
						],
						"outputs": [],
						"execution_count": 70
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def importCalculatorSingleSectorGrossExports(importer, exporter, sector):\r\n",
							"    # Filter the countrySectorGrossExportsDataFrame to get the output value for the importer and sector\r\n",
							"    countrySectorGrossExportsValue = countrySectorGrossExports.loc[(countrySectorGrossExports['country_code'] == importer) & (countrySectorGrossExports['sector'] == sector), 'Value'].squeeze()\r\n",
							"\r\n",
							"    # Calculate the total exports for the sector\r\n",
							"    sectorColSum = Z.loc[:, (importer, sector)].sum()\r\n",
							"\r\n",
							"    # Filter the eora_data.Z DataFrame to get the relevant rows and columns\r\n",
							"    countryZ_row_filter = eora_data.Z.index.get_level_values('region').str.match(exporter)\r\n",
							"    countryZ_column_filter = eora_data.Z.columns.get_level_values('region').str.match(importer)\r\n",
							"\r\n",
							"    countryZ = Z.loc[countryZ_row_filter, countryZ_column_filter]\r\n",
							"    importContributions = (countryZ.loc[(exporter, sector), [(importer, sector)]].values[0]) / sectorColSum\r\n",
							"\r\n",
							"    result = (countrySectorGrossExportsValue-sectorColSum) * importContributions\r\n",
							"    return result"
						],
						"outputs": [],
						"execution_count": 79
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"importCalculatorSingleSectorGrossExports('BEL', 'DEU', 'Agriculture')"
						],
						"outputs": [],
						"execution_count": 80
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def importCalculatorGrossExportsVector(importer, exporter, sectors):\r\n",
							"    result = []\r\n",
							"    for sector in sectors:\r\n",
							"        # Filter the countrySectorOutput DataFrame to get the output value for the importer and sector\r\n",
							"        countrySectorGrossExportsValue = countrySectorGrossExports.loc[(countrySectorGrossExports['country_code'] == importer) & (countrySectorGrossExports['sector'] == sector), 'Value'].squeeze()\r\n",
							"\r\n",
							"        # Calculate the total output for the sector\r\n",
							"        sectorColSum = Z.loc[:, (importer, sector)].sum()\r\n",
							"\r\n",
							"        # Filter the eora_data.Z DataFrame to get the relevant rows and columns\r\n",
							"        countryZ_row_filter = eora_data.Z.index.get_level_values('region').str.match(exporter)\r\n",
							"        countryZ_column_filter = eora_data.Z.columns.get_level_values('region').str.match(importer)\r\n",
							"\r\n",
							"        countryZ = Z.loc[countryZ_row_filter, countryZ_column_filter]\r\n",
							"        importContributions = (countryZ.loc[(exporter, sector), [(importer, sector)]].values[0]) / sectorColSum\r\n",
							"\r\n",
							"        result.append((countrySectorGrossExportsValue-sectorColSum) * importContributions)\r\n",
							"    return result"
						],
						"outputs": [],
						"execution_count": 81
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"sectors = ['Agriculture', 'Fishing', 'Mining and Quarrying', 'Food & Beverages', 'Textiles and Wearing Apparel','Wood and Paper', 'Petroleum, Chemical and Non-Metallic Mineral Products', 'Metal Products','Electrical and Machinery', 'Transport Equipment', 'Other Manufacturing', 'Recycling','Electricity, Gas and Water', 'Construction', 'Maintenance and Repair',\t'Wholesale Trade', 'Retail Trade', 'Hotels and Restraurants', 'Transport', 'Post and Telecommunications','Finacial Intermediation and Business Activities', 'Public Administration', 'Education, Health and Other Services', 'Private Households', 'Others','Re-export & Re-import']\r\n",
							"importContributionVector = importCalculatorGrossExportsVector('BEL', 'DEU', sectors)\r\n",
							"#importContributionVector\r\n",
							"importContributionSum = np.squeeze(np.sum(importContributionVector))\r\n",
							"\r\n",
							"importContributionSum"
						],
						"outputs": [],
						"execution_count": 82
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"This is just the gross balance of trade."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"BALGR_c = EXGR_c - IMGR_c\r\n",
							"BoT = pd.DataFrame(BALGR_c)\r\n",
							"BoT"
						],
						"outputs": [],
						"execution_count": 83
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"I need to calculate the country to country imports and country to country exports. Balance of trade would just be the exports minus the imports. I have the country to country exports (countryCountryExports). I should be able to flip the direction to get the imports (i.e. exports from Albania to Afghanistan == Afghan imports from Albania)"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countrySectorExports = pd.DataFrame(EXGR_cs_c)\r\n",
							"countryCountryExports = pd.DataFrame(EXGR_c_c)\r\n",
							"\r\n",
							"countrySectorLabels = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA_Labels/Country+Sector_Labels.csv', format='csv', sep=\"\\t\").toPandas()\r\n",
							"countryLabels = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA_Labels/country-labels.csv', format='csv', sep=\"\\t\").toPandas()\r\n",
							"\r\n",
							"countrySectorExports.set_axis(countryLabels.values.squeeze(), axis = 1, inplace = True)\r\n",
							"\r\n",
							"countrySectorLabels = countrySectorLabels.iloc[1:]\r\n",
							"countrySectorLabels = countrySectorLabels.reset_index(drop = True)\r\n",
							"countrySectorExports = countrySectorExports.assign(_c0 = countrySectorLabels['_c0'])\r\n",
							"\r\n",
							"countrySectorExports = countrySectorExports.reindex(columns =[countrySectorExports.columns[-1]] + countrySectorExports.columns[:-1].tolist())\r\n",
							"\r\n",
							"countrySectorExports['_c0'] = countrySectorExports['_c0'].str.replace('Industries, ', '')\r\n",
							"countrySectorExports['_c0'] = countrySectorExports['_c0'].str.replace('Commodities, ', '')\r\n",
							"\r\n",
							"countryCountryExports.set_axis(countryLabels.values.squeeze(), axis = 1, inplace = True)\r\n",
							"countryCountryExports = countryCountryExports.assign(_c0 = countryLabels['_c0'])\r\n",
							"countryCountryExports = countryCountryExports.reindex(columns = [countryCountryExports.columns[-1]] + countryCountryExports.columns[:-1].tolist())\r\n",
							"countryCountryExports.set_index('_c0', inplace = True)"
						],
						"outputs": [],
						"execution_count": 84
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def countryCountryBalanceOfTrade(supplier, countryOfInterest):\r\n",
							"    exportValue = countryCountryExports.loc[countryOfInterest, supplier]\r\n",
							"    importValue = countryCountryExports.loc[supplier, countryOfInterest]\r\n",
							"\r\n",
							"    BoT = exportValue-importValue\r\n",
							"    return BoT"
						],
						"outputs": [],
						"execution_count": 85
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countryCountryExports.sum(axis = 1)"
						],
						"outputs": [],
						"execution_count": 86
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countryCountryBalanceOfTrade('CHN', 'USA')"
						],
						"outputs": [],
						"execution_count": 87
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def grossBalanceOfTrade(countryOfInterest):\r\n",
							"    BoT = 0\r\n",
							"    for supplier in countryCountryExports.columns:\r\n",
							"        exportValue = countryCountryExports.loc[countryOfInterest, supplier]\r\n",
							"        importValue = countryCountryExports.loc[supplier, countryOfInterest]\r\n",
							"        BoT += exportValue - importValue\r\n",
							"    return BoT"
						],
						"outputs": [],
						"execution_count": 88
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"grossBalanceOfTrade('AFG')"
						],
						"outputs": [],
						"execution_count": 89
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def balanceOfTradeForAll(countryOfInterest):\r\n",
							"    BoT_list = []\r\n",
							"    for supplier in countryCountryExports.columns:\r\n",
							"        exportValue = countryCountryExports.loc[countryOfInterest, supplier]\r\n",
							"        importValue = countryCountryExports.loc[supplier, countryOfInterest]\r\n",
							"        BoT = exportValue - importValue\r\n",
							"        BoT_list.append(BoT)\r\n",
							"    return BoT_list"
						],
						"outputs": [],
						"execution_count": 90
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"balanceOfTradeForAll('AFG')"
						],
						"outputs": [],
						"execution_count": 91
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countryCountryBalanceOfTradeList = np.zeros((len(countryCountryExports.columns), len(countryCountryExports.columns)))\r\n",
							"for i, country in enumerate(countryCountryExports.columns):\r\n",
							"    BoT_list = balanceOfTradeForAll(country)\r\n",
							"    countryCountryBalanceOfTradeList[i] = np.array(BoT_list)"
						],
						"outputs": [],
						"execution_count": 92
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countryCountryBalanceOfTradeFrame = pd.DataFrame(np.zeros((len(countryCountryExports.columns), len(countryCountryExports.columns))), index=countryCountryExports.columns, columns=countryCountryExports.columns)\r\n",
							"for i, country in enumerate(countryCountryExports.columns):\r\n",
							"    BoT_list = balanceOfTradeForAll(country)\r\n",
							"    countryCountryBalanceOfTradeFrame.iloc[i] = np.array(BoT_list)"
						],
						"outputs": [],
						"execution_count": 93
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/EORA_PyMRIO2')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ac2sparkpooldev",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "e637e0af-b89f-47c6-a019-e4ec046bbd72"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Synapse/workspaces/ac2-synapse-ws-dev/bigDataPools/ac2sparkpooldev",
						"name": "ac2sparkpooldev",
						"type": "Spark",
						"endpoint": "https://ac2-synapse-ws-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ac2sparkpooldev",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"print(\"Im Awake\")\r\n",
							"\r\n",
							"#import pymrio as pmr\r\n",
							"from notebookutils import mssparkutils\r\n",
							"import os\r\n",
							"import io\r\n",
							"from collections import namedtuple\r\n",
							"import pandas as pd\r\n",
							"import numpy as np\r\n",
							"import plotly.graph_objects as go\r\n",
							"from scipy.linalg import block_diag\r\n",
							"import warnings\r\n",
							"\r\n",
							"pd.set_option('display.max_columns', 30)\r\n",
							"pd.set_option('display.expand_frame_repr', False)\r\n",
							"pd.set_option('max_colwidth', None)"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Parameters\r\n",
							"num_cntry = 189\r\n",
							"num_sectors = 26\r\n",
							"num_fd_components = 6\r\n",
							"year_start = 2022\r\n",
							"year_end = 2022\r\n",
							"\r\n",
							"#eora_years = np.linspace(year_start, year_end, num = year_end - year_start + 1).astype(int).astype(str)\r\n",
							"\r\n",
							"#Read in the data\r\n",
							"fd_matrix_path = 'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_2022_bp/Eora26_2022_bp_FD.txt'\r\n",
							"id_matrix_path = 'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_2022_bp/Eora26_2022_bp_T.txt'\r\n",
							"va_matrix_path = 'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_2022_bp/Eora26_2022_bp_VA.txt'\r\n",
							"\r\n",
							"fd_matrix = spark.read.load(fd_matrix_path, format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"id_matrix = spark.read.load(id_matrix_path, format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"va_matrix = spark.read.load(va_matrix_path, format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"#print(\"Data read for year: \" + eora_years[i])\r\n",
							"\r\n",
							"# Compute Stats\r\n",
							"va_total_cs = va_matrix.sum(axis = 0)\r\n",
							"FD = fd_matrix.reshape((num_cntry*num_sectors + 1), num_fd_components, -1)\r\n",
							"FD = FD.sum(axis=1)\r\n",
							"FD = np.squeeze(FD) # Squeeze to remove single-dimensional entries\r\n",
							"\r\n",
							"GRTR_INT_cs_cs = id_matrix[0:(num_cntry*num_sectors), 0:(num_cntry*num_sectors)]\r\n",
							"GRTR_FNL_cs_c = FD[0:num_cntry*num_sectors,0:num_cntry]\r\n",
							"VALUE_cs = va_total_cs[0:(num_cntry*num_sectors)]\r\n",
							"\r\n",
							"# Initialize empty list to hold blocks\r\n",
							"imtx_cs_c = []\r\n",
							"imtx_cs_cs = []\r\n",
							"imtx_c_cs=[]\r\n",
							"imtx_cs_ck = []\r\n",
							"\r\n",
							"# Create block matrix\r\n",
							"iblk_cs_c = np.ones((num_sectors, 1))  # Create num_sectors x 1 vector of ones\r\n",
							"iblk_cs_cs = np.ones((num_sectors,num_sectors))\r\n",
							"ivector = np.ones((1, num_sectors))\r\n",
							"iblk_cs_ck = np.ones((num_sectors, num_fd_components))\r\n",
							"\r\n",
							"# Construct block diagonal matrix\r\n",
							"for j in range(num_cntry):\r\n",
							"    if j == 0:\r\n",
							"        imtx_cs_c = iblk_cs_c  # Initialize with the first block\r\n",
							"        imtx_cs_cs = iblk_cs_cs\r\n",
							"        imtx_c_cs = ivector\r\n",
							"        imtx_cs_ck = iblk_cs_ck\r\n",
							"\r\n",
							"    else:\r\n",
							"        imtx_cs_c = block_diag(imtx_cs_c, iblk_cs_c) \r\n",
							"        imtx_cs_cs = block_diag(imtx_cs_cs, iblk_cs_cs) \r\n",
							"        imtx_c_cs = block_diag(imtx_c_cs, ivector)\r\n",
							"        imtx_cs_ck = block_diag(imtx_cs_ck, iblk_cs_ck)\r\n",
							"\r\n",
							"imtx_c_c = np.eye(num_cntry)\r\n",
							"\r\n",
							"#Gross Output\r\n",
							"GO_cs_c = GRTR_INT_cs_cs.reshape(num_cntry*num_sectors, num_sectors, -1)\r\n",
							"GO_cs_c = GO_cs_c.sum(axis = 1)\r\n",
							"GO_cs_c = np.squeeze(GO_cs_c)\r\n",
							"GO_cs_c = GO_cs_c + GRTR_FNL_cs_c\r\n",
							"GO_cs = GO_cs_c.sum(axis = 1)\r\n",
							"GO_c_c = np.matmul(imtx_c_cs,GO_cs_c)\r\n",
							"elementwise_GO_product =  np.tile(GO_cs[:, np.newaxis],(1,num_cntry)) * imtx_cs_c\r\n",
							"summed_GO_result = elementwise_GO_product.sum(axis=0)\r\n",
							"GO_c = summed_GO_result.T\r\n",
							"\r\n",
							"#Value Added\r\n",
							"elementwise_VALUE_product = np.tile(VALUE_cs[:, np.newaxis], (1, num_cntry)) * imtx_cs_c\r\n",
							"summed_VALUE_result = elementwise_VALUE_product.sum(axis=0)\r\n",
							"VALUE_c = summed_VALUE_result.T\r\n",
							"\r\n",
							"#Derived value added\r\n",
							"Inputs_cs = GRTR_INT_cs_cs.sum(axis = 0)\r\n",
							"replicated_Inputs_cs = np.tile(Inputs_cs[:, np.newaxis], (1, num_cntry)) \r\n",
							"elementwise_INPUTS_product = replicated_Inputs_cs * imtx_cs_c\r\n",
							"summed_INPUTS_result = elementwise_INPUTS_product.sum(axis = 0)\r\n",
							"Inputs_c = summed_INPUTS_result.T\r\n",
							"\r\n",
							"#VA = Gross Outputs - Inputs\r\n",
							"VALUE_derived_cs = GO_cs - Inputs_cs\r\n",
							"replicated_VALUE_derived_cs = np.tile(VALUE_derived_cs[:, np.newaxis], (1, num_cntry))\r\n",
							"elementwise_VALUE_derived_product = replicated_VALUE_derived_cs * imtx_cs_c\r\n",
							"summed_VALUE_derived_result = elementwise_VALUE_derived_product.sum(axis = 0)\r\n",
							"VALUE_derived_c = summed_VALUE_derived_result.T\r\n",
							"\r\n",
							"#Gross Exports\r\n",
							"ones_cs_cs_array = np.ones((num_cntry*num_sectors))\r\n",
							"EXGR_INT_cs_cs = GRTR_INT_cs_cs * (ones_cs_cs_array - imtx_cs_cs)\r\n",
							"\r\n",
							"EXGR_INT_cs_c = np.full((num_cntry * num_sectors, num_cntry), np.nan)\r\n",
							"for k in range(num_cntry):\r\n",
							"    EXGR_INT_cs_c[:, k] = np.sum(EXGR_INT_cs_cs[:, (k * num_sectors):(num_sectors * (k + 1))], axis=1)\r\n",
							"\r\n",
							"EXGR_INT_cs = EXGR_INT_cs_cs.sum(axis = 1)\r\n",
							"\r\n",
							"replicated_EXGR_INT_cs = np.tile(EXGR_INT_cs[:, np.newaxis], (1, num_cntry))\r\n",
							"elementwise_EXGR_INT_cs_product = replicated_EXGR_INT_cs * imtx_cs_c\r\n",
							"summed_EXGR_INT_cs_result = elementwise_EXGR_INT_cs_product.sum(axis = 0)\r\n",
							"EXGR_INT_c = summed_EXGR_INT_cs_result.T\r\n",
							"\r\n",
							"ones_cs_c_array = np.ones((num_cntry*num_sectors, num_cntry))\r\n",
							"EXGR_FNL_cs_c = GRTR_FNL_cs_c * (ones_cs_c_array - imtx_cs_c)\r\n",
							"\r\n",
							"EXGR_FNL_cs = EXGR_FNL_cs_c * (ones_cs_c_array - imtx_cs_c)\r\n",
							"EXGR_FNL_cs = EXGR_FNL_cs.sum(axis = 1)\r\n",
							"\r\n",
							"EXGR_FNL_c = np.tile(EXGR_FNL_cs[:, np.newaxis],(1, num_cntry)) * imtx_cs_c\r\n",
							"EXGR_FNL_c = EXGR_FNL_c.sum(axis = 0).T\r\n",
							"\r\n",
							"EXGR_cs_c = EXGR_INT_cs_c + EXGR_FNL_cs_c\r\n",
							"EXGR_c_c = np.matmul(imtx_c_cs, EXGR_cs_c)\r\n",
							"\r\n",
							"EXGR_cs = EXGR_INT_cs + EXGR_FNL_cs\r\n",
							"EXGR_c = EXGR_INT_c + EXGR_FNL_c\r\n",
							"\r\n",
							"#Gross Imports\r\n",
							"ones_cs_array = np.ones((num_cntry * num_sectors))\r\n",
							"IMGR_INT_cs = GRTR_INT_cs_cs * (ones_cs_array - imtx_cs_cs)\r\n",
							"IMGR_INT_cs = IMGR_INT_cs.sum(axis = 0)\r\n",
							"\r\n",
							"IMGR_INT_c = np.tile(IMGR_INT_cs[:, np.newaxis],(1, num_cntry)) * imtx_cs_c\r\n",
							"IMGR_INT_c = IMGR_INT_c.sum(axis = 0).T\r\n",
							"\r\n",
							"ones_cs_c_array = np.ones((num_cntry * num_sectors, num_cntry))\r\n",
							"IMGR_FNL_c = GRTR_FNL_cs_c * (ones_cs_c_array - imtx_cs_c)\r\n",
							"IMGR_FNL_c = IMGR_FNL_c.sum(axis = 0).T\r\n",
							"\r\n",
							"IMGR_c = IMGR_INT_c + IMGR_FNL_c\r\n",
							"\r\n",
							"#Gross Trade Balance\r\n",
							"BALGR_c = EXGR_c - IMGR_c\r\n",
							"\r\n",
							"#Demand for Domestic Inputs (Use of Domestic Intermediates)\r\n",
							"DDGR_INT_cs = GRTR_INT_cs_cs * imtx_cs_cs\r\n",
							"DDGR_INT_cs = DDGR_INT_cs.sum(axis = 0).T\r\n",
							"\r\n",
							"DDGR_INT_c = np.tile(DDGR_INT_cs[:, np.newaxis],(1, num_cntry)) * imtx_cs_c\r\n",
							"DDGR_INT_c = DDGR_INT_c.sum(axis = 0).T\r\n",
							"\r\n",
							"DDGR_FNL_c = GRTR_FNL_cs_c * imtx_cs_c\r\n",
							"DDGR_FNL_c = DDGR_FNL_c.sum(axis = 0).T\r\n",
							"\r\n",
							"#Domestic and Foreign Final Demand\r\n",
							"GRTR_FNL_DOM_cs_c = GRTR_FNL_cs_c * imtx_cs_c\r\n",
							"GRTR_FNL_DOM_cs = GRTR_FNL_DOM_cs_c.sum(axis = 1)\r\n",
							"\r\n",
							"#By sector\r\n",
							"GRTR_FNL_DOM_cs_ck = fd_matrix[0:num_cntry*num_sectors, 0:num_cntry*num_fd_components] * imtx_cs_ck\r\n",
							"\r\n",
							"##Sum across the third dimension, across countries for each of the 6 components of final demand\r\n",
							"GRTR_FNL_DOM_cs_nfd = GRTR_FNL_DOM_cs_ck.reshape((num_cntry*num_sectors), num_fd_components, -1)\r\n",
							"GRTR_FNL_DOM_cs_nfd = GRTR_FNL_DOM_cs_nfd.sum(axis = 2)\r\n",
							"\r\n",
							"#Foreign Demand\r\n",
							"GRTR_FNL_FOR_cs_c = GRTR_FNL_cs_c * (ones_cs_c_array - imtx_cs_c)\r\n",
							"GRTR_FNL_FOR_cs = GRTR_FNL_FOR_cs_c.sum(axis = 1)\r\n",
							"\r\n",
							"##By sector\r\n",
							"ones_cs_ck_array = np.ones((num_cntry*num_sectors, num_cntry*num_fd_components))\r\n",
							"GRTR_FNL_FOR_cs_ck = fd_matrix[0:num_cntry*num_sectors, 0:num_cntry*num_fd_components] * (ones_cs_ck_array - imtx_cs_ck)\r\n",
							"\r\n",
							"##Sum across the third dimension, across countries for each of the 6 components of final demand\r\n",
							"GRTR_FNL_FOR_cs_nfd = GRTR_FNL_FOR_cs_ck.reshape((num_cntry*num_sectors), num_fd_components, -1)\r\n",
							"GRTR_FNL_FOR_cs_nfd = GRTR_FNL_FOR_cs_nfd.sum(axis = 2)\r\n",
							"\r\n",
							"#VA Vector\r\n",
							"with warnings.catch_warnings():\r\n",
							"    warnings.simplefilter('ignore')\r\n",
							"    Amat = GRTR_INT_cs_cs / np.tile(GO_cs[:, np.newaxis], (1, num_cntry * num_sectors))\r\n",
							"\r\n",
							"Amat[np.isnan(Amat)] = 0\r\n",
							"Amat[np.isinf(Amat)] = 0\r\n",
							"\r\n",
							"#VA shares\r\n",
							"va_vec_cs = 1 - np.sum(Amat)\r\n",
							"V_hat = np.eye((num_cntry * num_sectors)) - np.diag(Amat.sum(axis = 0))\r\n",
							"\r\n",
							"#Leontief inverse\r\n",
							"IminusA = np.eye((num_cntry * num_sectors)) - Amat\r\n",
							"Bmat = np.linalg.inv(IminusA)\r\n",
							"\r\n",
							"#Total Value Added by country-sector\r\n",
							"BY = np.matmul(Bmat, GRTR_FNL_cs_c.sum(axis = 1))\r\n",
							"va_cs = va_vec_cs * BY\r\n",
							"\r\n",
							"#DVA and FVA of gross exports (From V*B*E)\r\n",
							"TiVA = V_hat @ Bmat @ np.diag(EXGR_cs)\r\n",
							"\r\n",
							"EXGR_DVA_cs = np.sum(TiVA * imtx_cs_cs, axis = 0).T\r\n",
							"EXGR_FVA_cs = np.sum(TiVA * (ones_cs_array - imtx_cs_cs), axis = 0).T\r\n",
							"\r\n",
							"EXGR_DVA_c = np.tile(EXGR_DVA_cs[:, np.newaxis],(1, num_cntry)) * imtx_cs_c\r\n",
							"EXGR_DVA_c = EXGR_DVA_c.sum(axis = 0).T\r\n",
							"\r\n",
							"EXGR_FVA_c = np.tile(EXGR_FVA_cs[:, np.newaxis],(1, num_cntry)) * imtx_cs_c\r\n",
							"EXGR_FVA_c = EXGR_FVA_c.sum(axis = 0).T\r\n",
							"\r\n",
							"VS1_cs = np.sum(TiVA * (ones_cs_array - imtx_cs_cs), axis = 1)\r\n",
							"VS1_c = np.tile(VS1_cs[:, np.newaxis], (1, num_cntry)) * imtx_cs_c\r\n",
							"VS1_c = VS1_c.sum(axis = 0).T\r\n",
							"\r\n",
							"#Compute VA matrices (from V*B*Y)\r\n",
							"VA_cs_c = V_hat @ Bmat @ GRTR_FNL_cs_c\r\n",
							"\r\n",
							"ones_c_c_array = np.ones((num_cntry, num_cntry))\r\n",
							"VAX_cs_c = VA_cs_c * (ones_cs_c_array - imtx_cs_c)\r\n",
							"VA_c_c = np.matmul(imtx_c_cs, VA_cs_c)\r\n",
							"\r\n",
							"#Value added of exports only (exclude value_added of demestic goods)\r\n",
							"VAX_c_c = VA_c_c * (ones_c_c_array - np.eye(num_cntry))\r\n",
							"\r\n",
							"VAX_c = VAX_c_c.sum(axis = 1)\r\n",
							"\r\n",
							"#Koopman et al. Equation 36 Terms\r\n",
							"VAX1_cs_c = V_hat @ (Bmat * imtx_cs_cs) @ (GRTR_FNL_cs_c * (ones_cs_c_array - imtx_cs_c))\r\n",
							"VAX1_c_c = np.matmul(imtx_c_cs, VAX1_cs_c) # aggregate across rows by country\r\n",
							"VAX1_c = VAX1_c_c.sum(axis = 1)\r\n",
							"\r\n",
							"VAX2_cs_c = V_hat @ (Bmat * (ones_cs_array - imtx_cs_cs)) @ (GRTR_FNL_cs_c  - imtx_cs_c)\r\n",
							"VAX2_c_c = np.matmul(imtx_c_cs, VAX2_cs_c) # aggregate across rows by country\r\n",
							"VAX2_c = VAX2_c_c.sum(axis = 1)\r\n",
							"\r\n",
							"VAX3_cs_c_sum1 = V_hat @ (Bmat * (ones_cs_array - imtx_cs_cs)) @ (GRTR_FNL_cs_c * (ones_cs_c_array - imtx_cs_c))\r\n",
							"VAX3_cs_c_sum2 = VAX3_cs_c_sum1 * (ones_cs_c_array - imtx_cs_c)\r\n",
							"VAX3_c_c = np.matmul(imtx_c_cs, VAX3_cs_c_sum2) # aggregate across rows by country\r\n",
							"VAX3_c = VAX3_c_c.sum(axis = 1)\r\n",
							"\r\n",
							"DVA4_cs_c = V_hat @ (Bmat * (ones_cs_array - imtx_cs_cs)) @ (GRTR_FNL_cs_c * (ones_cs_c_array - imtx_cs_c))\r\n",
							"DVA4_c_c = np.matmul(imtx_c_cs,DVA4_cs_c) * imtx_c_c # aggregate across rows by country, and take just the diagonal elements\r\n",
							"DVA4_c = DVA4_c_c.sum(axis = 1)\r\n",
							"\r\n",
							"eye_inverse = np.linalg.inv(np.eye((num_cntry * num_sectors)))\r\n",
							"DVA5_cs_c = V_hat @ (Bmat * (ones_cs_array - imtx_cs_cs)) @ (Amat * (ones_cs_array - imtx_cs_cs)) @\\\r\n",
							"            ((eye_inverse - Amat) * imtx_cs_cs) @ (GRTR_FNL_cs_c * imtx_cs_c)\r\n",
							"DVA5_c_c = np.matmul(imtx_c_cs,DVA5_cs_c) * imtx_c_c # aggregate across rows by country, and take just the diagonal elements\r\n",
							"DVA5_c = DVA5_c_c.sum(axis = 1)\r\n",
							"\r\n",
							"DVA6_c = EXGR_DVA_c - VAX_c - DVA4_c - DVA5_c\r\n",
							"\r\n",
							"#Foreign Value Added in Domestic Final Demand\r\n",
							"DFD_FVA_c = VAX_c_c.sum(axis = 0)"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countrySectorLabels = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA_Labels/Country+Sector_Labels.csv', format='csv', sep=\"\\t\").toPandas()\r\n",
							"countrySectorLabels = countrySectorLabels.iloc[1:]\r\n",
							"countrySectorLabels = countrySectorLabels.reset_index(drop = True)\r\n",
							"\r\n",
							"countrySectorLabels['_c0'] = countrySectorLabels['_c0'].str.replace('Industries, ', '')\r\n",
							"countrySectorLabels['_c0'] = countrySectorLabels['_c0'].str.replace('Commodities, ', '')\r\n",
							"countrySectorLabels[['Country_Code', 'Sector']] = countrySectorLabels['_c0'].str.split(', ', n=1, expand=True)\r\n",
							"countrySectorLabels = countrySectorLabels.drop(['_c0'], axis = 1)"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Zindex1 = countrySectorLabels['Country_Code']\r\n",
							"Zindex2 = countrySectorLabels['Sector']\r\n",
							"\r\n",
							"Z = pd.DataFrame(id_matrix)\r\n",
							"Z = Z.iloc[:-1, :-1]\r\n",
							"Z = Z.set_index([Zindex1, Zindex2])\r\n",
							"Z.columns = pd.MultiIndex.from_tuples(list(zip(Zindex1, Zindex2)))\r\n",
							"Z.columns.names = ['Country_Code', 'Sector']\r\n",
							"Z"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Gross Output Data Import and Prep. THIS ONE WORKS. USE IT.\r\n",
							"\r\n",
							"importer = 'BEL'\r\n",
							"exporter = 'DEU'\r\n",
							"sector = 'Transport'\r\n",
							"\r\n",
							"countrySectorGrossOutput = pd.DataFrame(GO_cs)\r\n",
							"\r\n",
							"countrySectorLabels = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA_Labels/Country+Sector_Labels.csv', format='csv', sep=\"\\t\").toPandas()\r\n",
							"countryLabels = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA_Labels/country-labels.csv', format='csv', sep=\"\\t\").toPandas()\r\n",
							"\r\n",
							"countrySectorLabels = countrySectorLabels.iloc[1:]\r\n",
							"countrySectorLabels = countrySectorLabels.reset_index(drop = True)\r\n",
							"countrySectorGrossOutput = countrySectorGrossOutput.assign(_c0 = countrySectorLabels['_c0'])\r\n",
							"\r\n",
							"countrySectorGrossOutput = countrySectorGrossOutput.reindex(columns =[countrySectorGrossOutput.columns[-1]] + countrySectorGrossOutput.columns[:-1].tolist())\r\n",
							"\r\n",
							"countrySectorGrossOutput['_c0'] = countrySectorGrossOutput['_c0'].str.replace('Industries, ', '')\r\n",
							"countrySectorGrossOutput['_c0'] = countrySectorGrossOutput['_c0'].str.replace('Commodities, ', '')\r\n",
							"\r\n",
							"countrySectorGrossOutput[['country_code', 'sector']] = countrySectorGrossOutput['_c0'].str.split(', ', expand=True,n=1)\r\n",
							"countrySectorGrossOutput = countrySectorGrossOutput.drop('_c0', axis=1)\r\n",
							"\r\n",
							"countrySectorGrossOutput = countrySectorGrossOutput.rename(columns={0: 'Value'})\r\n",
							"countrySectorGrossOutput = countrySectorGrossOutput.reindex(columns=['country_code', 'sector', 'Value'])\r\n",
							"\r\n",
							"countrySectorGrossOutput"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Gross Exports Data Import and Prep. THIS ONE WORKS. USE IT.\r\n",
							"importer = 'BEL'\r\n",
							"exporter = 'DEU'\r\n",
							"sector = 'Transport'\r\n",
							"\r\n",
							"countrySectorGrossExports = pd.DataFrame(EXGR_cs)\r\n",
							"\r\n",
							"countrySectorLabels = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA_Labels/Country+Sector_Labels.csv', format='csv', sep=\"\\t\").toPandas()\r\n",
							"countryLabels = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA_Labels/country-labels.csv', format='csv', sep=\"\\t\").toPandas()\r\n",
							"\r\n",
							"countrySectorLabels = countrySectorLabels.iloc[1:]\r\n",
							"countrySectorLabels = countrySectorLabels.reset_index(drop = True)\r\n",
							"countrySectorGrossExports = countrySectorGrossExports.assign(_c0 = countrySectorLabels['_c0'])\r\n",
							"\r\n",
							"countrySectorGrossExports = countrySectorGrossExports.reindex(columns =[countrySectorGrossExports.columns[-1]] + countrySectorGrossExports.columns[:-1].tolist())\r\n",
							"\r\n",
							"countrySectorGrossExports['_c0'] = countrySectorGrossExports['_c0'].str.replace('Industries, ', '')\r\n",
							"countrySectorGrossExports['_c0'] = countrySectorGrossExports['_c0'].str.replace('Commodities, ', '')\r\n",
							"\r\n",
							"countrySectorGrossExports[['country_code', 'sector']] = countrySectorGrossExports['_c0'].str.split(', ', expand=True,n=1)\r\n",
							"countrySectorGrossExports = countrySectorGrossExports.drop('_c0', axis=1)\r\n",
							"\r\n",
							"countrySectorGrossExports = countrySectorGrossExports.rename(columns={0: 'Value'})\r\n",
							"countrySectorGrossExports = countrySectorGrossExports.reindex(columns=['country_code', 'sector', 'Value'])\r\n",
							"\r\n",
							"countrySectorGrossExports"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"- $A = GrossOutputs_{Sector}$\r\n",
							"- $B = \\sum_{col} Sector$\r\n",
							"- $C = Z_{CountryA, Country B} / B$\r\n",
							"- $ Result = \\sum \\limits _{Sector 1} ^{Sector 26}[(A-B)*C]$"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Equation A (GrossOutput)\r\n",
							"countrySectorGrossOutputValue = countrySectorGrossOutput.loc[(countrySectorGrossOutput['country_code'] == 'BEL') & (countrySectorGrossOutput['sector'] == 'Transport'), 'Value'].squeeze()\r\n",
							"countrySectorGrossOutputValue"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Equation A (VAR, Gross Ouput)\r\n",
							"countrySectorGrossOutputValueVAR = countrySectorGrossOutput.loc[(countrySectorGrossOutput['country_code'] == importer) & (countrySectorGrossOutput['sector'] == sector), 'Value'].squeeze()\r\n",
							"countrySectorGrossOutputValueVAR"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Equation A (GrossExports)\r\n",
							"countrySectorGrossExportsValue = countrySectorGrossExports.loc[(countrySectorGrossExports['country_code'] == 'BEL') & (countrySectorGrossExports['sector'] == 'Transport'), 'Value'].squeeze()\r\n",
							"countrySectorGrossExportsValue"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Equation A (VAR, Gross Ouput)\r\n",
							"countrySectorGrossExportsValueVAR = countrySectorGrossExports.loc[(countrySectorGrossExports['country_code'] == importer) & (countrySectorGrossExports['sector'] == sector), 'Value'].squeeze()\r\n",
							"countrySectorGrossExportsValueVAR"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Equation B\r\n",
							"sectorColSum = Z.loc[:, [('BEL', 'Transport')]].sum().values[0]\r\n",
							"sectorColSum"
						],
						"outputs": [],
						"execution_count": 12
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Equation B (VAR)\r\n",
							"sectorColSumVAR = Z.loc[:, (importer, sector)].sum()\r\n",
							"sectorColSumVAR"
						],
						"outputs": [],
						"execution_count": 13
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Equation C\r\n",
							"countryZ_row_filter = Z.index.get_level_values('Country_Code').str.startswith('DEU')\r\n",
							"countryZ_column_filter = Z.columns.get_level_values('Country_Code').str.startswith('BEL')\r\n",
							"\r\n",
							"countryZ = Z.loc[countryZ_row_filter, countryZ_column_filter]\r\n",
							"importContributions = (countryZ.loc[('DEU', 'Transport'), [('BEL', 'Transport')]].values[0]) / sectorColSum\r\n",
							"importContributions"
						],
						"outputs": [],
						"execution_count": 14
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Equation C (VAR)\r\n",
							"countryZ_row_filter = Z.index.get_level_values('Country_Code').str.startswith(exporter)\r\n",
							"countryZ_column_filter = Z.columns.get_level_values('Country_Code').str.startswith(importer)\r\n",
							"\r\n",
							"countryZ = Z.loc[countryZ_row_filter, countryZ_column_filter]\r\n",
							"importContributionsVAR = (countryZ.loc[(exporter, sector), [(importer, sector)]].values[0]) / sectorColSum\r\n",
							"importContributionsVAR"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def importCalculatorSingleSectorGrossOutput(importer, exporter, sector):\r\n",
							"    # Filter the countrySectorGrossOutput DataFrame to get the output value for the importer and sector\r\n",
							"    countrySectorGrossOutputValue = countrySectorGrossOutput.loc[(countrySectorGrossOutput['country_code'] == importer) & (countrySectorGrossOutput['sector'] == sector), 'Value'].squeeze()\r\n",
							"\r\n",
							"    # Calculate the total output for the sector\r\n",
							"    sectorColSum = Z.loc[:, (importer, sector)].sum()\r\n",
							"\r\n",
							"    # Filter the Z DataFrame to get the relevant rows and columns\r\n",
							"    countryZ_row_filter = Z.index.get_level_values('Country_Code').str.match(exporter)\r\n",
							"    countryZ_column_filter = Z.columns.get_level_values('Country_Code').str.match(importer)\r\n",
							"\r\n",
							"    countryZ = Z.loc[countryZ_row_filter, countryZ_column_filter]\r\n",
							"    importContributions = (countryZ.loc[(exporter, sector), [(importer, sector)]].values[0]) / sectorColSum\r\n",
							"\r\n",
							"    result = (countrySectorGrossOutputValue-sectorColSum) * importContributions\r\n",
							"    return result"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"importCalculatorSingleSectorGrossOutput('BEL', 'DEU', 'Transport')"
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def importCalculatorSingleSectorGrossExports(importer, exporter, sector):\r\n",
							"    # Filter the countrySectorGrossOutput DataFrame to get the output value for the importer and sector\r\n",
							"    countrySectorGrossExportsValue = countrySectorGrossExports.loc[(countrySectorGrossExports['country_code'] == importer) & (countrySectorGrossExports['sector'] == sector), 'Value'].squeeze()\r\n",
							"\r\n",
							"    # Calculate the total output for the sector\r\n",
							"    sectorColSum = Z.loc[:, (importer, sector)].sum()\r\n",
							"\r\n",
							"    # Filter the Z DataFrame to get the relevant rows and columns\r\n",
							"    countryZ_row_filter = Z.index.get_level_values('Country_Code').str.match(exporter)\r\n",
							"    countryZ_column_filter = Z.columns.get_level_values('Country_Code').str.match(importer)\r\n",
							"\r\n",
							"    countryZ = Z.loc[countryZ_row_filter, countryZ_column_filter]\r\n",
							"    importContributions = (countryZ.loc[(exporter, sector), [(importer, sector)]].values[0]) / sectorColSum\r\n",
							"\r\n",
							"    result = (countrySectorGrossOutputValue-sectorColSum) * importContributions\r\n",
							"    return result"
						],
						"outputs": [],
						"execution_count": 18
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"importCalculatorSingleSectorGrossExports('BEL', 'DEU', 'Transport')"
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def importCalculatorVector(importer, exporter, sectors):\r\n",
							"    result = []\r\n",
							"    for sector in sectors:\r\n",
							"        # Filter the countrySectorGrossOutput DataFrame to get the output value for the importer and sector\r\n",
							"        countrySectorGrossOutputValue = countrySectorGrossOutput.loc[(countrySectorGrossOutput['country_code'] == importer) & (countrySectorGrossOutput['sector'] == sector), 'Value'].squeeze()\r\n",
							"\r\n",
							"        # Calculate the total output for the sector\r\n",
							"        sectorColSum = Z.loc[:, (importer, sector)].sum()\r\n",
							"\r\n",
							"        # Filter the Z DataFrame to get the relevant rows and columns\r\n",
							"        countryZ_row_filter = Z.index.get_level_values('Country_Code').str.match(exporter)\r\n",
							"        countryZ_column_filter = Z.columns.get_level_values('Country_Code').str.match(importer)\r\n",
							"        countryZ = Z.loc[countryZ_row_filter, countryZ_column_filter]\r\n",
							"        importContributions = (countryZ.loc[(exporter, sector), [(importer, sector)]].values[0]) / sectorColSum\r\n",
							"\r\n",
							"        result.append((countrySectorGrossOutputValue-sectorColSum) * importContributions)\r\n",
							"    return result"
						],
						"outputs": [],
						"execution_count": 20
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"sectors = ['Agriculture', 'Fishing', 'Mining and Quarrying', 'Food & Beverages', 'Textiles and Wearing Apparel','Wood and Paper', 'Petroleum, Chemical and Non-Metallic Mineral Products', 'Metal Products','Electrical and Machinery', 'Transport Equipment', 'Other Manufacturing', 'Recycling','Electricity, Gas and Water', 'Construction', 'Maintenance and Repair',\t'Wholesale Trade', 'Retail Trade', 'Hotels and Restraurants', 'Transport', 'Post and Telecommunications','Finacial Intermediation and Business Activities', 'Public Administration', 'Education, Health and Other Services', 'Private Households', 'Others','Re-export & Re-import']\r\n",
							"importContributionVector = importCalculatorVector('BEL', 'DEU', sectors)\r\n",
							"#importContributionVector\r\n",
							"importContributionSum = np.squeeze(np.sum(importContributionVector))\r\n",
							"\r\n",
							"importContributionSum"
						],
						"outputs": [],
						"execution_count": 21
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Balance of Trade Calculations"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countrySectorExports = pd.DataFrame(EXGR_cs_c)\r\n",
							"countryCountryExports = pd.DataFrame(EXGR_c_c)\r\n",
							"\r\n",
							"countrySectorLabels = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA_Labels/Country+Sector_Labels.csv', format='csv', sep=\"\\t\").toPandas()\r\n",
							"countryLabels = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA_Labels/country-labels.csv', format='csv', sep=\"\\t\").toPandas()\r\n",
							"\r\n",
							"countrySectorExports.set_axis(countryLabels.values.squeeze(), axis = 1, inplace = True)\r\n",
							"\r\n",
							"countrySectorLabels = countrySectorLabels.iloc[1:]\r\n",
							"countrySectorLabels = countrySectorLabels.reset_index(drop = True)\r\n",
							"countrySectorExports = countrySectorExports.assign(_c0 = countrySectorLabels['_c0'])\r\n",
							"\r\n",
							"countrySectorExports = countrySectorExports.reindex(columns =[countrySectorExports.columns[-1]] + countrySectorExports.columns[:-1].tolist())\r\n",
							"\r\n",
							"countrySectorExports['_c0'] = countrySectorExports['_c0'].str.replace('Industries, ', '')\r\n",
							"countrySectorExports['_c0'] = countrySectorExports['_c0'].str.replace('Commodities, ', '')\r\n",
							"\r\n",
							"countryCountryExports.set_axis(countryLabels.values.squeeze(), axis = 1, inplace = True)\r\n",
							"countryCountryExports = countryCountryExports.assign(_c0 = countryLabels['_c0'])\r\n",
							"countryCountryExports = countryCountryExports.reindex(columns = [countryCountryExports.columns[-1]] + countryCountryExports.columns[:-1].tolist())\r\n",
							"countryCountryExports.set_index('_c0', inplace = True)"
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def countryCountryBalanceOfTrade(supplier, countryOfInterest):\r\n",
							"    exportValue = countryCountryExports.loc[countryOfInterest, supplier]\r\n",
							"    importValue = countryCountryExports.loc[supplier, countryOfInterest]\r\n",
							"\r\n",
							"    BoT = exportValue-importValue\r\n",
							"    return BoT"
						],
						"outputs": [],
						"execution_count": 23
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def grossBalanceOfTradeChecker(countryOfInterest):\r\n",
							"    BoT = 0\r\n",
							"    for supplier in countryCountryExports.columns:\r\n",
							"        exportValue = countryCountryExports.loc[countryOfInterest, supplier]\r\n",
							"        importValue = countryCountryExports.loc[supplier, countryOfInterest]\r\n",
							"        BoT += exportValue - importValue\r\n",
							"    return BoT"
						],
						"outputs": [],
						"execution_count": 24
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def balanceOfTradeForAll(countryOfInterest):\r\n",
							"    BoT_list = []\r\n",
							"    for supplier in countryCountryExports.columns:\r\n",
							"        exportValue = countryCountryExports.loc[countryOfInterest, supplier]\r\n",
							"        importValue = countryCountryExports.loc[supplier, countryOfInterest]\r\n",
							"        BoT = exportValue - importValue\r\n",
							"        BoT_list.append(BoT)\r\n",
							"    return BoT_list"
						],
						"outputs": [],
						"execution_count": 25
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"balanceOfTradeForAll('AFG')"
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countryCountryBalanceOfTradeList = np.zeros((len(countryCountryExports.columns), len(countryCountryExports.columns)))\r\n",
							"for i, country in enumerate(countryCountryExports.columns):\r\n",
							"    BoT_list = balanceOfTradeForAll(country)\r\n",
							"    countryCountryBalanceOfTradeList[i] = np.array(BoT_list)"
						],
						"outputs": [],
						"execution_count": 27
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countryCountryBalanceOfTradeFrame = pd.DataFrame(np.zeros((len(countryCountryExports.columns), len(countryCountryExports.columns))), index=countryCountryExports.columns, columns=countryCountryExports.columns)\r\n",
							"for i, country in enumerate(countryCountryExports.columns):\r\n",
							"    BoT_list = balanceOfTradeForAll(country)\r\n",
							"    countryCountryBalanceOfTradeFrame.iloc[i] = np.array(BoT_list)"
						],
						"outputs": [],
						"execution_count": 28
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"The basics of the EORA MRIO"
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"$$ \\begin{array}{c|cc} & \\text{Z}_{\\text{1}} & \\text{Z}_{\\text{2}} & \\text{Y} & \\text{X}_{\\text{Go}} \\\\ \\hline  \\text{Z}_{\\text{1}} & 150 & 200 & 1650 & 2000 \\\\ \\text{Z}_{\\text{2}} & 100 & 300 & 2500 & 3000 \\\\ \\text{VA} & 1750 & 2500 \\\\ \\text{X}_{\\text{Go}} & 2000 & 3000 \\end{array} $$"
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Where:\r\n",
							"- Z is the intermediate demand matrix\r\n",
							"- Y is the final demand matrix\r\n",
							"- VA is the value add matrix\r\n",
							"- $ X_{Go} $ is the gross output for that country/sector. $ X_{Go} $ can be calculated by doing the rowsum of the Z and Y matrices OR the columnsum of the Z and VA matrices."
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"$X_{Go}$ can be more formally written by the formula $X_{Go} = AX+Y$ where A is the direct and indirect contributors matrix. The A matrix can be cacluated (form the table above):\r\n",
							"\r\n",
							"$$ \\begin{bmatrix} \\frac{Z_{1,1}}{2000} & \\frac{Z_{1,2}}{3000} \\\\ \\frac{Z_{2,1}}{2000} & \\frac{Z_{2,2}}{3000} \\end{bmatrix} $$\r\n",
							"\r\n",
							"Value wise, this can be represented (using the values from above)\r\n",
							"\r\n",
							"$$ \\begin{bmatrix} \\frac{150}{2000} & \\frac{200}{3000} \\\\ \\frac{100}{2000} & \\frac{300}{3000} \\end{bmatrix} $$"
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"This matrix is useful if you want to calculate the FUTURE output for a given country/sector where (naturally) the gross output is unknown. Assuming one has the A matrix and the expected Final Demand (Y), the projected gross output can be calculated using the following:\r\n",
							"\r\n",
							"$$ \\begin{align} \\text{Start} &: X=AX+Y \\\\ \\text{Step 1} &: X-AX=Y \\\\ \\text{Step 2} &: X(I-A) = Y \\\\ \\text{Step 3} &: X(I-A)(I-A)^{-1} = Y(I-A)^{-1} \\\\ \\text{Step 4} &: X=(I-A)^{-1} Y \\end{align} $$\r\n",
							"\r\n",
							"$I$ here is an identity matrix of the same size as $A$."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countrySectorLabels = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA_Labels/Country+Sector_Labels.csv', format='csv', sep=\"\\t\").toPandas()\r\n",
							"countryLabels = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA_Labels/country-labels.csv', format='csv', sep=\"\\t\").toPandas()\r\n",
							"\r\n",
							"countrySectorLabels = countrySectorLabels.iloc[1:]\r\n",
							"countrySectorLabels = countrySectorLabels.reset_index(drop = True)\r\n",
							"countrySectorLabels['_c0'] = countrySectorLabels['_c0'].str.replace('Industries, ', '')\r\n",
							"countrySectorLabels['_c0'] = countrySectorLabels['_c0'].str.replace('Commodities, ', '')\r\n",
							"countrySectorLabels[['Country_Code', 'Sector']] = countrySectorLabels['_c0'].str.split(', ', n=1, expand=True)\r\n",
							"countrySectorLabels = countrySectorLabels.drop(['_c0'], axis = 1)\r\n",
							"\r\n",
							"countrySectorLabels"
						],
						"outputs": [],
						"execution_count": 40
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"FDFrame = pd.DataFrame(fd_matrix)\r\n",
							"FDFrame = FDFrame.iloc[:-1, :-6]\r\n",
							"FDFrame = FDFrame.set_index([countrySectorLabels['Country_Code'], countrySectorLabels['Sector']])"
						],
						"outputs": [],
						"execution_count": 41
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"FDFrame"
						],
						"outputs": [],
						"execution_count": 42
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"VAindex1 = countrySectorLabels['Country_Code']\r\n",
							"VAindex2 = countrySectorLabels['Sector']\r\n",
							"\r\n",
							"VAFrame = pd.DataFrame(va_matrix)\r\n",
							"VAFrame = VAFrame.iloc[:, :-1]\r\n",
							"VAFrame.columns = pd.MultiIndex.from_tuples(list(zip(VAindex1, VAindex2)))\r\n",
							"VAFrame.columns.names = ['Country_Code', 'Sector']"
						],
						"outputs": [],
						"execution_count": 44
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Need to double check my math on these as this currently doesnt add up"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def XgoCalcRowSum(country, sector):\r\n",
							"    ZRowSum = (Z.loc[(country, sector), :]).sum()\r\n",
							"    FDSum = (FDFrame.loc[(country, sector), :]).sum()\r\n",
							"    rowSum = ZRowSum+FDSum\r\n",
							"    return rowSum"
						],
						"outputs": [],
						"execution_count": 45
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"XgoCalcRowSum('DEU', 'Transport')"
						],
						"outputs": [],
						"execution_count": 49
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def XgoCalcColSum(country, sector):\r\n",
							"    ZColSum = (Z.loc[:, (country, sector)]).sum()\r\n",
							"    VASum = (VAFrame.loc[:, (country, sector)]).sum()\r\n",
							"    colSum = ZColSum + VASum\r\n",
							"\r\n",
							"    return colSum"
						],
						"outputs": [],
						"execution_count": 47
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"XgoCalcColSum('DEU', 'Transport')"
						],
						"outputs": [],
						"execution_count": 50
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"(GrossOutput, Oil, Receiver - Colsum (of the Z matrix) of the Receiver sector) * (Sender sector input to Receiver sector/ Colsum of Receiver Oil sector)"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Who is doing the importing\r\n",
							"receiver = 'BEL'\r\n",
							"#Who is doing the exporting \r\n",
							"sender = 'DEU'\r\n",
							"#The sector of interest\r\n",
							"sector = 'Agriculture'\r\n",
							"\r\n",
							"#The Gross Ouput, per sector, for each country\r\n",
							"countrySectorGrossOutput = pd.DataFrame(GO_cs)\r\n",
							"#Putting labels on it\r\n",
							"countrySectorGrossOutput = countrySectorGrossOutput.set_index([countrySectorLabels['Country_Code'], countrySectorLabels['Sector']])\r\n",
							"#Getting the gross output of the sector of interest for the importer\r\n",
							"receiverGrossOutputSector = countrySectorGrossOutput.loc[(receiver, sector), :].values[0]\r\n",
							"\r\n",
							"#This is multistep. We first slice down to the row of the exporter. We are then slicing to the columns where the sender is present in the index.\r\n",
							"#This gives a 1x26 vector that we then rowsum on to give us our value.\r\n",
							"senderInputToReceiver = Z.loc[(sender, sector), (receiver, slice(None))].sum()\r\n",
							"\r\n",
							"#This is the column sum of the all of the inputs into our importing country's sector of interest. Everyone from AFG to ZWE.\r\n",
							"receiverZColsum = Z.loc[:, (receiver, sector)].sum(axis = 0)"
						],
						"outputs": [],
						"execution_count": 269
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Lets assume that our exporting nation is Germany (DEU) and the importing nation is Belgium (BEL) and the sector of interest is agriculture. We want to find the value add to the Belgian exports from German imports. Belgium imports, $5 of German agriculture product, but turns that into $20 of finished products. We want to find the delta.\r\n",
							"\r\n",
							"Our result is the [Gross Output of the Belgian Agriculture Sector - the column Sum of ALL of the intermediate inputs (Z matrix, from AFG to ZWE)]*[(the summed value of German agriculture products into the 26 sectors of the Belgian economy / the column Sum of ALL of the intermediate inputs (Z matrix, from AFG to ZWE) into the Belgian agriculture sector)]"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"result = (receiverGrossOutputSector - receiverZColsum) * (senderInputToReceiver/receiverZColsum)\r\n",
							"result"
						],
						"outputs": [],
						"execution_count": 268
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"countrySectorLabels = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA_Labels/Country+Sector_Labels.csv', format='csv', sep=\"\\t\").toPandas()\r\n",
							"countrySectorLabels = countrySectorLabels.iloc[1:]\r\n",
							"countrySectorLabels = countrySectorLabels.reset_index(drop = True)\r\n",
							"\r\n",
							"countrySectorLabels['_c0'] = countrySectorLabels['_c0'].str.replace('Industries, ', '')\r\n",
							"countrySectorLabels['_c0'] = countrySectorLabels['_c0'].str.replace('Commodities, ', '')\r\n",
							"countrySectorLabels[['Country_Code', 'Sector']] = countrySectorLabels['_c0'].str.split(', ', n=1, expand=True)\r\n",
							"countrySectorLabels = countrySectorLabels.drop(['_c0'], axis = 1)"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"country_codes_list = countrySectorLabels['Country_Code'].unique()\r\n",
							"sectors_list = countrySectorLabels['Sector'].unique()"
						],
						"outputs": [],
						"execution_count": 17
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"num_cntry = 189\r\n",
							"num_sectors = 26\r\n",
							"num_fd_components = 6\r\n",
							"year_start = 1990\r\n",
							"year_end = 2022\r\n",
							"\r\n",
							"years = np.linspace(year_start, year_end, num = year_end - year_start + 1).astype(int).astype(str)\r\n",
							"\r\n",
							"def calculate_GO_cs_and_Z(years):\r\n",
							"    gross_output_list = []\r\n",
							"    Z_list = []\r\n",
							"    for year in years:\r\n",
							"        # Read in the data\r\n",
							"        fd_matrix_path = f'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_'+year+'_bp/Eora26_'+year+'_bp_FD.txt'\r\n",
							"        id_matrix_path = f'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_'+year+'_bp/Eora26_'+year+'_bp_T.txt'\r\n",
							"        va_matrix_path = f'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_'+year+'_bp/Eora26_'+year+'_bp_VA.txt'\r\n",
							"\r\n",
							"        fd_matrix = spark.read.load(fd_matrix_path, format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"        id_matrix = spark.read.load(id_matrix_path, format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"        va_matrix = spark.read.load(va_matrix_path, format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"\r\n",
							"        # Compute Stats\r\n",
							"        va_total_cs = va_matrix.sum(axis = 0)\r\n",
							"        FD = fd_matrix.reshape((num_cntry*num_sectors + 1), num_fd_components, -1)\r\n",
							"        FD = FD.sum(axis=1)\r\n",
							"        FD = np.squeeze(FD) # Squeeze to remove single-dimensional entries\r\n",
							"\r\n",
							"        GRTR_INT_cs_cs = id_matrix[0:(num_cntry*num_sectors), 0:(num_cntry*num_sectors)]\r\n",
							"        GRTR_FNL_cs_c = FD[0:num_cntry*num_sectors,0:num_cntry]\r\n",
							"        VALUE_cs = va_total_cs[0:(num_cntry*num_sectors)]\r\n",
							"\r\n",
							"        # Initialize empty list to hold blocks\r\n",
							"        imtx_cs_c = []\r\n",
							"        imtx_cs_cs = []\r\n",
							"        imtx_c_cs=[]\r\n",
							"        imtx_cs_ck = []\r\n",
							"\r\n",
							"        # Create block matrix\r\n",
							"        iblk_cs_c = np.ones((num_sectors, 1))  # Create num_sectors x 1 vector of ones\r\n",
							"        iblk_cs_cs = np.ones((num_sectors,num_sectors))\r\n",
							"        ivector = np.ones((1, num_sectors))\r\n",
							"        iblk_cs_ck = np.ones((num_sectors, num_fd_components))\r\n",
							"\r\n",
							"        # Construct block diagonal matrix\r\n",
							"        for j in range(num_cntry):\r\n",
							"            if j == 0:\r\n",
							"                imtx_cs_c = iblk_cs_c  # Initialize with the first block\r\n",
							"                imtx_cs_cs = iblk_cs_cs\r\n",
							"                imtx_c_cs = ivector\r\n",
							"                imtx_cs_ck = iblk_cs_ck\r\n",
							"\r\n",
							"            else:\r\n",
							"                imtx_cs_c = block_diag(imtx_cs_c, iblk_cs_c) \r\n",
							"                imtx_cs_cs = block_diag(imtx_cs_cs, iblk_cs_cs) \r\n",
							"                imtx_c_cs = block_diag(imtx_c_cs, ivector)\r\n",
							"                imtx_cs_ck = block_diag(imtx_cs_ck, iblk_cs_ck)\r\n",
							"\r\n",
							"        imtx_c_c = np.eye(num_cntry)\r\n",
							"\r\n",
							"        #Gross Output\r\n",
							"        GO_cs_c = GRTR_INT_cs_cs.reshape(num_cntry*num_sectors, num_sectors, -1)\r\n",
							"        GO_cs_c = GO_cs_c.sum(axis = 1)\r\n",
							"        GO_cs_c = np.squeeze(GO_cs_c)\r\n",
							"        GO_cs_c = GO_cs_c + GRTR_FNL_cs_c\r\n",
							"        GO_cs = GO_cs_c.sum(axis = 1)\r\n",
							"        GO_c_c = np.matmul(imtx_c_cs,GO_cs_c)\r\n",
							"        elementwise_GO_product =  np.tile(GO_cs[:, np.newaxis],(1,num_cntry)) * imtx_cs_c\r\n",
							"        summed_GO_result = elementwise_GO_product.sum(axis=0)\r\n",
							"        GO_c = summed_GO_result.T\r\n",
							"\r\n",
							"        gross_output_list.append((year, GO_cs))\r\n",
							"        Z_list.append((year, id_matrix))\r\n",
							"\r\n",
							"    return gross_output_list, Z_list"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"gross_output_list, Z_matrices = calculate_GO_cs_and_Z(years)"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def valueAddCalculatorOneToROW_2(importer, exporter_list, sector_list, year_list, GO_cs_list, Z_list):\r\n",
							"    results_dfs = []\r\n",
							"    for year in year_list:\r\n",
							"        #print(\"Calculating for year:\", year)\r\n",
							"        GO_cs = pd.DataFrame(GO_cs_list[year-year_start][1])\r\n",
							"        GO_cs = GO_cs.assign(**{'Country_Code': countrySectorLabels['Country_Code'], 'Sector': countrySectorLabels['Sector']}).rename(columns={0: 'Value'})\r\n",
							"        GO_cs = GO_cs.set_index([countrySectorLabels['Country_Code'], countrySectorLabels['Sector']])\r\n",
							"\r\n",
							"        Z = pd.DataFrame(Z_list[year-year_start][1])\r\n",
							"        Z = Z.iloc[:-1, :-1]\r\n",
							"        Z = Z.set_index([Zindex1, Zindex2])\r\n",
							"        Z.columns = pd.MultiIndex.from_tuples(list(zip(Zindex1, Zindex2)))\r\n",
							"        Z.columns.names = ['Country_Code', 'Sector']\r\n",
							"\r\n",
							"        for exporter in exporter_list:\r\n",
							"            for sector in sector_list:\r\n",
							"                # Calculate the gross output of the sector of interest for the importer\r\n",
							"                receiverGrossOutputSector = GO_cs.loc[(importer, sector), :].values[0]\r\n",
							"\r\n",
							"                # Calculate the input from the exporter to the importer in the given sector\r\n",
							"                senderInputToReceiver = Z.loc[(exporter, sector), (importer, slice(None))].sum()\r\n",
							"\r\n",
							"                # Calculate the total input to the importer's sector from all exporters\r\n",
							"                receiverZColsum = Z.loc[:, (importer, sector)].sum(axis = 0)\r\n",
							"\r\n",
							"                # Calculate the value added by the exporter in the given sector for the importer\r\n",
							"                result = (receiverGrossOutputSector - receiverZColsum) * (senderInputToReceiver/receiverZColsum)\r\n",
							"\r\n",
							"                # Append the results to the dataframe\r\n",
							"                result_df = pd.DataFrame({\r\n",
							"                    'Importer': [importer],\r\n",
							"                    'Exporter': [exporter],\r\n",
							"                    'Sector': [sector],\r\n",
							"                    'Year': [year],\r\n",
							"                    'Value Added': [result],\r\n",
							"                    'Sender Input to Receiver': [senderInputToReceiver],\r\n",
							"                })\r\n",
							"                results_dfs.append(result_df)\r\n",
							"\r\n",
							"    # Concatenate the list of result dataframes into a single dataframe\r\n",
							"    results_df = pd.concat(results_dfs, ignore_index=True)\r\n",
							"    \r\n",
							"    results_df_csv_buffer = io.StringIO()\r\n",
							"    results_df.to_csv(results_df_csv_buffer, index=False)\r\n",
							"    results_df_csv_string = results_df_csv_buffer.getvalue()\r\n",
							"    out_path = f\"abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA26/{importer}_ValueAdd_1990_2022.csv\"\r\n",
							"    mssparkutils.fs.put(out_path, results_df_csv_string, overwrite=True)\r\n",
							"\r\n",
							"    return results_df"
						],
						"outputs": [],
						"execution_count": 23
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"valueAddCalculatorOneToROW_2('NAM', exporter_list = country_codes_list, sector_list = sectors_list, year_list = range(1990, 2023), GO_cs_list = gross_output_list, Z_list = Z_matrices)"
						],
						"outputs": [],
						"execution_count": 48
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def valueAddCalculatorMultiToROW(importer_list, exporter_list, sector_list, year_list, GO_cs_list, Z_list):\r\n",
							"    results_dfs_list = []\r\n",
							"    for importer in importer_list:\r\n",
							"        results_dfs = []\r\n",
							"        for year in year_list:\r\n",
							"            #print(\"Calculating for year:\", year)\r\n",
							"            GO_cs = pd.DataFrame(GO_cs_list[year-year_start][1])\r\n",
							"            GO_cs = GO_cs.assign(**{'Country_Code': countrySectorLabels['Country_Code'], 'Sector': countrySectorLabels['Sector']}).rename(columns={0: 'Value'})\r\n",
							"            GO_cs = GO_cs.set_index([countrySectorLabels['Country_Code'], countrySectorLabels['Sector']])\r\n",
							"\r\n",
							"            Z = pd.DataFrame(Z_list[year-year_start][1])\r\n",
							"            Z = Z.iloc[:-1, :-1]\r\n",
							"            Z = Z.set_index([Zindex1, Zindex2])\r\n",
							"            Z.columns = pd.MultiIndex.from_tuples(list(zip(Zindex1, Zindex2)))\r\n",
							"            Z.columns.names = ['Country_Code', 'Sector']\r\n",
							"\r\n",
							"            for exporter in exporter_list:\r\n",
							"                for sector in sector_list:\r\n",
							"                    # Calculate the gross output of the sector of interest for the importer\r\n",
							"                    receiverGrossOutputSector = GO_cs.loc[(importer, sector), :].values[0]\r\n",
							"\r\n",
							"                    # Calculate the input from the exporter to the importer in the given sector\r\n",
							"                    senderInputToReceiver = Z.loc[(exporter, sector), (importer, slice(None))].sum()\r\n",
							"\r\n",
							"                    # Calculate the total input to the importer's sector from all exporters\r\n",
							"                    receiverZColsum = Z.loc[:, (importer, sector)].sum(axis = 0)\r\n",
							"\r\n",
							"                    # Calculate the value added by the exporter in the given sector for the importer\r\n",
							"                    result = (receiverGrossOutputSector - receiverZColsum) * (senderInputToReceiver/receiverZColsum)\r\n",
							"\r\n",
							"                    # Append the results to the dataframe\r\n",
							"                    result_df = pd.DataFrame({\r\n",
							"                        'Importer': [importer],\r\n",
							"                        'Exporter': [exporter],\r\n",
							"                        'Sector': [sector],\r\n",
							"                        'Year': [year],\r\n",
							"                        'Value Added': [result],\r\n",
							"                        'Sender Input to Receiver': [senderInputToReceiver],\r\n",
							"                    })\r\n",
							"                    results_dfs.append(result_df)\r\n",
							"\r\n",
							"        # Concatenate the list of result dataframes into a single dataframe\r\n",
							"        results_df = pd.concat(results_dfs, ignore_index=True)\r\n",
							"        \r\n",
							"        results_df_csv_buffer = io.StringIO()\r\n",
							"        results_df.to_csv(results_df_csv_buffer, index=False)\r\n",
							"        results_df_csv_string = results_df_csv_buffer.getvalue()\r\n",
							"        out_path = f\"abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/EORA26/{importer}_ValueAdd_1990_2022.csv\"\r\n",
							"        mssparkutils.fs.put(out_path, results_df_csv_string, overwrite=True)\r\n",
							"\r\n",
							"        results_dfs_list.append(results_df)\r\n",
							"\r\n",
							"    return results_dfs_list"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"nations = ['USA', 'CHN', 'RUS']\r\n",
							"valueAddCalculatorMultiToROW(importer_list = nations, exporter_list = country_codes_list, sector_list = sectors_list, year_list = range(1990, 2023), GO_cs_list = gross_output_list, Z_list = Z_matrices)"
						],
						"outputs": [],
						"execution_count": 24
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/EORA_TiVA')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ac2sparkpooldev",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "4aa3b760-25c6-415d-9bbb-764756c9c4f7"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Synapse/workspaces/ac2-synapse-ws-dev/bigDataPools/ac2sparkpooldev",
						"name": "ac2sparkpooldev",
						"type": "Spark",
						"endpoint": "https://ac2-synapse-ws-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ac2sparkpooldev",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"import numpy as np\n",
							"from scipy.linalg import block_diag\n",
							"import warnings\n",
							"import pandas as pd\n",
							"import io"
						],
						"outputs": [],
						"execution_count": 265
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Parameters"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"num_cntry = 189\r\n",
							"num_sectors = 26\r\n",
							"num_fd_components = 6"
						],
						"outputs": [],
						"execution_count": 208
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Define the Intermediate Use and Final Demand Sections of Matrix\r\n",
							"Create global bilateral gross trade matrices by exporting industry/country (y_dim, rows) and importing industry/country (x_dim, cols) for intermediate (INT) or final (FNL) goods. \r\n",
							""
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Read in the data\r\n",
							"Final Demand Matrix  {name: fd_matrix, shape: ((num_cntry * num_sectors) + 1), ((num_cntry * num_sectors) + num_fd_components)}\r\n",
							"\r\n",
							"Intermediate Use Matrix  {name: id_matrix, shape: ((num_cntry * num_sectors) + 1), ((num_cntry * num_sectors) + 1)}\r\n",
							"\r\n",
							"Value Added Matrix {name: va_matrix, shape: num_fd_components, ((num_cntry * num_sectors) + 1)}"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"fd_matrix = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_1990_bp/Eora26_1990_bp_FD.txt', format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"id_matrix = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_1990_bp/Eora26_1990_bp_T.txt', format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)\r\n",
							"va_matrix = spark.read.load('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_1990_bp/Eora26_1990_bp_VA.txt', format='csv', sep=\"\\t\").toPandas().to_numpy(dtype=float)"
						],
						"outputs": [],
						"execution_count": 209
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"va_total_cs = va_matrix.sum(axis = 0)"
						],
						"outputs": [],
						"execution_count": 210
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Sum over all 6 components of the final demand matrix for each country final shape should be [(num_cntry*num_sectors) x num_cntry]"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"FD = fd_matrix.reshape((num_cntry*num_sectors + 1), num_fd_components, _1)\r\n",
							"FD = FD.sum(axis=1)\r\n",
							"FD = np.squeeze(FD) # Squeeze to remove single_dimensional entries"
						],
						"outputs": [],
						"execution_count": 211
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Drop the final statistical discrepancy row/column from matrix (aka Rest of World)"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"GRTR_INT_cs_cs = id_matrix[0:(num_cntry*num_sectors), 0:(num_cntry*num_sectors)]\n",
							"GRTR_FNL_cs_c = FD[0:num_cntry*num_sectors,0:num_cntry]\n",
							"VALUE_cs = va_total_cs[0:(num_cntry*num_sectors)]"
						],
						"outputs": [],
						"execution_count": 212
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Identity matrices for summing across sectors (when calculating totals by country)\n",
							"\n",
							"imtx_cs_c _ a block diagonal matrix with blocks of ones (num_sectors, 1) on the diagonal\n",
							"\n",
							"imtx_cs_cs _ a block diagonal matrix with blocks of ones (num_sectors, num_sectors) on the diagonal\n",
							"\n",
							"imtx_c_cs _ a block diagonal matrix with blocks of ones (1, num_sectors) on the diagonal\n",
							"\n",
							"imtx_cs_ck _ a block diagonal matrix with blocks of ones (num_sectors, num_fd_components) on the diagonal\n",
							"\n",
							"imtx_c_c _ identity matrix with shape of (num_cntry, num_cntry)\n",
							""
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Initialize empty list to hold blocks\n",
							"imtx_cs_c = []\n",
							"imtx_cs_cs = []\n",
							"imtx_c_cs=[]\n",
							"imtx_cs_ck = []\n",
							"\n",
							"# Create block matrix\n",
							"iblk_cs_c = np.ones((num_sectors, 1))  # Create num_sectors x 1 vector of ones\n",
							"iblk_cs_cs = np.ones((num_sectors,num_sectors))\n",
							"ivector = np.ones((1, num_sectors))\n",
							"iblk_cs_ck = np.ones((num_sectors, num_fd_components))\n",
							"\n",
							"# Construct block diagonal matrix\n",
							"for i in range(num_cntry):\n",
							"    if i == 0:\n",
							"        imtx_cs_c = iblk_cs_c  # Initialize with the first block\n",
							"        imtx_cs_cs = iblk_cs_cs\n",
							"        imtx_c_cs = ivector\n",
							"        imtx_cs_ck = iblk_cs_ck\n",
							"\n",
							"    else:\n",
							"        imtx_cs_c = block_diag(imtx_cs_c, iblk_cs_c) \n",
							"        imtx_cs_cs = block_diag(imtx_cs_cs, iblk_cs_cs) \n",
							"        imtx_c_cs = block_diag(imtx_c_cs, ivector)\n",
							"        imtx_cs_ck = block_diag(imtx_cs_ck, iblk_cs_ck)\n",
							"\n",
							"\n",
							"imtx_c_c = np.eye(num_cntry)\n",
							"\n",
							""
						],
						"outputs": [],
						"execution_count": 213
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Calculating Gross Output (GO)\r\n",
							"\r\n",
							"Sum across all num_sectors sectors by country for intermediate demand and then add total final demand. This step assumes the statistical discrepancy rows and columns were removed."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"GO_cs_c = GRTR_INT_cs_cs.reshape(num_cntry*num_sectors, num_sectors, _1)\r\n",
							"GO_cs_c = GO_cs_c.sum(axis = 1)\r\n",
							"GO_cs_c = np.squeeze(GO_cs_c)\r\n",
							"GO_cs_c = GO_cs_c + GRTR_FNL_cs_c\r\n",
							"GO_cs = GO_cs_c.sum(axis = 1)"
						],
						"outputs": [],
						"execution_count": 214
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Aggregate grouss output matrix across sectors [num_cntry x num_cntry]"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"GO_c_c = np.matmul(imtx_c_cs,GO_cs_c)"
						],
						"outputs": [],
						"execution_count": 215
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Total gross output for each country_sector [num_cntry * num_sectors x 1], summed across columns"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"# Step 1: Replicate GO_cs\r\n",
							"replicated_GO_cs = np.tile(GO_cs[:, np.newaxis],(1,num_cntry))\r\n",
							"\r\n",
							"# Step 2: Element_wise multiply\r\n",
							"elementwise_GO_product =  replicated_GO_cs * imtx_cs_c\r\n",
							"\r\n",
							"# Step 3: Sum along the specified axis (axis=0)\r\n",
							"summed_GO_result = elementwise_GO_product.sum(axis=0)\r\n",
							"\r\n",
							"# Step 4: Transpose the result\r\n",
							"GO_c = summed_GO_result.T"
						],
						"outputs": [],
						"execution_count": 216
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### VALUE_ADDED"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Pretty much same procedure as the previous step except now the focus is on the VALUE_cs matrix\r\n",
							"\r\n",
							"replicated_VALUE_cs = np.tile(VALUE_cs[:, np.newaxis], (1, num_cntry))\r\n",
							"elementwise_VALUE_product = replicated_VALUE_cs * imtx_cs_c\r\n",
							"summed_VALUE_result = elementwise_VALUE_product.sum(axis=0)\r\n",
							"VALUE_c = summed_VALUE_result.T\r\n",
							"\r\n",
							"#Derived value added\r\n",
							"Inputs_cs = GRTR_INT_cs_cs.sum(axis = 0)\r\n",
							"replicated_Inputs_cs = np.tile(Inputs_cs[:, np.newaxis], (1, num_cntry)) \r\n",
							"elementwise_INPUTS_product = replicated_Inputs_cs * imtx_cs_c\r\n",
							"summed_INPUTS_result = elementwise_INPUTS_product.sum(axis = 0)\r\n",
							"Inputs_c = summed_INPUTS_result.T\r\n",
							"\r\n",
							"#VA = Gross Outputs _ Inputs\r\n",
							"VALUE_derived_cs = GO_cs _ Inputs_cs\r\n",
							"replicated_VALUE_derived_cs = np.tile(VALUE_derived_cs[:, np.newaxis], (1, num_cntry))\r\n",
							"elementwise_VALUE_derived_product = replicated_VALUE_derived_cs * imtx_cs_c\r\n",
							"summed_VALUE_derived_result = elementwise_VALUE_derived_product.sum(axis = 0)\r\n",
							"VALUE_derived_c = summed_VALUE_derived_result.T"
						],
						"outputs": [],
						"execution_count": 217
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Gross Exports\r\n",
							"\r\n",
							"Gross exports of intermediate goods and services from domestic sector $s$ in country $c$"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"ones_cs_cs_array = np.ones((num_cntry*num_sectors))\r\n",
							"EXGR_INT_cs_cs = GRTR_INT_cs_cs * (ones_cs_cs_array _ imtx_cs_cs)\r\n",
							"\r\n",
							"EXGR_INT_cs_c = np.full((num_cntry * num_sectors, num_cntry), np.nan)\r\n",
							"for k in range(num_cntry):\r\n",
							"    EXGR_INT_cs_c[:, k] = np.sum(EXGR_INT_cs_cs[:, (k * num_sectors):(num_sectors * (k + 1))], axis=1)\r\n",
							"\r\n",
							"EXGR_INT_cs = EXGR_INT_cs_cs.sum(axis = 1)\r\n",
							"\r\n",
							"replicated_EXGR_INT_cs = np.tile(EXGR_INT_cs[:, np.newaxis], (1, num_cntry))\r\n",
							"elementwise_EXGR_INT_cs_product = replicated_EXGR_INT_cs * imtx_cs_c\r\n",
							"summed_EXGR_INT_cs_result = elementwise_EXGR_INT_cs_product.sum(axis = 0)\r\n",
							"EXGR_INT_c = summed_EXGR_INT_cs_result.T"
						],
						"outputs": [],
						"execution_count": 218
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Gross exports of final demand goods and services from domestic sector $s$ in country $c$."
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"ones_cs_c_array = np.ones((num_cntry*num_sectors, num_cntry))\r\n",
							"EXGR_FNL_cs_c = GRTR_FNL_cs_c * (ones_cs_c_array _ imtx_cs_c)\r\n",
							"\r\n",
							"EXGR_FNL_cs = EXGR_FNL_cs_c * (ones_cs_c_array _ imtx_cs_c)\r\n",
							"EXGR_FNL_cs = EXGR_FNL_cs.sum(axis = 1)\r\n",
							"\r\n",
							"EXGR_FNL_c = np.tile(EXGR_FNL_cs[:, np.newaxis],(1, num_cntry)) * imtx_cs_c\r\n",
							"EXGR_FNL_c = EXGR_FNL_c.sum(axis = 0).T"
						],
						"outputs": [],
						"execution_count": 219
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Total gross exports (country_sector $\\times$ country)"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"EXGR_cs_c = EXGR_INT_cs_c + EXGR_FNL_cs_c\r\n",
							"EXGR_c_c = np.matmul(imtx_c_cs, EXGR_cs_c)"
						],
						"outputs": [],
						"execution_count": 220
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Total gross exports (country_sector $\\times$ 1) and Total gross exports (country $\\times$ 1)"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"EXGR_cs = EXGR_INT_cs + EXGR_FNL_cs\r\n",
							"EXGR_c = EXGR_INT_c + EXGR_FNL_c"
						],
						"outputs": [],
						"execution_count": 221
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Gross Imports: (Imported Intermediates)\r\n",
							"\r\n",
							"Gross Imports of Intermediates (by country_sector, and by country)"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"ones_cs_array = np.ones((num_cntry * num_sectors))\r\n",
							"IMGR_INT_cs = GRTR_INT_cs_cs * (ones_cs_array _ imtx_cs_cs)\r\n",
							"IMGR_INT_cs = IMGR_INT_cs.sum(axis = 0)\r\n",
							"\r\n",
							"IMGR_INT_c = np.tile(IMGR_INT_cs[:, np.newaxis],(1, num_cntry)) * imtx_cs_c\r\n",
							"IMGR_INT_c = IMGR_INT_c.sum(axis = 0).T"
						],
						"outputs": [],
						"execution_count": 222
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Gross Imports of Final Demand goods and services (by country)"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"ones_cs_c_array = np.ones((num_cntry * num_sectors, num_cntry))\r\n",
							"IMGR_FNL_c = GRTR_FNL_cs_c * (ones_cs_c_array _ imtx_cs_c)\r\n",
							"IMGR_FNL_c = IMGR_FNL_c.sum(axis = 0).T"
						],
						"outputs": [],
						"execution_count": 223
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Total gross imports (by country)"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"IMGR_c = IMGR_INT_c + IMGR_FNL_c"
						],
						"outputs": [],
						"execution_count": 224
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Gross trade balance"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"BALGR_c = EXGR_c _ IMGR_c"
						],
						"outputs": [],
						"execution_count": 225
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Demand for Domestic Inputs (Use of Domestic Intermediates)\r\n",
							"\r\n",
							"Gross Domestic Intermediate demand for domestic inputs by country_sector"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"DDGR_INT_cs = GRTR_INT_cs_cs * imtx_cs_cs\r\n",
							"DDGR_INT_cs = DDGR_INT_cs.sum(axis = 0).T\r\n",
							"\r\n",
							"DDGR_INT_c = np.tile(DDGR_INT_cs[:, np.newaxis],(1, num_cntry)) * imtx_cs_c\r\n",
							"DDGR_INT_c = DDGR_INT_c.sum(axis = 0).T"
						],
						"outputs": [],
						"execution_count": 226
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Gross Domestic Final demand of domestic inputs by country_sector"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"DDGR_FNL_c = GRTR_FNL_cs_c * imtx_cs_c\r\n",
							"DDGR_FNL_c = DDGR_FNL_c.sum(axis = 0).T"
						],
						"outputs": [],
						"execution_count": 227
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Domestic and Foreign Final Demand"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"GRTR_FNL_DOM_cs_c = GRTR_FNL_cs_c * imtx_cs_c\r\n",
							"GRTR_FNL_DOM_cs = GRTR_FNL_DOM_cs_c.sum(axis = 1)\r\n",
							"\r\n",
							"#By sector\r\n",
							"GRTR_FNL_DOM_cs_ck = fd_matrix[0:num_cntry*num_sectors, 0:num_cntry*num_fd_components] * imtx_cs_ck\r\n",
							"\r\n",
							"##Sum across the third dimension, across countries for each of the 6 components of final demand\r\n",
							"GRTR_FNL_DOM_cs_nfd = GRTR_FNL_DOM_cs_ck.reshape((num_cntry*num_sectors), num_fd_components, _1)\r\n",
							"GRTR_FNL_DOM_cs_nfd = GRTR_FNL_DOM_cs_nfd.sum(axis = 2)\r\n",
							"\r\n",
							"#Foreign Demand\r\n",
							"GRTR_FNL_FOR_cs_c = GRTR_FNL_cs_c * (ones_cs_c_array _ imtx_cs_c)\r\n",
							"GRTR_FNL_FOR_cs = GRTR_FNL_FOR_cs_c.sum(axis = 1)\r\n",
							"\r\n",
							"##By sector\r\n",
							"ones_cs_ck_array = np.ones((num_cntry*num_sectors, num_cntry*num_fd_components))\r\n",
							"GRTR_FNL_FOR_cs_ck = fd_matrix[0:num_cntry*num_sectors, 0:num_cntry*num_fd_components] * (ones_cs_ck_array _ imtx_cs_ck)\r\n",
							"\r\n",
							"##Sum across the third dimension, across countries for each of the 6 components of final demand\r\n",
							"GRTR_FNL_FOR_cs_nfd = GRTR_FNL_FOR_cs_ck.reshape((num_cntry*num_sectors), num_fd_components, _1)\r\n",
							"GRTR_FNL_FOR_cs_nfd = GRTR_FNL_FOR_cs_nfd.sum(axis = 2)"
						],
						"outputs": [],
						"execution_count": 228
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Compute the VA vector indirectly (just to check that no problems exist with inverses)\r\n",
							"A matrix, input_output coefficients (share of gross output)"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"with warnings.catch_warnings():\r\n",
							"    warnings.simplefilter('ignore')\r\n",
							"    Amat = GRTR_INT_cs_cs / np.tile(GO_cs[:, np.newaxis], (1, num_cntry * num_sectors))\r\n",
							"Amat[np.isnan(Amat)] = 0\r\n",
							"Amat[np.isinf(Amat)] = 0\r\n",
							"\r\n",
							"#VA shares\r\n",
							"va_vec_cs = 1 _ np.sum(Amat)\r\n",
							"V_hat = np.eye((num_cntry * num_sectors)) _ np.diag(Amat.sum(axis = 0))\r\n",
							"\r\n",
							"#Leontief inverse\r\n",
							"IminusA = np.eye((num_cntry * num_sectors)) _ Amat\r\n",
							"Bmat = np.linalg.inv(IminusA) #Leontief Inverse\r\n",
							"\r\n",
							"#Total Value Added by country_sector\r\n",
							"BY = np.matmul(Bmat, GRTR_FNL_cs_c.sum(axis = 1))\r\n",
							"va_cs = va_vec_cs * BY"
						],
						"outputs": [],
						"execution_count": 229
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### DVA and FVA of gross exports (From $V*B*E$)"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"TiVA = V_hat @ Bmat @ np.diag(EXGR_cs)"
						],
						"outputs": [],
						"execution_count": 230
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"EXGR_DVA_cs = np.sum(TiVA * imtx_cs_cs, axis = 0).T\r\n",
							"EXGR_FVA_cs = np.sum(TiVA * (ones_cs_array _ imtx_cs_cs), axis = 0).T\r\n",
							"\r\n",
							"EXGR_DVA_c = np.tile(EXGR_DVA_cs[:, np.newaxis],(1, num_cntry)) * imtx_cs_c\r\n",
							"EXGR_DVA_c = EXGR_DVA_c.sum(axis = 0).T\r\n",
							"\r\n",
							"EXGR_FVA_c = np.tile(EXGR_FVA_cs[:, np.newaxis],(1, num_cntry)) * imtx_cs_c\r\n",
							"EXGR_FVA_c = EXGR_FVA_c.sum(axis = 0).T"
						],
						"outputs": [],
						"execution_count": 231
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"VS1_cs = np.sum(TiVA * (ones_cs_array _ imtx_cs_cs), axis = 1)\r\n",
							"VS1_c = np.tile(VS1_cs[:, np.newaxis], (1, num_cntry)) * imtx_cs_c\r\n",
							"VS1_c = VS1_c.sum(axis = 0).T"
						],
						"outputs": [],
						"execution_count": 232
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Compute VA matrices (from $V*B*Y$)\r\n",
							"\r\n",
							"Off_diagonal elements give you the VAX components"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"VA_cs_c = V_hat @ Bmat @ GRTR_FNL_cs_c"
						],
						"outputs": [],
						"execution_count": 233
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Total VAX (= VAX1 + VAX2 + VAX3); VAX_c is same as FFD_DVA"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"ones_c_c_array = np.ones((num_cntry, num_cntry))\r\n",
							"VAX_cs_c = VA_cs_c * (ones_cs_c_array _ imtx_cs_c)\r\n",
							"VA_c_c = np.matmul(imtx_c_cs, VA_cs_c)\r\n",
							"\r\n",
							"#Value added of exports only (exclude value_added of demestic goods)\r\n",
							"VAX_c_c = VA_c_c * (ones_c_c_array _ np.eye(num_cntry))\r\n",
							"\r\n",
							"VAX_c = VAX_c_c.sum(axis = 1)"
						],
						"outputs": [],
						"execution_count": 234
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Koopman et al. Equation 36 Terms\r\n",
							"\r\n",
							"This equation allows us to obtain the $G$ country, $N$ sector generalized version of gross exports accounting. See [this paper](https://www.nber.org/system/files/working_papers/w18579/w18579.pdf) for more details."
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#### Term 1"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"VAX1_cs_c = V_hat @ (Bmat * imtx_cs_cs) @ (GRTR_FNL_cs_c * (ones_cs_c_array _ imtx_cs_c))\r\n",
							"VAX1_c_c = np.matmul(imtx_c_cs, VAX1_cs_c) # aggregate across rows by country\r\n",
							"VAX1_c = VAX1_c_c.sum(axis = 1)"
						],
						"outputs": [],
						"execution_count": 239
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#### Term 2"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"VAX2_cs_c = V_hat @ (Bmat * (ones_cs_array _ imtx_cs_cs)) @ (GRTR_FNL_cs_c  _ imtx_cs_c)\r\n",
							"VAX2_c_c = np.matmul(imtx_c_cs, VAX2_cs_c) # aggregate across rows by country\r\n",
							"VAX2_c = VAX2_c_c.sum(axis = 1)"
						],
						"outputs": [],
						"execution_count": 240
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#### Term 3"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"VAX3_cs_c_sum1 = V_hat @ (Bmat * (ones_cs_array _ imtx_cs_cs)) @ (GRTR_FNL_cs_c * (ones_cs_c_array _ imtx_cs_c))\r\n",
							"VAX3_cs_c_sum2 = VAX3_cs_c_sum1 * (ones_cs_c_array _ imtx_cs_c)\r\n",
							"VAX3_c_c = np.matmul(imtx_c_cs, VAX3_cs_c_sum2) # aggregate across rows by country\r\n",
							"VAX3_c = VAX3_c_c.sum(axis = 1)"
						],
						"outputs": [],
						"execution_count": 241
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#### Term 4"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"DVA4_cs_c = V_hat @ (Bmat * (ones_cs_array _ imtx_cs_cs)) @ (GRTR_FNL_cs_c * (ones_cs_c_array _ imtx_cs_c))\r\n",
							"DVA4_c_c = np.matmul(imtx_c_cs,DVA4_cs_c) * imtx_c_c # aggregate across rows by country, and take just the diagonal elements\r\n",
							"DVA4_c = DVA4_c_c.sum(axis = 1)"
						],
						"outputs": [],
						"execution_count": 242
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#### Term 5"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"eye_inverse = np.linalg.inv(np.eye((num_cntry * num_sectors)))\r\n",
							"DVA5_cs_c = V_hat @ (Bmat * (ones_cs_array _ imtx_cs_cs)) @ (Amat * (ones_cs_array _ imtx_cs_cs)) @\\\r\n",
							"              ((eye_inverse _ Amat) * imtx_cs_cs) @ (GRTR_FNL_cs_c * imtx_cs_c)\r\n",
							"DVA5_c_c = np.matmul(imtx_c_cs,DVA5_cs_c) * imtx_c_c # aggregate across rows by country, and take just the diagonal elements\r\n",
							"DVA5_c = DVA5_c_c.sum(axis = 1)"
						],
						"outputs": [],
						"execution_count": 244
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#### Term 6"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"DVA6_c = EXGR_DVA_c _ VAX_c _ DVA4_c _ DVA5_c"
						],
						"outputs": [],
						"execution_count": 246
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#### Foreign Value Added in Domestic Final Demand"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"DFD_FVA_c = VAX_c_c.sum(axis = 0)"
						],
						"outputs": [],
						"execution_count": 248
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Export Country Data"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"country_data = {\r\n",
							"    'gross_output': GO_c,\r\n",
							"    'gross_exports_intermediate': EXGR_INT_c,\r\n",
							"    'gross_exports_final': EXGR_FNL_c,\r\n",
							"    'gross_exports': EXGR_c,\r\n",
							"    'gross_imports_intermediate': IMGR_INT_c,\r\n",
							"    'gross_imports_final': IMGR_FNL_c,\r\n",
							"    'gross_imports': IMGR_c,\r\n",
							"    'gross_trade_balance': BALGR_c,\r\n",
							"    'gross_domestic_demand_intermediate': DDGR_INT_c,\r\n",
							"    'gross_domestic_demand_final': DDGR_FNL_c,\r\n",
							"    'exports_domesitc_value_added': EXGR_DVA_c,\r\n",
							"    'exports_foreign_value_addes' : EXGR_FVA_c,\r\n",
							"    'exports_used_for_export_production': VS1_c,\r\n",
							"    'value_added_exports': VAX_c,\r\n",
							"    'foreign_value_added_domestic_demand': DFD_FVA_c,\r\n",
							"    'export_value_added_one': VAX1_c,\r\n",
							"    'export_value_added_two': VAX2_c,\r\n",
							"    'export_value_added_three': VAX3_c,\r\n",
							"    'domestic_value_added_four': DVA4_c,\r\n",
							"    'domestic_value_added_five': DVA5_c,\r\n",
							"    'domestic_value_added_six': DVA6_c,\r\n",
							"    'gross_value_added': VALUE_c,\r\n",
							"    'gross_derived_value_added': VALUE_derived_c\r\n",
							"\r\n",
							"}\r\n",
							"country_data_frame = pd.DataFrame(country_data)\r\n",
							"\r\n",
							"# Convert DataFrame to CSV strings, export to folders\r\n",
							"country_data_csv_buffer = io.StringIO()\r\n",
							"country_data_frame.to_csv(country_data_csv_buffer, index=False)\r\n",
							"country_data_csv_string = country_data_csv_buffer.getvalue()\r\n",
							"mssparkutils.fs.put(\"abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_Country_Statistics/test.csv\", country_data_csv_string, overwrite=True)\r\n",
							"\r\n",
							"\r\n",
							"# country_data_frame.write.options(header = 'True', delimiter =  ',')\\\r\n",
							"#    .csv(path='abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Eora26_Country_Statistics/test')"
						],
						"outputs": [],
						"execution_count": 267
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#### Export Country_Sector Data"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"country_sector_data = {\r\n",
							"    'gross_output': GO_cs,\r\n",
							"    'gross_exports_intermediate': EXGR_INT_cs,\r\n",
							"    'gross_exports_final': EXGR_FNL_cs,\r\n",
							"    'gross_exports': EXGR_cs,\r\n",
							"    'gross_imports_intermediate': IMGR_INT_cs,\r\n",
							"    'gross_intermediate_domestic_demand': DDGR_INT_cs,\r\n",
							"    'exports_domesitc_value_added': EXGR_DVA_cs,\r\n",
							"    'exports_foreign_value_added': EXGR_FVA_cs,\r\n",
							"    'exports_used_for_export_production': VS1_cs,\r\n",
							"    'gross_value_added': VALUE_cs,\r\n",
							"    'gross_derived_value_added': VALUE_derived_cs\r\n",
							"}\r\n",
							"\r\n",
							"country_sector_data_frame = pd.DataFrame(country_sector_data)"
						],
						"outputs": [],
						"execution_count": 256
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Test_Execution')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ac2sparkpooldev",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "c3591a32-018b-46db-a727-ccb1fa78584a"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Synapse/workspaces/ac2-synapse-ws-dev/bigDataPools/ac2sparkpooldev",
						"name": "ac2sparkpooldev",
						"type": "Spark",
						"endpoint": "https://ac2-synapse-ws-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ac2sparkpooldev",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"print(\"wakeup\")"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import pymrio as pmr"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Masschelin: This seemed to work\r\n",
							"import pandas as pd\r\n",
							"\r\n",
							"py_code = pd.read_csv(\"abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/function.py\", header=None)[0].str.cat(sep='\\n')\r\n",
							"\r\n",
							"#abfss://acj8code@ac2synapsedatalabstorage.dfs.core.windows.net/this5.py\r\n",
							"exec(py_code)\r\n",
							"\r\n",
							"Shane(\"Smith\")"
						],
						"outputs": [],
						"execution_count": 39
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import myWheel as m\r\n",
							""
						],
						"outputs": [],
						"execution_count": 49
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from notebookutils import mssparkutils  \r\n",
							" \r\n",
							"mssparkutils.fs.mount(  \r\n",
							"    \"abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net\",  \r\n",
							"    \"/ac2-synapse-ws-dev/libraries/testing-0.1-py3-none-any.whl\",  \r\n",
							"    {\"linkedService\":\"acj802\"}  \r\n",
							") "
						],
						"outputs": [],
						"execution_count": 42
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import sys\r\n",
							"!{sys.executable} -m pip install --upgrade /testing-0.1-py3-none-any.whl\r\n",
							"\r\n",
							"\r\n",
							"\r\n",
							"\r\n",
							""
						],
						"outputs": [],
						"execution_count": 54
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#Masschelin:\r\n",
							"\r\n",
							"#String reconstructed from here: hxxps://github.com/MicrosoftDocs/azure-docs/blob/main/articles/synapse-analytics/spark/apache-spark-manage-workspace-packages.md\r\n",
							"#So, for some reason, this lists only a .zip file.\r\n",
							"\r\n",
							"mssparkutils.fs.ls(\"abfss://ac2synapsefiles01@ac2synapsedatalabstorage.dfs.core.windows.net/synapse/workspaces/ac2-synapse-ws-dev/sparkpools/ac2sparkpooldev/libraries/\")\r\n",
							"\r\n",
							"#Readin further down, this apparently is not supported for spark 3.0+\r\n",
							"    # \"This method of managing custom wheel files will not be supported on the Azure Synapse Runtime for Apache Spark 3.0. \r\n",
							"    # Please refer to the Workspace packages feature to manage custom wheel files.\"\r\n",
							"\r\n",
							"# Based upon more google-fu, once its assigned to a pool, its just a import \"name_of_custom_package\""
						],
						"outputs": [],
						"execution_count": 9
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Tust_function')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ac2sparkpooldev",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "69c76efb-9241-47aa-af97-b66ec6533721"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Synapse/workspaces/ac2-synapse-ws-dev/bigDataPools/ac2sparkpooldev",
						"name": "ac2sparkpooldev",
						"type": "Spark",
						"endpoint": "https://ac2-synapse-ws-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ac2sparkpooldev",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"def Shane (last = \"duh\"):\r\n",
							"    print(last)\r\n",
							""
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Shane()"
						],
						"outputs": [],
						"execution_count": 3
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/UKY_Coups_Data')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ac2sparkpooldev",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "c36235fe-8d93-4d7e-8b83-1277737947ba"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Synapse/workspaces/ac2-synapse-ws-dev/bigDataPools/ac2sparkpooldev",
						"name": "ac2sparkpooldev",
						"type": "Spark",
						"endpoint": "https://ac2-synapse-ws-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ac2sparkpooldev",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"print (\"initiate\")"
						],
						"outputs": [],
						"execution_count": 1
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/UNCOMTRADE_PKG')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "Set of Function for Searching UNCOMTRADE DATA",
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ac2sparkpooldev",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "6c6ac09b-6f0d-406f-b412-3f74307d29d4"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": true,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Synapse/workspaces/ac2-synapse-ws-dev/bigDataPools/ac2sparkpooldev",
						"name": "ac2sparkpooldev",
						"type": "Spark",
						"endpoint": "https://ac2-synapse-ws-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ac2sparkpooldev",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### UNCOMTRADE SEARCH\r\n",
							"\r\n",
							"This is a set of functions for searching UNCOMTRADE Data"
						]
					},
					{
						"cell_type": "code",
						"source": [
							"print('UNCOMTRADE Serach Running')"
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"##### Packages"
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import sys\r\n",
							"!{sys.executable} -m pip install --upgrade comtradeapicall\r\n",
							"\r\n",
							"import pandas as pd\r\n",
							"import requests\r\n",
							"import comtradeapicall"
						],
						"outputs": [],
						"execution_count": 23
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"##### Variable Prep"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"my_Key = '1f4c419345184626a103f8e79f7fbc9c'"
						],
						"outputs": [],
						"execution_count": 24
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"typeCode = 'C' ### C == Good M == Service None== Everything\r\n",
							"freqCode = 'A'  #### A== Annual M == Monthly\r\n",
							"clCode = 'HS'  ### Use HS\r\n",
							"period = '2022'  ### YYYY or YYYYMM must change Frequency code\r\n",
							"reporterCode = None     #36 = Australia 842 USA 434=Lybia None== Any... TIP Use None for non-un or ureliable Countries (Lybia or Russia...)\r\n",
							"cmdCode = None  ### The comodity code or set of comoditiy codes from the HS set in the comp trade ref tables\r\n",
							"flowCode = None ###  None = all there are 12 codes in total  see ref tables (Import Export Rexport... etc) \r\n",
							"partnerCode = '434'  ## Libya Primary Trade Flow -- Code of interest....\r\n",
							"partner2Code = None ## Regional secondary flow??? Set to to none ...\r\n",
							"customsCode = None  ### Catagorical Variable - 16 cats for tarrif purposes?\r\n",
							"motCode = None #### Mode of transportation \r\n",
							"maxRecords = 500  ### This is the max for a free account\r\n",
							"format_output = 'JSON'   \r\n",
							"aggregateBy = 'cmdCode'  # aggregates on a vector.  cmdCode to match the GUI output\r\n",
							"breakdownMode = 'classic' ### classic and Plus.  Plus consolidates some of the data not sure why.\r\n",
							"countOnly = False ### counts the number of records  use to understand if you exceed the 500 limit\r\n",
							"includeDesc = True  #FALSE Removes all desc variables effectively make the data much smaller buy you need the ref tables to understand the cat vars."
						],
						"outputs": [],
						"execution_count": 25
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"def CountrySearch(Country_Code =\"434\", Year_Start = 2021, Year_End = 2023):\r\n",
							"    \r\n",
							"    Years = list(range(Year_Start, Year_End +1 ))\r\n",
							"\r\n",
							"    ## Get Size\r\n",
							"\r\n",
							"    size1 = comtradeapicall.getFinalData(my_Key,typeCode=typeCode, freqCode=freqCode, clCode=clCode, period=str(Years[0]),\r\n",
							"                                        reporterCode=reporterCode, cmdCode=cmdCode, flowCode=flowCode, partnerCode=Country_Code,\r\n",
							"                                        partner2Code=partner2Code,\r\n",
							"                                        customsCode=customsCode, motCode=motCode, maxRecords=maxRecords, format_output=format_output,\r\n",
							"                                        aggregateBy=aggregateBy, breakdownMode=breakdownMode, countOnly=True, includeDesc=includeDesc)\r\n",
							"\r\n",
							"    # Catch Error\r\n",
							"    size = int(size1.iat[0,0])\r\n",
							"    print(f\"{Years[0]} {size}\")\r\n",
							"\r\n",
							"    if int(size) > 499:\r\n",
							"        print(\"Error Greater than 499 -- origin\")\r\n",
							"        return(\"You Broke it at origin\") \r\n",
							"\r\n",
							"    #initial\r\n",
							"    myData = comtradeapicall.getFinalData(my_Key, typeCode=typeCode, freqCode=freqCode, clCode=clCode, period=str(Years[0]),\r\n",
							"                                        reporterCode=reporterCode, cmdCode=cmdCode, flowCode=flowCode, partnerCode=Country_Code,\r\n",
							"                                        partner2Code=partner2Code,\r\n",
							"                                        customsCode=customsCode, motCode=motCode, maxRecords=maxRecords, format_output=format_output,\r\n",
							"                                        aggregateBy=aggregateBy, breakdownMode=breakdownMode, countOnly=countOnly, includeDesc=includeDesc)\r\n",
							"    \r\n",
							"\r\n",
							"    for year in Years[1:]:\r\n",
							"        print (f\"{'Moving to'} {year}\")\r\n",
							"\r\n",
							"        size1 = comtradeapicall.getFinalData(my_Key,typeCode=typeCode, freqCode=freqCode, clCode=clCode, period=str(year),\r\n",
							"                                        reporterCode=reporterCode, cmdCode=cmdCode, flowCode=flowCode, partnerCode=Country_Code,\r\n",
							"                                        partner2Code=partner2Code,\r\n",
							"                                        customsCode=customsCode, motCode=motCode, maxRecords=maxRecords, format_output=format_output,\r\n",
							"                                        aggregateBy=aggregateBy, breakdownMode=breakdownMode, countOnly=True, includeDesc=includeDesc)\r\n",
							"\r\n",
							"        # Catch Error\r\n",
							"        size = int(size1.iat[0,0])\r\n",
							"        print(f\"{year} {size}\")\r\n",
							"\r\n",
							"        if int(size) > 499:\r\n",
							"            print(f\"{'Error Greater than 499'} {year}\")\r\n",
							"            return(f\"{'You Broke it @'} {year}\" ) \r\n",
							"\r\n",
							"        #initial\r\n",
							"        myDf = comtradeapicall.getFinalData(my_Key,typeCode=typeCode, freqCode=freqCode, clCode=clCode, period=str(year),\r\n",
							"                                            reporterCode=reporterCode, cmdCode=cmdCode, flowCode=flowCode, partnerCode=Country_Code,\r\n",
							"                                            partner2Code=partner2Code,\r\n",
							"                                            customsCode=customsCode, motCode=motCode, maxRecords=maxRecords, format_output=format_output,\r\n",
							"                                            aggregateBy=aggregateBy, breakdownMode=breakdownMode, countOnly=countOnly, includeDesc=includeDesc)\r\n",
							"\r\n",
							"        myData = pd.concat([myData, myDf])\r\n",
							"\r\n",
							"\r\n",
							"\r\n",
							"    return (myData)\r\n",
							""
						],
						"outputs": [],
						"execution_count": 26
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"   myData = comtradeapicall.getFinalData(my_Key,typeCode=typeCode, freqCode=freqCode, clCode=clCode, period=str(2022),\r\n",
							"                                        reporterCode=reporterCode, cmdCode=cmdCode, flowCode=flowCode, partnerCode='434',\r\n",
							"                                        partner2Code=partner2Code,\r\n",
							"                                        customsCode=customsCode, motCode=motCode, maxRecords=maxRecords, format_output=format_output,\r\n",
							"                                        aggregateBy=aggregateBy, breakdownMode=breakdownMode, countOnly=countOnly, includeDesc=includeDesc)"
						],
						"outputs": [],
						"execution_count": 27
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"myDf"
						],
						"outputs": [],
						"execution_count": 28
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"CountrySearch()"
						],
						"outputs": [],
						"execution_count": 29
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/UNCOMTRADE_Querry_Example')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"description": "connection to comtrade",
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ac2sparkpooldev",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "60067717-4613-4913-a2d0-9cfd0d12e3e2"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Synapse/workspaces/ac2-synapse-ws-dev/bigDataPools/ac2sparkpooldev",
						"name": "ac2sparkpooldev",
						"type": "Spark",
						"endpoint": "https://ac2-synapse-ws-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ac2sparkpooldev",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 10,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"Hasbrouck 3oct24 copy code provided by UN COM Trade "
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"print(\"Wakey Wakey\")"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"source": [
							"# Install a pip comtradeapicall package in the current Jupyter kernel\r\n",
							"import sys\r\n",
							"!{sys.executable} -m pip install --upgrade comtradeapicall"
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import pandas\r\n",
							"import requests\r\n",
							"import comtradeapicall"
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"subscription_key = '<YOUR KEY>' # comtrade api subscription key (from comtradedeveloper.un.org)\r\n",
							"directory = '<OUTPUT DIR>'  # output directory for downloaded files \r\n",
							"proxy_url = '<PROXY URL>'  # optional if you need proxy url"
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#set some variables\r\n",
							"from datetime import date\r\n",
							"from datetime import timedelta\r\n",
							"today = date.today()\r\n",
							"yesterday = today - timedelta(days=1)\r\n",
							"lastweek = today - timedelta(days=7)"
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							" Call preview final data API to a data frame, max to 500 records, no subscription key required\r\n",
							" \r\n",
							" This example: Australia imports of commodity code 91 in classic mode in May 2022"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"mydf = comtradeapicall.previewFinalData(typeCode='C', freqCode='M', clCode='HS', period='202205',\r\n",
							"                                        reporterCode='36', cmdCode='36', flowCode='M', partnerCode=None,\r\n",
							"                                        partner2Code=None,\r\n",
							"                                        customsCode=None, motCode=None, maxRecords=500, format_output='JSON',\r\n",
							"                                        aggregateBy=None, breakdownMode='classic', countOnly=None, includeDesc=True)"
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"mydf.head(5)"
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"-------------------------- End Example ---------------------------------------------"
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"## Libya Example\r\n",
							"\r\n",
							"*NOTE: MAX Querry 500 rows without subscription*"
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"#### Links\r\n",
							"- [UNCOMTRADE REF TABLES](https://comtradeplus.un.org/ListOfReferences)\r\n",
							"- [UNCOMTRADEAPI](https://comtradedeveloper.un.org/signin?returnUrl=%2F)"
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"import pandas as pd\r\n",
							"### reset  pandas data frame to see all columns on df return\r\n",
							"pd.set_option('display.max_columns', None)\r\n",
							"pd.set_option('display.expand_frame_repr', False)\r\n",
							"pd.set_option('max_colwidth', None)"
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"help(comtradeapicall.previewFinalData)"
						],
						"outputs": []
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							""
						]
					},
					{
						"cell_type": "markdown",
						"metadata": {
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"### Selection Criteria\r\n",
							"- typeCode(str) : Product type. Goods (C) or Services (S)\r\n",
							"- freqCode(str) : The time interval at which observations occur. Annual (A) or Monthly (M)\r\n",
							"- clCode(str) : Indicates the product classification used and which version (HS, SITC)\r\n",
							"- period(str) : Combination of year and month (for monthly), year for (annual)\r\n",
							"- reporterCode(str) : The country or geographic area to which the measured statistical phenomenon relates\r\n",
							"- cmdCode(str) : Product code in conjunction with classification code\r\n",
							"- flowCode(str) : Trade flow or sub-flow (exports, re-exports, imports, re-imports, etc.)\r\n",
							"- partnerCode(str) : The primary partner country or geographic area for the respective trade flow\r\n",
							"- partner2Code(str) : A secondary partner country or geographic area for the respective trade flow\r\n",
							"- customsCode(str) : Customs or statistical procedure\r\n",
							"- motCode(str) : The mode of transport used when goods enter or leave the economic territory of a country\r\n",
							"### Query Options\r\n",
							"- maxRecords(int) : Limit number of returned records\r\n",
							"- format_output(str) : The output format. CSV or JSON\r\n",
							"- aggregateBy(str) : Option for aggregating the query\r\n",
							"- breakdownMode(str) : Option to select the classic (trade by partner/product) or plus (extended breakdown) mode\r\n",
							"- countOnly(bool) : Return the actual number of records if set to True\r\n",
							"- includeDesc(bool) : Option to include the description or not\r\n",
							"### AIS Selection Criteria\r\n",
							"- typeCode(str) : Product type. Only Goods (C)\r\n",
							"- freqCode(str) : The time interval at which observations occur. Daily (D)\r\n",
							"- datefrom(str) and dateto(str) : Date(s) of observation - ASCII format\r\n",
							"- countryareaCode(str) : The country or geographic area to which the measured statistical phenomenon relates. Use getReference('ais:countriesareas') for the complete list.\r\n",
							"- vesselTypeCode(str) : The high level categorization of vessels transporting the goods. Use getReference('ais:vesseltypes') for the complete list.\r\n",
							"- flowCode(str) : Trade flow (exports, imports)\r\n",
							"### Proxy Server\r\n",
							"- proxy_url(str) : All functions that call the API support the proxy server. Use the parameter proxy_url.\r\n",
							""
						]
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"typeCode = 'C' ### C == Good M == Service None== Everything\r\n",
							"freqCode = 'A'  #### A== Annual M == Monthly\r\n",
							"clCode = 'HS'  ### Use HS\r\n",
							"period = '2022'  ### YYYY or YYYYMM must change Frequency code\r\n",
							"reporterCode = None     #36 = Australia 842 USA 434=Lybia None== Any... TIP Use None for non-un or ureliable Countries (Lybia or Russia...)\r\n",
							"cmdCode = None  ### The comodity code or set of comoditiy codes from the HS set in the comp trade ref tables\r\n",
							"flowCode = None ###  None = all there are 12 codes in total  see ref tables (Import Export Rexport... etc) \r\n",
							"partnerCode = '434'  ## Libya Primary Trade Flow -- Code of interest....\r\n",
							"partner2Code = None ## Regional secondary flow??? Set to to none ...\r\n",
							"customsCode = None  ### Catagorical Variable - 16 cats for tarrif purposes?\r\n",
							"motCode = None #### Mode of transportation \r\n",
							"maxRecords = 500  ### This is the max for a free account\r\n",
							"format_output = 'JSON'   \r\n",
							"aggregateBy = 'cmdCode'  # aggregates on a vector.  cmdCode to match the GUI output\r\n",
							"breakdownMode = 'classic' ### classic and Plus.  Plus consolidates some of the data not sure why.\r\n",
							"countOnly = False ### counts the number of records  use to understand if you exceed the 500 limit\r\n",
							"includeDesc = True  #FALSE Removes all desc variables effectively make the data much smaller buy you need the ref tables to understand the cat vars.\r\n",
							""
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"mydf = comtradeapicall.previewFinalData(typeCode=typeCode, freqCode=freqCode, clCode=clCode, period=period,\r\n",
							"                                        reporterCode=reporterCode, cmdCode=cmdCode, flowCode=flowCode, partnerCode=partnerCode,\r\n",
							"                                        partner2Code=partner2Code,\r\n",
							"                                        customsCode=customsCode, motCode=motCode, maxRecords=maxRecords, format_output=format_output,\r\n",
							"                                        aggregateBy=aggregateBy, breakdownMode=breakdownMode, countOnly=countOnly, includeDesc=includeDesc)"
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"tags": [
								"parameters"
							]
						},
						"source": [
							"mydf"
						],
						"outputs": []
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"help(comtradeapicall)"
						],
						"outputs": []
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/World_Bank_Indicators_Clean')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "ac2sparkpooldev",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "28g",
					"driverCores": 4,
					"executorMemory": "28g",
					"executorCores": 4,
					"numExecutors": 2,
					"runAsWorkspaceSystemIdentity": false,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "6b299932-8abf-4376-a964-05c0b02272c7"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Synapse/workspaces/ac2-synapse-ws-dev/bigDataPools/ac2sparkpooldev",
						"name": "ac2sparkpooldev",
						"type": "Spark",
						"endpoint": "https://ac2-synapse-ws-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ac2sparkpooldev",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net",
							"authHeader": null
						},
						"sparkVersion": "3.4",
						"nodeCount": 3,
						"cores": 4,
						"memory": 28,
						"extraHeader": null
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"source": [
							"import pandas as pd\r\n",
							"\r\n",
							"# Load the CSV file\r\n",
							"df = pd.read_csv('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Basic_Stats_(WB_Sourced)/World_Bank_Indicators_Unpivoted.csv')\r\n",
							"\r\n",
							"# Convert columns with scientific notation to standard numeric format\r\n",
							"columns_to_convert = ['Age_dependency_ratio_Percent_of_working_age_population','Agricultural_land_Percent_of_land_area','Agricultural_land_sq_km','Agriculture_forestry_and_fishing_value_added_Percent_of_GDP','Agriculture_forestry_and_fishing_value_added_current_USD','Arable_land_Percent_of_land_area','Arable_land_hectares','Arms_exports_SIPRI_trend_indicator_values','Arms_imports_SIPRI_trend_indicator_values','Battle_related_deaths_number_of_people','Birth_rate_crude_per_1000_people','Chemicals_Percent_of_value_added_in_manufacturing','Container_port_traffic_TEU_20_foot_equivalent_units','Current_health_expenditure_Percent_of_GDP','Current_health_expenditure_per_capita_current_USD','Death_rate_crude_per_1000_people','Electric_power_consumption_kWh_per_capita','Energy_imports_net_Percent_of_energy_use','Energy_use_kg_of_oil_equivalent_per_capita','Exports_of_goods_and_services_Percent_of_GDP','External_debt_stocks_Percent_of_GNI','External_debt_stocks_total_DOD_current_USD','Fertility_rate_total_births_per_woman','Food_beverages_and_tobacco_Percent_of_value_added_in_manufacturing','Foreign_direct_investment_net_BoP_current_USD','Foreign_direct_investment_net_inflows_BoP_current_USD','Forest_area_Percent_of_land_area','Forest_area_sq_km','GDP_current_USD','GDP_growth_annual_Percent','GDP_per_capita_current_USD','GDP_per_capita_PPP_current_international_dollar','GDP_PPP_current_international_dollar','GNI_per_capita_Atlas_method_current_USD','GNI_per_capita_PPP_current_international_dollar','GNI_Atlas_method_current_USD','GNI_PPP_current_international_dollar','Gini_index','Gross_capital_formation_Percent_of_GDP','Gross_value_added_at_basic_prices_GVA_current_USD','High_technology_exports_Percent_of_manufactured_exports','Imports_of_goods_and_services_Percent_of_GDP','Income_share_held_by_lowest_20Percent','Individuals_using_the_Internet_Percent_of_population','Industry_including_construction_value_added_Percent_of_GDP','Industry_including_construction_value_added_current_USD','Inflation_GDP_deflator_annual_Percent','Inflation_consumer_prices_annual_Percent','Interest_payments_Percent_of_revenue','Internally_displaced_persons_new_displacement_associated_with_disasters_number_of_cases','International_migrant_stock_Percent_of_population','Labor_force_total','Land_area_sq_km','Life_expectancy_at_birth_total_years','Literacy_rate_adult_total_Percent_of_people_ages_15_and_above','Manufacturing_value_added_Percent_of_GDP','Manufacturing_value_added_current_USD','Market_capitalization_of_listed_domestic_companies_Percent_of_GDP','Merchandise_trade_Percent_of_GDP','Military_expenditure_Percent_of_GDP','Military_expenditure_current_USD','Mobile_cellular_subscriptions_per_100_people','Mortality_rate_under_5_per_1000_live_births','Net_ODA_received_per_capita_current_USD','Net_migration','PM2decimal5_air_pollution_population_exposed_to_levels_exceeding_WHO_guideline_value_Percent_of_total','Personal_remittances_paid_current_USD','Personal_remittances_received_Percent_of_GDP','Population_growth_annual_Percent','Population_female','Population_female_Percent_of_total_population','Population_male','Population_male_Percent_of_total_population','Population_total','Poverty_headcount_ratio_at_national_poverty_lines_Percent_of_population','Prevalence_of_HIV_total_Percent_of_population_ages_15_49','Primary_completion_rate_total_Percent_of_relevant_age_group','Rail_lines_total_route_km','Railways_goods_transported_million_ton_km','Railways_passengers_carried_million_passenger_km','Revenue_excluding_grants_Percent_of_GDP','School_enrollment_primary_and_secondary_gross_gender_parity_index_GPI','School_enrollment_secondary_Percent_gross','School_enrollment_tertiary_Percent_gross','Services_value_added_Percent_of_GDP','Services_value_added_current_USD','Start_up_procedures_to_register_a_business_number','Stocks_traded_total_value_Percent_of_GDP','Surface_area_sq_km','Survival_to_age_65_female_Percent_of_cohort','Survival_to_age_65_male_Percent_of_cohort','Tax_revenue_Percent_of_GDP','Taxes_on_exports_Percent_of_tax_revenue','Total_debt_service_Percent_of_GNI','Unemployment_total_Percent_of_total_labor_force_national_estimate','Urban_population_Percent_of_total_population','Water_productivity_total_constant_2015_USD_GDP_per_cubic_meter_of_total_freshwater_withdrawal']\r\n",
							"for column in columns_to_convert:\r\n",
							"    df[column] = df[column].apply(lambda x: '{:.15f}'.format(float(x)) if pd.notnull(x) else x)\r\n",
							"\r\n",
							"# Save the cleaned data back to a CSV file\r\n",
							"df.to_csv('abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/Basic_Stats_(WB_Sourced)/World_Bank_Indicators_Unpivoted_cleaned.csv', index=False)"
						],
						"outputs": [],
						"execution_count": 11
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/EORACountryStatDemo')]",
			"type": "Microsoft.Synapse/workspaces/databases",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"Ddls": [
					{
						"ActionType": "CREATE",
						"OldEntity": null,
						"NewEntity": {
							"Name": "EORACountryStatDemo",
							"EntityType": "DATABASE",
							"Origin": {
								"Type": "SPARK"
							},
							"Properties": {
								"IsSyMSCDMDatabase": true
							},
							"Source": {
								"Provider": "ADLS",
								"Location": "abfss://ac2synapsefiles01@ac2synapsedatalabstorage.dfs.core.windows.net/EORACountryStatDemo",
								"Properties": {
									"FormatType": "csv",
									"LinkedServiceName": "ac2-synapse-ws-dev-WorkspaceDefaultStorage"
								}
							},
							"PublishStatus": "PUBLISHED",
							"ObjectVersion": 2,
							"ObjectId": "7285fe6a-b1c2-47c4-8453-315732d4fff9"
						},
						"Source": {
							"Type": "SPARK"
						}
					},
					{
						"ActionType": "CREATE",
						"OldEntity": null,
						"NewEntity": {
							"Name": "CountryStats",
							"EntityType": "TABLE",
							"TableType": "EXTERNAL",
							"Namespace": {
								"SchemaName": null,
								"DatabaseName": "EORACountryStatDemo",
								"DatabaseId": null
							},
							"StorageDescriptor": {
								"Distribution": null,
								"Columns": [
									{
										"Name": "year",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "integer",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 0,
											"Scale": 0,
											"Properties": {
												"HIVE_TYPE_STRING": "integer"
											}
										}
									},
									{
										"Name": "gross_output",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									},
									{
										"Name": "gross_exports_intermediate",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									},
									{
										"Name": "gross_exports_final",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									},
									{
										"Name": "gross_exports",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									},
									{
										"Name": "gross_imports_intermediate",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									},
									{
										"Name": "gross_imports_final",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									},
									{
										"Name": "gross_imports",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									},
									{
										"Name": "gross_trade_balance",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									},
									{
										"Name": "gross_domestic_demand_intermediate",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									},
									{
										"Name": "gross_domestic_demand_final",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									},
									{
										"Name": "exports_domesitc_value_added",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									},
									{
										"Name": "exports_foreign_value_added",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									},
									{
										"Name": "exports_used_for_export_production",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									},
									{
										"Name": "value_added_exports",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									},
									{
										"Name": "foreign_value_added_domestic_demand",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									},
									{
										"Name": "export_value_added_one",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									},
									{
										"Name": "export_value_added_two",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									},
									{
										"Name": "export_value_added_three",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									},
									{
										"Name": "domestic_value_added_four",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									},
									{
										"Name": "domestic_value_added_five",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									},
									{
										"Name": "domestic_value_added_six",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									},
									{
										"Name": "gross_value_added",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									},
									{
										"Name": "gross_derived_value_added",
										"Description": null,
										"OriginDataTypeName": {
											"TypeName": "decimal",
											"IsComplexType": false,
											"IsNullable": true,
											"Length": 0,
											"Precision": 38,
											"Scale": 18,
											"Properties": {
												"HIVE_TYPE_STRING": "decimal"
											}
										}
									}
								],
								"ColumnSetEntityName": "9e7d1fa2-78d8-4a3a-a15b-d07b6c6a91fa",
								"Format": {
									"InputFormat": "org.apache.hadoop.hive.ql.io.parquet.MapredParquetInputFormat",
									"OutputFormat": "org.apache.hadoop.hive.ql.io.parquet.MapredParquetOutputFormat",
									"FormatType": "parquet",
									"SerializeLib": "org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe",
									"Properties": {
										"path": "abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/parquet/eora-country-stats-2022.parquet",
										"FormatTypeSetToDatabaseDefault": false
									}
								},
								"Source": {
									"Provider": "ADLS",
									"Location": "abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/parquet/eora-country-stats-2022.parquet",
									"Properties": {
										"LinkedServiceName": "ac2-synapse-ws-dev-WorkspaceDefaultStorage",
										"LocationSetToDatabaseDefault": false
									}
								},
								"Properties": {
									"textinputformat.record.delimiter": ",",
									"compression": "{\"type\":\"None\",\"level\":\"optimal\"}",
									"derivedModelAttributeInfo": "{\"attributeReferences\":{}}"
								},
								"Compressed": false,
								"SerDeInfo": null,
								"IsStoredAsSubdirectories": false
							},
							"Owner": null,
							"CreateTime": 0,
							"LastAccessTime": 0,
							"Retention": 0,
							"Temporary": false,
							"IsRewriteEnabled": false,
							"ViewOriginalText": null,
							"ViewExpandedText": null,
							"Origin": {
								"Type": "SPARK"
							},
							"OriginObjectId": null,
							"IsSharedEntity": false,
							"PublishStatus": "PUBLISHED",
							"Properties": {
								"Description": "",
								"DisplayFolderInfo": "{\"name\":\"Others\",\"colorCode\":\"\"}",
								"PrimaryKeys": "",
								"spark.sql.sources.provider": "parquet",
								"spark.sql.sources.schema.numParts": "1",
								"spark.sql.sources.schema.part.0": "{\"type\":\"struct\",\"fields\":[{\"name\":\"year\",\"type\":\"integer\",\"nullable\":true,\"metadata\":{}},{\"name\":\"gross_output\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"gross_exports_intermediate\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"gross_exports_final\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"gross_exports\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"gross_imports_intermediate\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"gross_imports_final\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"gross_imports\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"gross_trade_balance\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"gross_domestic_demand_intermediate\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"gross_domestic_demand_final\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"exports_domesitc_value_added\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"exports_foreign_value_added\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"exports_used_for_export_production\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"value_added_exports\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"foreign_value_added_domestic_demand\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"export_value_added_one\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"export_value_added_two\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"export_value_added_three\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"domestic_value_added_four\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"domestic_value_added_five\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"domestic_value_added_six\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"gross_value_added\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}},{\"name\":\"gross_derived_value_added\",\"type\":\"decimal(38,18)\",\"nullable\":true,\"metadata\":{}}]}"
							},
							"ObjectVersion": 2,
							"ObjectId": "2d906be0-dfa8-4842-9f15-dde3ceb1c9c9",
							"Description": ""
						},
						"Source": {
							"Type": "SPARK"
						}
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ac2sparkpooldev')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 15
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 10,
					"minNodeCount": 3
				},
				"nodeCount": 3,
				"nodeSize": "Small",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.4",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": true,
				"customLibraries": [
					{
						"name": "testing-0.1-py3-none-any.whl",
						"path": "ac2-synapse-ws-dev/libraries/testing-0.1-py3-none-any.whl",
						"containerName": "prep",
						"uploadedTimestamp": "0001-01-01T00:00:00+00:00",
						"type": "whl"
					},
					{
						"name": "david_project-0.1-py3-none-any.whl",
						"path": "ac2-synapse-ws-dev/libraries/david_project-0.1-py3-none-any.whl",
						"containerName": "prep",
						"uploadedTimestamp": "0001-01-01T00:00:00+00:00",
						"type": "whl"
					},
					{
						"name": "lpSolve_5.6.22.tar.gz",
						"path": "ac2-synapse-ws-dev/libraries/lpSolve_5.6.22.tar.gz",
						"containerName": "prep",
						"uploadedTimestamp": "0001-01-01T00:00:00+00:00",
						"type": "gz"
					},
					{
						"name": "bnlearn_5.0.tar.gz",
						"path": "ac2-synapse-ws-dev/libraries/bnlearn_5.0.tar.gz",
						"containerName": "prep",
						"uploadedTimestamp": "0001-01-01T00:00:00+00:00",
						"type": "gz"
					},
					{
						"name": "rmetalog_1.0.3.tar.gz",
						"path": "ac2-synapse-ws-dev/libraries/rmetalog_1.0.3.tar.gz",
						"containerName": "prep",
						"uploadedTimestamp": "0001-01-01T00:00:00+00:00",
						"type": "gz"
					},
					{
						"name": "en_core_web_sm-3.8.0-py3-none-any.whl",
						"path": "ac2-synapse-ws-dev/libraries/en_core_web_sm-3.8.0-py3-none-any.whl",
						"containerName": "prep",
						"uploadedTimestamp": "0001-01-01T00:00:00+00:00",
						"type": "whl"
					},
					{
						"name": "spark-excel_2.12-3.5.1_0.20.4.jar",
						"path": "ac2-synapse-ws-dev/libraries/spark-excel_2.12-3.5.1_0.20.4.jar",
						"containerName": "prep",
						"uploadedTimestamp": "0001-01-01T00:00:00+00:00",
						"type": "jar"
					}
				],
				"annotations": []
			},
			"dependsOn": [],
			"location": "eastus"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/ac2sqldwdev')]",
			"type": "Microsoft.Synapse/workspaces/sqlPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"collation": "SQL_Latin1_General_CP1_CI_AS",
				"maxSizeBytes": 263882790666240,
				"annotations": []
			},
			"dependsOn": [],
			"location": "eastus"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/default/synapse-ws-custstgacct--ac2-synapse-ws-dev-ac2synapsedatalabstorage')]",
			"type": "Microsoft.Synapse/workspaces/managedVirtualNetworks/managedPrivateEndpoints",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"privateLinkResourceId": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Storage/storageAccounts/ac2synapsedatalabstorage",
				"groupId": "dfs",
				"fqdns": [
					"ac2synapsedatalabstorage.dfs.core.windows.net"
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/managedVirtualNetworks/default')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/default/synapse-ws-sql--ac2-synapse-ws-dev')]",
			"type": "Microsoft.Synapse/workspaces/managedVirtualNetworks/managedPrivateEndpoints",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"privateLinkResourceId": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Synapse/workspaces/ac2-synapse-ws-dev",
				"groupId": "sql",
				"fqdns": [
					"ac2-synapse-ws-dev.dd138e92-b02c-477d-a3aa-86a940c86bcc.sql.azuresynapse.net"
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/managedVirtualNetworks/default')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/default/synapse-ws-sqlOnDemand--ac2-synapse-ws-dev')]",
			"type": "Microsoft.Synapse/workspaces/managedVirtualNetworks/managedPrivateEndpoints",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"privateLinkResourceId": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Synapse/workspaces/ac2-synapse-ws-dev",
				"groupId": "sqlOnDemand",
				"fqdns": [
					"ac2-synapse-ws-dev-ondemand.dd138e92-b02c-477d-a3aa-86a940c86bcc.sql.azuresynapse.net"
				]
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/managedVirtualNetworks/default')]"
			]
		}
	]
}