{
	"name": "AFRICOM_Instability_Index",
	"properties": {
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "ac2sparkpooldev",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "28g",
			"driverCores": 4,
			"executorMemory": "28g",
			"executorCores": 4,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2",
				"spark.autotune.trackingId": "413edbbb-782c-4909-86ca-0e106c66356a"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/fb276628-ada1-41d2-9fe6-b02c83c5d04e/resourceGroups/ac2-rg-synapse-01/providers/Microsoft.Synapse/workspaces/ac2-synapse-ws-dev/bigDataPools/ac2sparkpooldev",
				"name": "ac2sparkpooldev",
				"type": "Spark",
				"endpoint": "https://ac2-synapse-ws-dev.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/ac2sparkpooldev",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.4",
				"nodeCount": 3,
				"cores": 4,
				"memory": 28,
				"automaticScaleJobs": false
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### LTC Cardy Moten III, ACJ802, cardy.moten3.mil@mail.mil \n",
					"#### 19 May 2025"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Purpose\n",
					"\n",
					"This notebook provides the methodology for extracting the requisite datasets to build and subsequently analyze the [AFRICOM Instability Risk Index (IRI) Assessment](https://dod365.sharepoint-mil.us/:w:/r/teams/AFRICOM-AFRICOMJ802Collaboration/Shared%20Documents/General/Campaign%20Assessment%20Literature/3-Analysis%20and%20Assessment/Risk%20Analysis/Africa%20Instability%20Risk%20Assessment_5MAY2025.docx?d=wc2e7e9be66ea4c1b9e77a30f729d54ce&csf=1&web=1&e=XXlM2m) [1]. The proponent for the use of the index and the methodology to create the index is the USAFRICOM J54."
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Index Overview\n",
					"\n",
					"The IRI is a composite index that is built from 30 indicators across two domains (Social Cohesion and Governance Capacity) developed by the IRI assessmeent team [1]. Each indicator is converted from its raw format to a rescaled score between 0 to 2 summarized by the table below.\n",
					"\n",
					"| Score | Interpretation            |\n",
					"|-------|---------------------------|\n",
					"| 0     | low instability risk      |\n",
					"| 1     | moderate instability risk |\n",
					"| 2     | high instability risk     |\n",
					"\n",
					"Based on this method a country can have a score ranging from 0 - 60 with lower scores representing more stability. To ensure consistency with using this index with across countries when analyzing with regards to domains across time, the scores are nomalized again to a 0 - 1 ratio value. This conversion is simply done by the following formula $$normalized\\_score = \\frac{current\\_score}{max\\_score}$$\n",
					"\n",
					"## Methodology Addition\n",
					"\n",
					"In addition to the coversion of the raw data, we will also produce estimates out to the current year of analysis since a few datasets stop their collection prior to the current year of analysis. In these cases we will employ Autoregressive Integrated Moving Average (ARIMA) estimates along with building a sample distribution using Metalogs [2] [3].\n",
					""
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Packages"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Installs"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"%pip install --upgrade pip\n",
					"%pip install pandas_datareader\n",
					"%pip install pymetalog"
				],
				"execution_count": 1
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Imports"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"import pandas as pd\n",
					"import numpy as np\n",
					"import requests\n",
					"import pandas_datareader.wb as wb\n",
					"from notebookutils import mssparkutils\n",
					"from pyspark.sql import SparkSession\n",
					"from pyspark.sql.functions import col, year\n",
					"import pymetalog\n",
					"from statsmodels.tsa.arima.model import ARIMA\n",
					"from datetime import datetime"
				],
				"execution_count": 2
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Helper Functions"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"def check_country_names(list_a, list_b):\n",
					"    set_a = set(list_a)\n",
					"    set_b = set(list_b)\n",
					"    print(set_a.difference(set_b))\n",
					"\n",
					"def capture_named_args(**kwargs):\n",
					"    return list(kwargs.keys())\n",
					"\n",
					"def create_domain_index(country_iso, df1, df2, df3, df4, df5):\n",
					"    try:\n",
					"        if all(country_iso in df[\"iso3\"].values for df in [df1, df2, df3, df4, df5]):\n",
					"            print(f\"{country_iso} exists in all data frames. Continuing!\")\n",
					"    except KeyError as e:\n",
					"        print(f\"Column not found: {e}\")\n",
					"    except Exception as e:\n",
					"        print(f\"{country_iso} is missing in at least one data frame.\")\n",
					"\n",
					"    df_1 = df1[df1['iso3'] == country_iso].copy()\n",
					"    df_1.drop(columns=[\"value\"], inplace=True)\n",
					"\n",
					"    df_2 = df2[df2['iso3'] == country_iso].copy()\n",
					"    df_2.drop(columns=[\"value\"], inplace=True)\n",
					"\n",
					"    df_3 = df3[df3['iso3'] == country_iso].copy()\n",
					"    df_3.drop(columns=[\"value\"], inplace=True)\n",
					"\n",
					"    df_4 = df4[df4['iso3'] == country_iso].copy()\n",
					"    df_4.drop(columns=[\"value\"], inplace=True)\n",
					"\n",
					"    df_5 = df5[df5['iso3'] == country_iso].copy()\n",
					"    df_5.drop(columns=[\"value\"], inplace=True)\n",
					"        \n",
					"    # Merge all dataframes on 'year'\n",
					"    index_df = df_1.merge(df_2, on='year', how='outer', suffixes=('', '_df2')) \\\n",
					"                         .merge(df_3, on='year', how='outer', suffixes=('', '_df3')) \\\n",
					"                         .merge(df_4, on='year', how='outer', suffixes=('', '_df4')) \\\n",
					"                         .merge(df_5, on='year', how='outer', suffixes=('', '_df5'))\n",
					"\n",
					"    # Identify score columns\n",
					"    score_cols = [col for col in index_df.columns if col.endswith('_score')]\n",
					"    \n",
					"\n",
					"    # Interpolate missing values\n",
					"    for col in score_cols:\n",
					"        if index_df[col].isnull().any():\n",
					"            index_df[col] = index_df[col].interpolate(method='linear', limit_direction='both')\n",
					"\n",
					"    keep_cols = ['iso3', 'name', 'year'] + score_cols\n",
					"    index_df = index_df[keep_cols]\n",
					"\n",
					"    # Calculate domain score\n",
					"    index_df['domain_score'] = index_df[score_cols].sum(axis=1, skipna=True) / 10\n",
					"    index_df = index_df[['iso3', 'name', 'year', 'domain_score']]\n",
					"\n",
					"    return index_df\n",
					"\n",
					"def compute_estimate_percentiles(index_df):\n",
					"    start_year = max(index_df['year']) + 1\n",
					"    end_year = datetime.now().year\n",
					"\n",
					"\n",
					"    # Fit ARIMA model\n",
					"    model = ARIMA(index_df['domain_score'], order=(1, 1, 1))\n",
					"    model_fit = model.fit()\n",
					"\n",
					"    # Forecast from start_year to end_year\n",
					"    forecast = model_fit.get_forecast(steps=3)\n",
					"    forecast_index = list(range(start_year, end_year + 1))\n",
					"    forecast_df = pd.DataFrame({\n",
					"        'year': forecast_index,\n",
					"        'forecast': forecast.predicted_mean,\n",
					"        'lower_ci': forecast.conf_int(alpha=0.10).iloc[:, 0],\n",
					"        'upper_ci': forecast.conf_int(alpha=0.10).iloc[:, 1]\n",
					"    })\n",
					"\n",
					"    #Extract the 10-50-90 values for a metalog distribution\n",
					"    forecast_end_year = forecast_df[forecast_df['year'] == end_year]\n",
					"    forecast_value = forecast_end_year['forecast'].values[0]\n",
					"    lower_ci_end_year = forecast_end_year['lower_ci'].values[0]\n",
					"    upper_ci_end_year = forecast_end_year['upper_ci'].values[0]\n",
					"\n",
					"    percentiles = np.percentile([lower_ci_end_year, forecast_value, upper_ci_end_year], [10, 50, 90])\n",
					"    return percentiles"
				],
				"execution_count": 3
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"# Gather Data\n",
					"\n",
					"USAFRICOM should collect new data on an annual basis since most of these data sources are updated on that cycle.\n",
					"\n",
					"## Social Cohesion Domain\n",
					""
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Socioenvironmental Pressures Subdomain\n",
					"\n",
					"| Data Source | URL | Indicator Domain | Notes |\n",
					"|-------------|-----|------------------|-------|\n",
					"| Notre Dame Global Adaptation Initiative (ND-GAIN) [4]    | <https://gain.nd.edu/our-work/country-index/download-data/> | Socioenvironmental Pressures | Annual Update |\n",
					"| The Commonwealth - Global Youth Index [5]    | <https://cwapiservices.thecommonwealth.org/index.html> | Socioenvironmental Pressures | Annual Update |\n",
					"| World Bank Literacy Rates [6]    | <https://data.worldbank.org/indicator/SE.ADT.LITR.ZS?most_recent_value_desc=true> | Socioenvironmental Pressures | Replacement for the United Nations Human Development Report -Education Index Score |\n",
					"| Fragile State Index—Human Flight and Brain Drain score [7]    | <https://fragilestatesindex.org/indicators/e3/> | Socioenvironmental Pressures | Annual Update |\n",
					"| Fragile State Index—Demographic Pressures score [7]   | <https://fragilestatesindex.org/indicators/s1/> | Socioenvironmental Pressures | Annual Update |\n",
					"\n",
					"Table of IRI Socioenvironmental Datasources\n",
					""
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### ND-Gain\n",
					"\n",
					"This dataset comes in a zip file containing multiple file. The required file to build the IRI is called `resources/gain/gain.csv`. After downloading the file, I renamed it to `nd_gain_country_index_2024.csv`."
				]
			},
			{
				"cell_type": "code",
				"source": [
					"\n",
					"# Define the column names\n",
					"iri_col_names = [\"iso3\", \"name\", \"year\", \"value\"]\n",
					"\n",
					"# Read the CSV files\n",
					"environmental_adaptation_path = 'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/AFRICOM_Instability_Index/nd_gain_country_index_2024.csv'\n",
					"african_countries_path = 'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/AFRICOM_Instability_Index/African_Countries_ISO3.csv'\n",
					"environmental_adaptation = pd.read_csv(environmental_adaptation_path)\n",
					"\n",
					"african_countries = pd.read_csv(african_countries_path)\n",
					"\n",
					"# Filter for African countries\n",
					"environmental_adaptation = environmental_adaptation[environmental_adaptation['ISO3'].isin(african_countries['iso3'])]\n",
					"environmental_adaptation.loc[environmental_adaptation['Name'] == \"Congo\", 'Name'] = \"Republic of the Congo\"\n",
					"environmental_adaptation.loc[environmental_adaptation['Name'] == \"Congo, the Democratic Republic o\", 'Name'] = \"Democratic Republic of the Congo\"\n",
					"environmental_adaptation.loc[environmental_adaptation['Name'] == \"Cape Verde\", 'Name'] = \"Cabo Verde\"\n",
					"environmental_adaptation.loc[environmental_adaptation['Name'] == \"Libyan Arab Jamahiriya\", 'Name'] = \"Libya\"\n",
					"environmental_adaptation.loc[environmental_adaptation['Name'] == \"Swaziland\", 'Name'] = \"Eswatini\"\n",
					"environmental_adaptation.loc[environmental_adaptation['Name'] == \"Tanzania, United Republic of\", 'Name'] = \"Tanzania\"\n",
					"\n",
					"\n",
					"# Reshape the data from wide to long format\n",
					"environmental_adaptation = environmental_adaptation.melt(\n",
					"    id_vars=[\"ISO3\", \"Name\"],\n",
					"    value_vars=[str(year) for year in range(1995, 2022 + 1)],\n",
					"    var_name=\"year\",\n",
					"    value_name=\"value\"\n",
					")\n",
					"\n",
					"# Rename columns\n",
					"environmental_adaptation.columns = iri_col_names\n",
					"\n",
					"# Compute 'adaptation_score'\n",
					"environmental_adaptation['adaptation_score'] = 2 - (2 * environmental_adaptation['value'] / 100)\n",
					"\n",
					"# Convert 'year' to numeric\n",
					"environmental_adaptation['year'] = pd.to_numeric(environmental_adaptation['year'])\n",
					"\n",
					"# Filter for years >= 2000\n",
					"environmental_adaptation = environmental_adaptation[environmental_adaptation['year'] >= 2013]\n",
					"\n",
					"print(environmental_adaptation.head())"
				],
				"execution_count": 4
			},
			{
				"cell_type": "code",
				"source": [
					"check_country_names(environmental_adaptation['name'], african_countries['country']) #used to check for spelling differences in country name sets"
				],
				"execution_count": 5
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Commonwealth Youth Index"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"#Read in json file\n",
					"\n",
					"url = \"https://cwapiservices.thecommonwealth.org/CountryData/GetAllYDI_index_scores\"\n",
					"headers = {\"Accept\": \"application/json\"}\n",
					"\n",
					"response = requests.get(url, headers=headers)\n",
					"data = response.json()\n",
					"\n",
					"\n",
					"# Convert to DataFrame\n",
					"youth_underdevelopment = pd.json_normalize(data)\n",
					"youth_underdevelopment.loc[youth_underdevelopment['country'] == 'C�te d�Ivoire', 'country'] = \"Cote d'Ivoire\"\n",
					"youth_underdevelopment.loc[youth_underdevelopment['country'] == 'S�o Tom� & Pr�ncipe', 'country'] = \"Sao Tome and Principe\"\n",
					"youth_underdevelopment.loc[youth_underdevelopment['country'] =='Congo - Kinshasa', 'country'] = \"Democratic Republic of the Congo\"\n",
					"youth_underdevelopment.loc[youth_underdevelopment['country'] == 'Congo - Brazzaville', 'country'] = \"Republic of the Congo\"\n",
					"youth_underdevelopment.loc[youth_underdevelopment['country'] == 'Cape Verde', 'country'] = \"Cabo Verde\"\n",
					"\n",
					"# Filter for African countries\n",
					"youth_underdevelopment = youth_underdevelopment[youth_underdevelopment['iD_0'].isin(african_countries['iso3'])]\n",
					"\n",
					"#Select iD_0, country, year, overall_score\n",
					"youth_underdevelopment = youth_underdevelopment[['iD_0', 'country', 'year', 'overall_score']]\n",
					"\n",
					"# Rename columns\n",
					"youth_underdevelopment.columns = iri_col_names\n",
					"\n",
					"# Compute 'underdevelopment_score'\n",
					"youth_underdevelopment['underdevelopment_score'] = 2 - (2 * youth_underdevelopment['value'])\n",
					"\n",
					"# Convert 'year' to numeric\n",
					"youth_underdevelopment['year'] = pd.to_numeric(youth_underdevelopment['year'])\n",
					"\n",
					"# Filter for years >= 2013\n",
					"youth_underdevelopment = youth_underdevelopment[youth_underdevelopment['year'] >= 2013]\n",
					"\n",
					"print(youth_underdevelopment.head())\n",
					"\n",
					""
				],
				"execution_count": 6
			},
			{
				"cell_type": "code",
				"source": [
					"check_country_names(youth_underdevelopment['name'], african_countries['country'])"
				],
				"execution_count": 7
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Illiteracy"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#Read in Data\n",
					"\n",
					"# Define the indicator and countries (or use 'all')\n",
					"indicator = 'SE.ADT.LITR.ZS'\n",
					"\n",
					"# Fetch data for all countries\n",
					"illiteracy = wb.download(indicator=indicator, country='all', start=2000, end=2023)\n",
					"illiteracy = illiteracy.reset_index()\n",
					"illiteracy.loc[illiteracy['country'] == 'Congo, Dem. Rep.', 'country'] = 'Democratic Republic of the Congo'\n",
					"illiteracy.loc[illiteracy['country'] == 'Congo, Rep.', 'country'] = 'Republic of the Congo'\n",
					"\n",
					"\n",
					"\n",
					"#Get ISO3 values and filter for specific African countries\n",
					"illiteracy = pd.merge(illiteracy, african_countries, on='country', how='left')\n",
					"illiteracy = illiteracy[illiteracy['iso3'].isin(african_countries['iso3'])]\n",
					"\n",
					"#Rename columns\n",
					"illiteracy = illiteracy[['iso3', 'country', 'year', indicator]]\n",
					"illiteracy.columns = iri_col_names\n",
					"illiteracy = illiteracy.dropna(subset=['value'])\n",
					"illiteracy['value'] = 100 - illiteracy['value'] #want illiteracy percentage\n",
					"\n",
					"# Compute 'illiteracy_score'\n",
					"illiteracy['illiteracy_score'] = 2 * illiteracy['value'] / 100\n",
					"\n",
					"# Convert 'year' to numeric\n",
					"illiteracy['year'] = pd.to_numeric(illiteracy['year'])\n",
					"\n",
					"# Filter for years >=2013\n",
					"illiteracy = illiteracy[illiteracy['year'] >=2013]\n",
					"\n",
					"\n",
					"print(illiteracy.head())\n",
					""
				],
				"execution_count": 8
			},
			{
				"cell_type": "code",
				"source": [
					"check_country_names(illiteracy['name'], african_countries['country'])"
				],
				"execution_count": 9
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Fragile State Index Data"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"file_list = mssparkutils.fs.ls(\"abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/AFRICOM_Instability_Index/fsi_data\")\n",
					"file_paths = []\n",
					"\n",
					"for file_path in file_list:\n",
					"    if '.xlsx' in file_path.path:\n",
					"        file_paths.append(file_path.path)\n",
					"\n",
					"dfs = []\n",
					"\n",
					"\n",
					"for path in file_paths:\n",
					"    df = spark.read.format(\"com.crealytics.spark.excel\") \\\n",
					"        .option(\"header\", \"true\") \\\n",
					"        .option(\"inferSchema\", \"true\") \\\n",
					"        .load(path)\n",
					"    df = df.select(df.columns[:16]) #Data from 2009 onwards has an extra column\n",
					"    \n",
					"# Cast all columns to string to ensure compatibility\n",
					"    for col_name in df.columns:\n",
					"        df = df.withColumn(col_name, df[col_name].cast(\"string\"))\n",
					"\n",
					"    dfs.append(df)\n",
					"\n",
					"# Union all DataFrames\n",
					"combined_df = dfs[0]\n",
					"for df in dfs[1:]:\n",
					"    combined_df = combined_df.unionByName(df)\n",
					"\n",
					"\n",
					"# Cast the first three columns\n",
					"fsi_data = combined_df \\\n",
					"    .withColumn(\"Country\", col(\"Country\").cast(\"string\")) \\\n",
					"    .withColumn(\"Year\", year(col(\"Year\")).cast(\"int\")) \\\n",
					"    .withColumn(\"Rank\", col(\"Rank\").cast(\"string\"))\n",
					"\n",
					"\n",
					"# Cast the remaining columns to double\n",
					"for col_name in fsi_data.columns[3:]:\n",
					"    fsi_data = fsi_data.withColumn(col_name, col(col_name).cast(\"double\"))\n",
					"\n",
					"fsi_data = fsi_data.toPandas()\n",
					"fsi_data[\"Year\"] = fsi_data[\"Year\"].fillna(0).astype(int)\n",
					"fsi_data = pd.merge(fsi_data, african_countries, left_on='Country',  right_on='country', how='left')\n",
					"fsi_data = fsi_data.dropna(subset = ['iso3'])\n",
					"fsi_data = fsi_data.drop_duplicates(subset=['iso3', 'Year'], keep=\"first\")\n",
					"fsi_data.loc[fsi_data['Country'] == 'Congo Democratic Republic', 'Country'] = 'Democratic Republic of the Congo'\n",
					"fsi_data.loc[fsi_data['Country'] == 'Congo Republic', 'Country'] = 'Republic of the Congo'\n",
					"\n",
					"\n",
					"print(fsi_data.head())\n",
					""
				],
				"execution_count": 10
			},
			{
				"cell_type": "code",
				"source": [
					"check_country_names(fsi_data['Country'], african_countries['country'])"
				],
				"execution_count": 11
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Human Flight (FSI E3)\n",
					"\n",
					"This is a subsection of the `fsi` dataset, thus a similar methodology will be used for other `fsi` subsets."
				]
			},
			{
				"cell_type": "code",
				"source": [
					"#Extract appropriate column and format the rest of the data\n",
					"selected_col = 'E3: Human Flight and Brain Drain'\n",
					"human_flight = fsi_data[['iso3','Country', 'Year', selected_col]].copy()\n",
					"human_flight.columns = iri_col_names\n",
					"\n",
					"# Compute 'human_flight_score'\n",
					"human_flight['human_flight_score'] = 2 * human_flight['value'] / 10\n",
					"\n",
					"# Convert 'year' to numeric\n",
					"human_flight['year'] = pd.to_numeric(human_flight['year'])\n",
					"\n",
					"# Filter for years >=2013\n",
					"human_flight = human_flight[human_flight['year'] >=2013]\n",
					"\n",
					"print(human_flight.head())"
				],
				"execution_count": 12
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Demographic Pressures (FSI S1)"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"#Extract appropriate column and format the rest of the data\n",
					"selected_col = 'S1: Demographic Pressures'\n",
					"demographic_pressure = fsi_data[['iso3', 'Country', 'Year', selected_col]].copy()\n",
					"demographic_pressure.columns = iri_col_names\n",
					"\n",
					"\n",
					"# Compute 'demographic_pressure_score'\n",
					"demographic_pressure['demographic_pressure_score'] = 2 * demographic_pressure['value'] / 10\n",
					"\n",
					"# Convert 'year' to numeric\n",
					"demographic_pressure['year'] = pd.to_numeric(demographic_pressure['year'])\n",
					"\n",
					"# Filter for years >=2013\n",
					"demographic_pressure = demographic_pressure[demographic_pressure['year'] >=2013]\n",
					"\n",
					"print(demographic_pressure.head())"
				],
				"execution_count": 13
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Socioenvironmental Pressures Index"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"#Check to see if all countries are accounted for in all datasets\n",
					"missing_iso = {}\n",
					"for iso in african_countries['iso3']:\n",
					"    missing_iso[iso] = []\n",
					"    if not any(environmental_adaptation['iso3'].str.contains(iso)):\n",
					"        missing_iso[iso].append('environmental_adaptation')\n",
					"    if not any(youth_underdevelopment['iso3'].str.contains(iso)):\n",
					"        missing_iso[iso].append('youth_underdevelopment')\n",
					"    if not any(illiteracy['iso3'].str.contains(iso)):\n",
					"        missing_iso[iso].append('illiteracy')\n",
					"    if not any(human_flight['iso3'].str.contains(iso)):\n",
					"        missing_iso[iso].append('human_flight')\n",
					"    if not any(demographic_pressure['iso3'].str.contains(iso)):\n",
					"        missing_iso[iso].append('demographic_pressure')\n",
					"print(missing_iso)"
				],
				"execution_count": 14
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"According to the above check for a country missing in the five datasets, we will not be able to compute a complete index for DJI, EGY, GMB, GNB, LBY, and SSD."
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"##### Kenya Example"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"country_iso = \"KEN\"\n",
					"ken_socio_pressures_df = create_domain_index(country_iso, environmental_adaptation, youth_underdevelopment, illiteracy, human_flight, demographic_pressure)\n",
					"ken_socio_pressures_df.sort_values(by='year', inplace=True)\n",
					"#ken_socio_pressures_df = ken_socio_pressures_df.rename(columns={'domain_score': 'socio_pressure_score'})"
				],
				"execution_count": 15
			},
			{
				"cell_type": "code",
				"source": [
					"print(ken_socio_pressures_df)"
				],
				"execution_count": 16
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"This section demonstrates how to "
				]
			},
			{
				"cell_type": "code",
				"source": [
					"percentiles = compute_estimate_percentiles(ken_socio_pressures_df)\n",
					"m = pymetalog.metalog(percentiles, boundedness='b', bounds=[0, 1], term_limit=3)\n",
					"\n",
					""
				],
				"execution_count": 17
			},
			{
				"cell_type": "code",
				"source": [
					"pymetalog.summary(m)"
				],
				"execution_count": 18
			},
			{
				"cell_type": "code",
				"source": [
					"pymetalog.plot(m)"
				],
				"execution_count": 19
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Group Grievances Subdomain\n",
					"\n",
					"| Data Source | URL | Indicator Domain | Notes |\n",
					"|-------------|-----|------------------|-------|\n",
					"| Fragile State Index—Inequality score [7]    | <https://fragilestatesindex.org/indicators/e2/> | Socioenvironmental Pressures | Annual Update |\n",
					"| International Labor Organization—Unemployment Total (% of total labor force) [8]    | <https://data.worldbank.org/indicator/SL.UEM.TOTL.ZS> | Socioenvironmental Pressures | Annual Update |\n",
					"| Fragile State Index—Group Grievance score [7]    | <https://fragilestatesindex.org/indicators/c3/> | Socioenvironmental Pressures | Annual Update |\n",
					"| Fragile State Index—Refugees and IDPs score [7]    | <https://fragilestatesindex.org/indicators/s2/> | Socioenvironmental Pressures | Annual Update |\n",
					"| Mo Ibrahim Index-Infrastructure score [9]   | <https://mo.ibrahim.foundation/our-research/iiag> | Socioenvironmental Pressures | Annual Update |\n",
					"\n",
					"Table of IRI Group Grievances Datasources\n",
					""
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Inequality (FSI E2)"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"#Extract appropriate column and format the rest of the data\n",
					"selected_col = 'E2: Economic Inequality'\n",
					"inequality = fsi_data[['iso3', 'Country', 'Year', selected_col]].copy()\n",
					"inequality.columns = iri_col_names\n",
					"\n",
					"\n",
					"# Compute 'inequality_score'\n",
					"inequality['inequality_score'] = 2 * inequality['value'] / 10\n",
					"\n",
					"# Convert 'year' to numeric\n",
					"inequality['year'] = pd.to_numeric(inequality['year'])\n",
					"\n",
					"# Filter for years >=2013\n",
					"inequality = inequality[inequality['year'] >=2013]\n",
					"\n",
					"print(inequality.head())"
				],
				"execution_count": 20
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Unemployment"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"# Read the CSV files\n",
					"unemployment_path = 'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/AFRICOM_Instability_Index/ilo_unemployment_rate_wb.csv'\n",
					"unemployment = pd.read_csv(unemployment_path, skiprows=4)\n",
					"unemployment.loc[unemployment['Country Name'] == 'Congo, Rep.', 'Country Name'] = 'Republic of the Congo'\n",
					"unemployment.loc[unemployment['Country Name'] == 'Congo, Dem. Rep.', 'Country Name'] = 'Democratic Republic of the Congo'\n",
					"unemployment.loc[unemployment['Country Name'] == 'Egypt, Arab Rep.', 'Country Name'] = 'Egypt'\n",
					"unemployment.loc[unemployment['Country Name'] == 'Gambia, The', 'Country Name'] = 'Gambia'\n",
					"unemployment = unemployment.drop(columns=['Indicator Name', 'Indicator Code', 'Unnamed: 69'], errors='ignore')\n",
					"unemployment = unemployment.melt(id_vars=['Country Name', 'Country Code'],\n",
					"                  var_name='year',\n",
					"                  value_name='unemployment_rate')\n",
					"unemployment = unemployment.dropna(subset=['unemployment_rate'])\n",
					"unemployment = unemployment[unemployment['Country Code'].isin(african_countries['iso3'])]\n",
					"\n",
					"# Rename and reorder columns\n",
					"unemployment = unemployment[['Country Code', 'Country Name', 'year', 'unemployment_rate']].copy()\n",
					"unemployment.columns = iri_col_names\n",
					"\n",
					"# Compute 'human_flight_score'\n",
					"unemployment['unemployment_score'] = 2 * unemployment['value'] / 100\n",
					"\n",
					"# Convert 'year' to numeric\n",
					"unemployment['year'] = pd.to_numeric(unemployment['year'])\n",
					"\n",
					"# Filter for years >=2013\n",
					"unemployment = unemployment[unemployment['year'] >=2013]\n",
					"\n",
					"print(unemployment.head())"
				],
				"execution_count": 21
			},
			{
				"cell_type": "code",
				"source": [
					"check_country_names(unemployment['name'], african_countries['country'])"
				],
				"execution_count": 22
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Group Grievance (FSI C3)"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"#Extract appropriate column and format the rest of the data\n",
					"selected_col = 'C3: Group Grievance'\n",
					"group_grievance = fsi_data[['iso3', 'Country', 'Year', selected_col]].copy()\n",
					"group_grievance.columns = iri_col_names\n",
					"\n",
					"\n",
					"# Compute 'group_grievance_score'\n",
					"group_grievance['group_grievance_score'] = 2 * group_grievance['value'] / 10\n",
					"\n",
					"# Convert 'year' to numeric\n",
					"group_grievance['year'] = pd.to_numeric(group_grievance['year'])\n",
					"\n",
					"# Filter for years >=2013\n",
					"group_grievance = group_grievance[group_grievance['year'] >=2013]\n",
					"\n",
					"print(group_grievance.head())"
				],
				"execution_count": 23
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Refugees and IDPs (FSI S2)"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"#Extract appropriate column and format the rest of the data\n",
					"selected_col = 'S2: Refugees and IDPs'\n",
					"refugees = fsi_data[['iso3', 'Country', 'Year', selected_col]].copy()\n",
					"refugees.columns = iri_col_names\n",
					"\n",
					"\n",
					"# Compute 'refugees_score'\n",
					"refugees['refugees_score'] = 2 * refugees['value'] / 10\n",
					"\n",
					"# Convert 'year' to numeric\n",
					"refugees['year'] = pd.to_numeric(refugees['year'])\n",
					"\n",
					"# Filter for years >=2013\n",
					"refugees = refugees[refugees['year'] >=2013]\n",
					"\n",
					"print(refugees.head())"
				],
				"execution_count": 24
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Mo Ibrahim Foundation Data"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"iiag_df_path = 'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/AFRICOM_Instability_Index/iiag_data/2024-IIAG-scores.xlsx'\n",
					"iiag_df = pd.read_excel(iiag_df_path)\n",
					"iiag_df = pd.merge(iiag_df, african_countries, left_on='Country', right_on='country', how='left')\n",
					"iiag_df = iiag_df[iiag_df['iso3'].isin(african_countries['iso3'])]\n",
					"iiag_df.drop(columns=['Country'], inplace=True)\n",
					"print(iiag_df.head())"
				],
				"execution_count": 25
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Infrastructure (IIAG INFR)"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"infrastructure = iiag_df[['iso3', 'country', 'Year', 'INFR']].copy()\n",
					"infrastructure.columns = iri_col_names\n",
					"\n",
					"# Compute 'infrastructure_score'\n",
					"infrastructure['infrastructure_score'] = 2 - (2 * infrastructure['value'] / 100) #Lower scores are worse\n",
					"\n",
					"# Convert 'year' to numeric\n",
					"infrastructure['year'] = pd.to_numeric(infrastructure['year'])\n",
					"\n",
					"# Filter for years >=2013\n",
					"infrastructure = infrastructure[infrastructure['year'] >=2013]\n",
					"\n",
					"print(infrastructure.head())"
				],
				"execution_count": 26
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Group Grievances Index"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"#Check to see if all countries are accounted for in all datasets\n",
					"missing_iso = {}\n",
					"for iso in african_countries['iso3']:\n",
					"    missing_iso[iso] = []\n",
					"    if not any(inequality['iso3'].str.contains(iso)):\n",
					"        missing_iso[iso].append('inequality')\n",
					"    if not any(unemployment['iso3'].str.contains(iso)):\n",
					"        missing_iso[iso].append('unemployment')\n",
					"    if not any(group_grievance['iso3'].str.contains(iso)):\n",
					"        missing_iso[iso].append('group_grievance')\n",
					"    if not any(refugees['iso3'].str.contains(iso)):\n",
					"        missing_iso[iso].append('refugees')\n",
					"    if not any(infrastructure['iso3'].str.contains(iso)):\n",
					"        missing_iso[iso].append('infrastructure')\n",
					"print(missing_iso)"
				],
				"execution_count": 27
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"The following countries do not have data associated with at least one of the requisite datasets: CIV, COD, GNB, COG, SYC"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"ken_group_grievance_df = create_domain_index(country_iso, inequality, unemployment, group_grievance, refugees, infrastructure)\n",
					"ken_group_grievance_df['iso3'] = country_iso\n",
					"ken_group_grievance_df['name'] = 'Kenya'\n",
					"ken_group_grievance_df.sort_values(by='year', inplace=True)\n",
					"print(ken_group_grievance_df)"
				],
				"execution_count": 28
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"### Sociopolitical Unrest Subdomain\n",
					"\n",
					"| Data Source | URL | Indicator Domain | Notes |\n",
					"|-------------|-----|------------------|-------|\n",
					"| Mo Ibrahim Index-Absence of Armed Conflict Score [9]   | <https://mo.ibrahim.foundation/our-research/iiag> | Socioenvironmental Pressures | Annual Update |\n",
					"| Mo Ibrahim Index-Absence of Violence Against Civilians Score [9]   | <https://mo.ibrahim.foundation/our-research/iiag> | Socioenvironmental Pressures | Annual Update |\n",
					"| Mo Ibrahim Index-Absence of Crime Score [9]   | <https://mo.ibrahim.foundation/our-research/iiag> | Socioenvironmental Pressures | Annual Update |\n",
					"| Political Terror Scale [10]   | <https://www.politicalterrorscale.org/Data/Datatable.html> | Socioenvironmental Pressures | Annual Update |\n",
					"| Global Peace Index-Violent Demonstrations Score [11]    | URL Here | Socioenvironmental Pressures | Annual Update |\n",
					"\n",
					"\n",
					"Table of IRI Group Grievances Datasources\n",
					""
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Abscence of Armed Conflict (IIAG AbsArmedConf)"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"armed_conflict = iiag_df[['iso3', 'country', 'Year', 'AbsArmedConf']].copy()\n",
					"armed_conflict.columns = iri_col_names\n",
					"\n",
					"# Compute 'armed_conflict_score'\n",
					"armed_conflict['armed_conflict_score'] = 2 - (2 * armed_conflict['value'] / 100) #Lower scores are worse\n",
					"\n",
					"# Convert 'year' to numeric\n",
					"armed_conflict['year'] = pd.to_numeric(armed_conflict['year'])\n",
					"\n",
					"# Filter for years >=2013\n",
					"armed_conflict = armed_conflict[armed_conflict['year'] >=2013]\n",
					"\n",
					"print(armed_conflict.head())"
				],
				"execution_count": 29
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Absence of Violence Against Civilians (IIAG AbsViolCiv)"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"civilian_violence = iiag_df[['iso3', 'country', 'Year', 'AbsViolCiv']].copy()\n",
					"civilian_violence.columns = iri_col_names\n",
					"\n",
					"# Compute 'civilian_violence_score'\n",
					"civilian_violence['civilian_violence_score'] = 2 - (2 * civilian_violence['value'] / 100) #Lower scores are worse\n",
					"\n",
					"# Convert 'year' to numeric\n",
					"civilian_violence['year'] = pd.to_numeric(civilian_violence['year'])\n",
					"\n",
					"# Filter for years >=2013\n",
					"civilian_violence = civilian_violence[civilian_violence['year'] >=2013]\n",
					"\n",
					"print(civilian_violence.head())"
				],
				"execution_count": 30
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Absence of Crime (IIAG AbsCrim)"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"crime_absence = iiag_df[['iso3', 'country', 'Year', 'AbsCrim']].copy()\n",
					"crime_absence.columns = iri_col_names\n",
					"\n",
					"# Compute 'crime_absence_score'\n",
					"crime_absence['crime_absence_score'] = 2 - (2 * crime_absence['value'] / 100) #Lower scores are worse\n",
					"\n",
					"# Convert 'year' to numeric\n",
					"crime_absence['year'] = pd.to_numeric(crime_absence['year'])\n",
					"\n",
					"# Filter for years >=2013\n",
					"crime_absence = crime_absence[crime_absence['year'] >=2013]\n",
					"\n",
					"print(crime_absence.head())"
				],
				"execution_count": 35
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Political Terror"
				]
			},
			{
				"cell_type": "code",
				"source": [
					"political_terror_path = 'abfss://acj802@ac2synapsedatalabstorage.dfs.core.windows.net/AFRICOM_Instability_Index/pts_data.csv'\n",
					"political_terror = pd.read_csv(political_terror_path)\n",
					"political_terror.loc[political_terror['Country'] == 'Congo, the Democratic Republic of the', 'Country'] = 'Democratic Republic of the Congo'\n",
					"political_terror.loc[political_terror['Country'] == 'Congo', 'Country'] = 'Republic of the Congo'\n",
					"political_terror.loc[political_terror['Country'] == 'Tanzania, United Republic of', 'Country'] = 'Tanzania'\n",
					"political_terror['average_score'] = political_terror[['Amnesty International', 'Human Rights Watch', 'U.S. State Department']].mean(axis=1).copy()\n",
					"\n",
					"#Get ISO3 values and filter for specific African countries\n",
					"political_terror = pd.merge(political_terror, african_countries, left_on='Country', right_on='country', how='left')\n",
					"political_terror = political_terror[political_terror['iso3'].isin(african_countries['iso3'])]\n",
					"\n",
					"#Reorder and rename columns\n",
					"political_terror = political_terror[['iso3', 'Country', 'Year', 'average_score']].copy()\n",
					"political_terror.columns = iri_col_names\n",
					"\n",
					"# Compute 'political_terror_score'\n",
					"political_terror['political_terror_score'] = 2 * ((political_terror['value'] - 1) / 4) #Original scores are 1 - 5 with 5 being the worst\n",
					"\n",
					"\n",
					"\n",
					"# Convert 'year' to numeric\n",
					"political_terror['year'] = pd.to_numeric(political_terror['year'])\n",
					"\n",
					"# Filter for years >=2013\n",
					"political_terror = political_terror[political_terror['year'] >=2013]\n",
					"\n",
					"\n",
					"\n",
					"\n",
					"\n",
					"\n",
					"print(political_terror.head())"
				],
				"execution_count": 36
			},
			{
				"cell_type": "code",
				"source": [
					"check_country_names(political_terror['name'], african_countries['country'])"
				],
				"execution_count": 34
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"#### Violent Demonstrations"
				]
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"\n",
					"### References\n",
					"[1] USAFRICOM J54. (2025). *Africa Instability Risk Assessment*. USAFRICOM.\n",
					"\n",
					"[2] Wikipedia. (2025). *Autoregressive integrated moving average*. http://en.wikipedia.org/w/index.php?title=Autoregressive\\%20integrated\\%20moving\\%20average&oldid=1286449544, accessed 07 May 2025.\n",
					"\n",
					"[3] Wikipedia. (2025). *Metalog distribution*. http://en.wikipedia.org/w/index.php?title=Metalog\\%20distribution&oldid=1278020484, accessed 07 May 2025.\n",
					"\n",
					"[4] University of Notre Dame. (2025). *Notre Dame Global Adaptation Initiative Country Index (ND-GAIN)*. https://gain.nd.edu/our-work/country-index/download-data/\n",
					"\n",
					"[5] The Commonwealth. (2025). *Youth Development Index*. https://cwapiservices.thecommonwealth.org/index.html\n",
					"\n",
					"[6] World Bank. (2025). *Literacy rate, adult total (% of people ages 15 and above)*. https://data.worldbank.org/indicator/SE.ADT.LITR.ZS?most_recent_value_desc=true\n",
					"\n",
					"[7] The Fund for Peace. (2022). *Fragile State Index*. https://fragilestatesindex.org/excel/\n",
					"\n",
					"[8] International Labor Organization (2025). *Unemployment and Labor Underutilization*. https://data.worldbank.org/indicator/SL.UEM.TOTL.ZS\n",
					"\n",
					"[9] Mo Ibrahim Foundation (2025). *Ibrahim Index of African Governance (IIAG)*. https://mo.ibrahim.foundation/our-research/iiag\n",
					"\n",
					"[10] Political Terror Scale (2025). *PTS Data Table*. https://www.politicalterrorscale.org/Data/Datatable.html\n",
					"\n",
					""
				]
			}
		]
	}
}